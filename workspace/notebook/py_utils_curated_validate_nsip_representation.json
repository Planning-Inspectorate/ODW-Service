{
	"name": "py_utils_curated_validate_nsip_representation",
	"properties": {
		"description": "Validation notebook for validating curated layer tables against the json schema.",
		"folder": {
			"name": "utils/data-validation"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "2adc27b3-54b9-4444-a7f5-251274dc93b1"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Validation notebook for validating curated layer tables against the json schema\r\n",
					"\r\n",
					"#### NB: PLEASE ATTACH TO THE SPARK POOL \"PINSSYNSPODW\" AS THIS IS RUNNING PYTHON 3.10 WHICH IS NEEDED"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Install packages"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%pip install --quiet --upgrade pip\r\n",
					"%pip install --quiet jsonschema==4.20.0 iso8601==2.1.0 git+https://github.com/Planning-Inspectorate/data-model@main#egg=pins_data_model"
				],
				"execution_count": 47
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Imports"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pandas as pd\r\n",
					"import numpy as np\r\n",
					"import json\r\n",
					"from collections import defaultdict\r\n",
					"import pprint\r\n",
					"from jsonschema import validate, FormatChecker, ValidationError, Draft202012Validator\r\n",
					"from iso8601 import parse_date, ParseError\r\n",
					"from pins_data_model import load_schemas"
				],
				"execution_count": 48
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Import validation funcitons notebook"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run utils/data-validation/py_utils_curated_validate_functions"
				],
				"execution_count": 49
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Define constants"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"SCHEMAS = load_schemas.load_all_schemas()[\"schemas\"]\r\n",
					"SCHEMA = SCHEMAS[\"nsip-representation.schema.json\"]\r\n",
					"PRIMARY_KEY = \"caseRef\" \r\n",
					"DATABASE = \"odw_curated_db\"\r\n",
					"TABLE = \"relevant_representation\"\r\n",
					"QUERY = f\"SELECT * FROM `{DATABASE}`.`{TABLE}`\"\r\n",
					"OUTPUT_FILE = f\"{TABLE}.txt\""
				],
				"execution_count": 50
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Create dataframe of the data from the table\r\n",
					"\r\n",
					"For certain tables it may be necessary to rename a column or two in order to create the array and avoid duplicate field names.\r\n",
					"\r\n",
					"It's also necessary to convert None and NaT values to empty strings. A NULL value in SQL is shown as None for strings or NaT for timestamps in pandas so converting to an empty string will match the expected schema as we're validating using a pandas dataframe.\r\n",
					"\r\n",
					"The replace() function is used to convert NaT values to None and then these are converted to empty strings using fillna()."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df = spark.sql(QUERY)\r\n",
					"data = df.toPandas()\r\n",
					"data.rename(columns={\"attachmentIds\": \"attachmentId\"}, inplace=True)\r\n",
					"for column in data:\r\n",
					"    data[column].replace({pd.NaT: None, np.nan: None},inplace=True)"
				],
				"execution_count": 51
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data.head(5)"
				],
				"execution_count": 52
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Validate against the schema\r\n",
					"\r\n",
					"%%capture magic command is used to capture the cell output and assign it to the variable \"output\". This can then be used later as the data to be written to file.\r\n",
					"\r\n",
					"The validate variable can be used and returned as the exit value of the notebook."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%%capture output\r\n",
					"\r\n",
					"validate = validate_data(data=create_json_from_table_with_arrays(data, \r\n",
					"                                                            primary_key=PRIMARY_KEY,\r\n",
					"                                                            array=\"attachmentIds\",\r\n",
					"                                                            array_field=\"attachmentId\"), \r\n",
					"                        schema=SCHEMA,\r\n",
					"                        primary_key= PRIMARY_KEY)"
				],
				"execution_count": 53
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Print the validation output\r\n",
					"\r\n",
					"Output is sent to storage so commented out but can be printed here if need be"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"result = output.stdout\r\n",
					"print(result)"
				],
				"execution_count": 54
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"SELECT * FROM odw_curated_db.relevant_representation WHERE caseRef = 'EN020015'"
				],
				"execution_count": 55
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Write output to storage"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"write_file_to_storage(path, OUTPUT_FILE, result)"
				],
				"execution_count": 56
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Set notebook exit value to the validate variable above\r\n",
					"\r\n",
					"True for successful validation\r\n",
					"False for faield validation"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mssparkutils.notebook.exit(validate)"
				],
				"execution_count": 57
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Check data points to ensure correct\r\n",
					"First start with Service Bus"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"SELECT * FROM odw_standardised_db.sb_nsip_representation where caseRef = 'TR0110033' order by ingested_datetime asc"
				],
				"execution_count": 58
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"SELECT * FROM odw_harmonised_db.sb_nsip_representation where caseRef = 'TR0110033' order by IngestionDate asc"
				],
				"execution_count": 59
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"SELECT * FROM odw_harmonised_db.nsip_relevant_representation where caseRef = 'TR0110033' order by IngestionDate asc\r\n",
					"\r\n",
					"-- This is clearly wrong as only the last one should be set to Y. Need to debug"
				],
				"execution_count": 64
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"SELECT * FROM odw_curated_db.relevant_representation where caseRef = 'TR0110033' "
				],
				"execution_count": 60
			}
		]
	}
}