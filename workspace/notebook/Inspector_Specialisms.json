{
	"name": "Inspector_Specialisms",
	"properties": {
		"folder": {
			"name": "odw-harmonised"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "abf44b2e-1057-4e3e-9331-9ef137959418"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Entity Name : Inspector Specialism \n",
					"### Author: Prathap A\n",
					"### Date: 25/02/2025\n",
					"\n",
					"#### version : 0001\n",
					"\n",
					"###### <u>Description</u>:\n",
					"This template is designed to facilitate the monthly processing and harmonization of Inspector Specialism. It includes steps for initializing the environment, creating and managing Delta tables, and inserting data into harmonized tables. The template ensures that Inspector Specialism data is accurately transformed, stored, and made available for reporting and analysis.\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Intialisations"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import udf, col, lit, when, coalesce, concat, sum, avg, max, min, count, countDistinct, date_format, to_date, datediff, months_between, year, month,  hour, minute, second, expr, asc, desc\n",
					"from pyspark.sql.types import DateType, TimestampType, StringType, IntegerType, FloatType, DoubleType, BooleanType, StructType, StructField, ArrayType, MapType\n",
					"from pyspark.sql.window import Window\n",
					"from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead, ntile\n",
					"from pyspark.sql import SQLContext\n",
					"from pyspark.sql import DataFrame\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.avro.functions import from_avro, to_avro\n",
					"from pyspark.sql.streaming import DataStreamReader, DataStreamWriter\n",
					"from pyspark.sql.utils import AnalysisException\n",
					"from pyspark.sql.catalog import Catalog\n",
					"from pyspark.sql.column import Column\n",
					"from pyspark.sql.group import GroupedData\n",
					"from pyspark.sql.pandas.functions import pandas_udf\n",
					"\n",
					"from datetime import datetime, timedelta\n",
					"import pandas as pd\n",
					"import numpy as np"
				],
				"execution_count": 23
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"describe odw_harmonised_db.transform_inspector_Specialisms"
				],
				"execution_count": 24
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Create Table inspector_Specialisms"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"-- Delete all records from the transform table\n",
					"DELETE FROM odw_harmonised_db.transform_inspector_Specialisms;\n",
					"\n",
					"-- Insert new records into the transform table\n",
					"INSERT INTO odw_harmonised_db.transform_inspector_Specialisms (\n",
					"    StaffNumber,\n",
					"    Firstname,\n",
					"    Lastname,\n",
					"    QualificationName,\n",
					"    Proficien,\n",
					"    SourceSystemID,\n",
					"    IngestionDate,\n",
					"    ValidTo,\n",
					"    RowID,\n",
					"    IsActive\n",
					")\n",
					"SELECT \n",
					"    CASE \n",
					"        WHEN LEN(StaffNumber) = 6 THEN\n",
					"            CASE \n",
					"                WHEN StaffNumber LIKE '50%' THEN CONCAT('00', StaffNumber)\n",
					"                WHEN StaffNumber LIKE '42%' THEN CONCAT('50', StaffNumber)\n",
					"                ELSE StaffNumber\n",
					"            END\n",
					"        WHEN LEN(StaffNumber) = 8 THEN StaffNumber\n",
					"        ELSE StaffNumber\n",
					"    END AS StaffNumber,\n",
					"    Firstname,\n",
					"    Lastname,\n",
					"    QualificationName,\n",
					"    Proficien,\n",
					"    'saphr' AS SourceSystemID,\n",
					"    CURRENT_DATE() AS IngestionDate,\n",
					"    CURRENT_DATE() AS ValidTo,\n",
					"    NULL AS RowID,\n",
					"    'Y' AS IsActive\n",
					"FROM odw_standardised_db.inspector_specialisms_monthly t1\n",
					"WHERE StaffNumber IS NOT NULL;"
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"UPDATE odw_harmonised_db.transform_inspector_Specialisms\n",
					"SET RowID = md5(concat_ws('|', \n",
					"    coalesce(cast(StaffNumber as string), ''), \n",
					"    coalesce(cast(Firstname as string), ''), \n",
					"    coalesce(cast(Lastname as string), ''), \n",
					"    coalesce(cast(QualificationName as string), ''), \n",
					"    coalesce(cast(Proficien as string), '')\n",
					"))"
				],
				"execution_count": 26
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Update Statements"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"MERGE INTO odw_harmonised_db.sap_hr_inspector_Specialisms AS target\n",
					"USING (\n",
					"    SELECT \n",
					"        oldSpe.StaffNumber, \n",
					"        oldSpe.QualificationName\n",
					"    FROM \n",
					"        odw_harmonised_db.sap_hr_inspector_Specialisms oldSpe\n",
					"    LEFT OUTER JOIN \n",
					"        odw_harmonised_db.transform_inspector_Specialisms souSpe\n",
					"    ON \n",
					"        oldSpe.StaffNumber = souSpe.StaffNumber\n",
					"        AND oldSpe.QualificationName = souSpe.QualificationName\n",
					"    WHERE \n",
					"        souSpe.StaffNumber IS NULL\n",
					") AS source\n",
					"ON \n",
					"    target.StaffNumber = source.StaffNumber\n",
					"    AND target.QualificationName = source.QualificationName\n",
					"    AND target.Current = 1\n",
					"WHEN MATCHED THEN\n",
					"UPDATE SET \n",
					"    target.Current = 0,\n",
					"    target.ValidTo = CURRENT_DATE();"
				],
				"execution_count": 27
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"INSERT INTO odw_harmonised_db.sap_hr_inspector_Specialisms (\n",
					"    StaffNumber, \n",
					"    Firstname, \n",
					"    Lastname, \n",
					"    QualificationName, \n",
					"    Proficien, \n",
					"    SourceSystemID, \n",
					"    IngestionDate, \n",
					"    ValidFrom, \n",
					"    ValidTo, \n",
					"    Current, \n",
					"    RowID, \n",
					"    IsActive, \n",
					"    LastUpdated\n",
					")\n",
					"SELECT \n",
					"    souSpe.StaffNumber, \n",
					"    souSpe.Firstname, \n",
					"    souSpe.Lastname, \n",
					"    souSpe.QualificationName, \n",
					"    souSpe.Proficien, \n",
					"    'saphr', \n",
					"    current_date(), \n",
					"    current_date(), \n",
					"    '9999-12-31', \n",
					"    1, \n",
					"    souSpe.RowID, \n",
					"    'Y', \n",
					"    current_date()\n",
					"FROM odw_harmonised_db.transform_inspector_Specialisms souSpe\n",
					"LEFT OUTER JOIN odw_harmonised_db.sap_hr_inspector_Specialisms tarSpe\n",
					"    ON souSpe.StaffNumber = tarSpe.StaffNumber\n",
					"    AND tarSpe.Current = 1\n",
					"    AND souSpe.QualificationName = tarSpe.QualificationName\n",
					"WHERE tarSpe.StaffNumber IS NULL;"
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"INSERT INTO odw_harmonised_db.sap_hr_inspector_Specialisms (\n",
					"    StaffNumber, \n",
					"    Firstname, \n",
					"    Lastname, \n",
					"    QualificationName, \n",
					"    Proficien, \n",
					"    SourceSystemID, \n",
					"    IngestionDate, \n",
					"    ValidFrom, \n",
					"    ValidTo, \n",
					"    Current, \n",
					"    RowID, \n",
					"    IsActive, \n",
					"    LastUpdated\n",
					")\n",
					"SELECT \n",
					"    souSpe.StaffNumber, \n",
					"    souSpe.Firstname, \n",
					"    souSpe.Lastname, \n",
					"    souSpe.QualificationName, \n",
					"    souSpe.Proficien, \n",
					"    'saphr', \n",
					"    current_date(), \n",
					"    current_date(), \n",
					"    '9999-12-31', \n",
					"    1, \n",
					"    souSpe.RowID, \n",
					"    'Y', \n",
					"    current_date()\n",
					"FROM odw_harmonised_db.transform_inspector_Specialisms souSpe\n",
					"LEFT OUTER JOIN odw_harmonised_db.sap_hr_inspector_Specialisms tarSpe\n",
					"    ON souSpe.StaffNumber = tarSpe.StaffNumber\n",
					"    AND tarSpe.Current = 1\n",
					"    AND souSpe.QualificationName = tarSpe.QualificationName\n",
					"WHERE tarSpe.RowID <> souSpe.RowID"
				],
				"execution_count": 29
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"-- Step 1: Deduplicate the source table (newSpe)\n",
					"WITH DeduplicatedSource AS (\n",
					"    SELECT \n",
					"        StaffNumber,\n",
					"        QualificationName,\n",
					"        ValidFrom,\n",
					"        Current,\n",
					"        ROW_NUMBER() OVER (\n",
					"            PARTITION BY StaffNumber, QualificationName \n",
					"            ORDER BY ValidFrom DESC\n",
					"        ) AS row_num\n",
					"    FROM \n",
					"        odw_harmonised_db.sap_hr_inspector_Specialisms\n",
					"    WHERE \n",
					"        Current = 1\n",
					"        AND ValidFrom = CURRENT_DATE()\n",
					")\n",
					"\n",
					"-- Step 2: Perform the MERGE operation using the deduplicated source\n",
					"MERGE INTO odw_harmonised_db.sap_hr_inspector_Specialisms AS oldSpe\n",
					"USING DeduplicatedSource AS newSpe\n",
					"ON \n",
					"    oldSpe.StaffNumber = newSpe.StaffNumber\n",
					"    AND oldSpe.QualificationName = newSpe.QualificationName\n",
					"    AND oldSpe.Current = 1\n",
					"    AND oldSpe.ValidFrom < CURRENT_DATE()\n",
					"    AND newSpe.row_num = 1 -- Ensure only one row per combination\n",
					"WHEN MATCHED THEN\n",
					"UPDATE SET \n",
					"    oldSpe.Current = 0,\n",
					"    oldSpe.ValidTo = CURRENT_DATE();"
				],
				"execution_count": 30
			}
		]
	}
}