{
	"name": "sap-hr-views",
	"properties": {
		"folder": {
			"name": "odw-harmonised/SAP-HR"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "043e2cc8-f414-4c96-a7f5-69fc7827860f"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 32,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"expected_from=''"
				],
				"execution_count": 42
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**The expected_from parameter above is the month which we want to ingest. For example, if we want data from January 2023, we can query this data from standardised by setting the expected_from as the start of next month (February)**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"if expected_from != '':\n",
					"    spark.sql(f\"SET DATE_VAR = '{expected_from}'\")\n",
					"else:\n",
					"    spark.sql(f\"SET DATE_VAR = (SELECT MAX(expected_from) FROM odw_standardised_db.hr_saphr)\")"
				],
				"execution_count": 43
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Fix Absence Hours in odw-standardised.hr_absences\n",
					"\n",
					"**Some absences might have incorrect number of hours. This cell calculates the absence hours between a `start_date` and `end_date` based on the `work_schedule_rule` of the Employee and updates the table**\n",
					"\n",
					"TODO: Update the vw_absences view instead of the hr_absences table to save execution time."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pandas as pd\n",
					"from pyspark.sql import SparkSession\n",
					"spark = SparkSession.builder.getOrCreate()\n",
					"\n",
					"def get_england_and_wales(data_frame):\n",
					"    return (\n",
					"        pd\n",
					"        .json_normalize(\n",
					"            data_frame.to_dict(),\n",
					"            record_path=[['england-and-wales', 'events']]\n",
					"        )\n",
					"        .astype({\n",
					"            'title': 'string',\n",
					"            'date': 'string',\n",
					"            'notes': 'string',\n",
					"            'bunting': 'bool'\n",
					"        })\n",
					"    )\n",
					"\n",
					"bank_holidays = pd.read_json(path_or_buf = 'https://www.gov.uk/bank-holidays.json')\n",
					"bh = get_england_and_wales(bank_holidays)\n",
					"\n",
					"storage_account=mssparkutils.notebook.run('/utils/py_utils_get_storage_account')\n",
					"include_bank_holidays = False\n",
					"\n",
					"def get_absence_hrs(days, original_hrs, start, end, ws):\n",
					"    ws = work_schedule[work_schedule[\"work_schedule_rule\"] == ws]\n",
					"    if len(ws) == 0:\n",
					"        return str(original_hrs)\n",
					"    if len(ws) > 1:\n",
					"        ws = ws.iloc[0]\n",
					"    \n",
					"    sum = 0\n",
					"\n",
					"    try:\n",
					"        for d in pd.bdate_range(start, end):\n",
					"            day_short_name = d.day_name()[0:2]\n",
					"            hrs = float(ws[day_short_name.lower()])\n",
					"            if str(d)[:10] in bh['date'].values:\n",
					"                if include_bank_holidays:\n",
					"                    sum += hrs\n",
					"            else:\n",
					"                sum += days*hrs if days < 1 else hrs\n",
					"    except:\n",
					"        return str(original_hrs)\n",
					"\n",
					"    return str(sum)\n",
					"\n",
					"absences_table = 'odw_standardised_db.hr_absences'\n",
					"absences_table_loc = \"abfss://odw-standardised@\" + storage_account+'HR/hr_absences'\n",
					"\n",
					"# getting the closest expected_from date in the table based on the expected_from parameter\n",
					"if expected_from != '':\n",
					"    absences_expected_from = spark.sql(f\"SELECT expected_from FROM {absences_table} as table_alias WHERE table_alias.expected_from <= '{expected_from}' ORDER BY table_alias.expected_from DESC LIMIT 1;\")\n",
					"else:\n",
					"    absences_expected_from = spark.sql(f\"SELECT MAX(expected_from) FROM {absences_table}\")\n",
					"try:\n",
					"    absences_expected_from = absences_expected_from.first()[0]\n",
					"except:\n",
					"    absences_expected_from = ''\n",
					"\n",
					"work_schedule = spark.read.format('delta').load(\"abfss://odw-standardised@\" + storage_account+'HR/hr_work_schedule_rule').toPandas()\n",
					"absences = spark.sql(f\"select * from {absences_table} where cast(expected_from as Date) = '{absences_expected_from}'\").toPandas()\n",
					"\n",
					"if(len(absences) > 0):\n",
					"    for i, row in absences.iterrows():\n",
					"        absences.at[i, 'hrs'] = get_absence_hrs(float(row['days']), float(row['hrs']), row['start_date'], row['end_date'], row['work_schedule_rule'])\n",
					"\n",
					"    absencesDF = spark.createDataFrame(absences)\n",
					"    absencesDF.write.format(\"delta\").mode(\"overwrite\").option(\"replaceWhere\", f\"cast(expected_from as Date) = '{absences_expected_from}'\").save(absences_table_loc)"
				],
				"execution_count": 21
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Creates a view odw_standardised_db.vw_absences_temp \n",
					"#### Creates the view with a column RN (Row Number) to be able to select non-duplicates. This is a temporary view and will be deleted after being utilised in the harmonised layer"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_absences_temp\n",
					"\n",
					"AS\n",
					"\n",
					"SELECT  \n",
					"    *,\n",
					"    ROW_NUMBER() OVER (PARTITION BY Staff_Number, Start_Date ORDER BY Staff_Number) AS RN\n",
					"\n",
					"FROM odw_standardised_db.hr_absences\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": 37
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_absences\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT \r\n",
					"    CASE \r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 5\r\n",
					"        THEN CONCAT('00',Staff_Number)\r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 4\r\n",
					"        THEN CONCAT('50',Staff_Number)        \r\n",
					"        ELSE Staff_Number\r\n",
					"    END as Staff_Number,\r\n",
					"    Abs_Type,\r\n",
					"    Sickness_Group,\r\n",
					"    to_timestamp(Start_Date) AS Start_Date,\r\n",
					"    to_timestamp(End_Date) AS End_Date,\r\n",
					"    Attendance_or_Absence_Type,\r\n",
					"    Days,\r\n",
					"    Hrs,\r\n",
					"    Start,\r\n",
					"    End_time,\r\n",
					"    Cal_days,\r\n",
					"    Work_Schedule_Rule,\r\n",
					"    Wk_Hrs,\r\n",
					"    Hrs_Day,\r\n",
					"    WkDys,\r\n",
					"    to_timestamp(Annual_Leave_Start) AS Annual_Leave_Start, \r\n",
					"    ingested_datetime,\r\n",
					"    expected_from,\r\n",
					"    expected_to\r\n",
					"\r\n",
					"FROM odw_standardised_db.vw_absences_temp\r\n",
					"WHERE RN = 1;"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Creates a view odw_standardised_db.hr_addresses_temp \n",
					"#### Creates the view with a column RN (Row Number) to be able to select non-duplicates. This is a temporary view and will be deleted after being utilised in the harmonised layer"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					}
				},
				"source": [
					"%%sql\n",
					"\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.hr_addresses_temp\n",
					"\n",
					"AS\n",
					"\n",
					"SELECT  \n",
					"    *,\n",
					"    ROW_NUMBER() OVER (PARTITION BY Staff_Number ORDER BY Staff_Number) AS RN\n",
					"\n",
					"FROM odw_standardised_db.hr_addresses\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_addresses\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT \r\n",
					"    CASE \r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 5\r\n",
					"        THEN CONCAT('00',Staff_Number)\r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 4\r\n",
					"        THEN CONCAT('50',Staff_Number)        \r\n",
					"        ELSE Staff_Number\r\n",
					"    END as Staff_Number,\r\n",
					"    Street_and_House_Number,\r\n",
					"    `2nd_Address_Line`,\r\n",
					"    City,\r\n",
					"    District,\r\n",
					"    Postal_Code,\r\n",
					"    Region_State_Province_Count,\r\n",
					"    to_timestamp(Start_Date) AS Start_Date,\r\n",
					"    to_timestamp(End_Date) AS End_Date,\r\n",
					"    Charting_Officer,\r\n",
					"    Charting_Officer_for_Inspector,\r\n",
					"    Subs_PS_Group,\r\n",
					"    Tel_No,\r\n",
					"    Personal_Mobile,\r\n",
					"    Work_Mobile,\r\n",
					"    to_timestamp(Chngd_on) AS Chngd_on,\r\n",
					"    ingested_datetime,\r\n",
					"    expected_from,\r\n",
					"    expected_to\r\n",
					"\r\n",
					"FROM odw_standardised_db.hr_addresses_temp\r\n",
					"WHERE RN = 1;"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Creates a view odw_standardised_db.hr_email_temp \n",
					"#### Creates the view with a column RN (Row Number) to be able to select non-duplicates. This is a temporary view and will be deleted after being utilised in the harmonised layer"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					}
				},
				"source": [
					"%%sql\n",
					"\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.hr_email_temp\n",
					"\n",
					"AS\n",
					"\n",
					"SELECT  \n",
					"    *,\n",
					"    ROW_NUMBER() OVER (PARTITION BY Staff_Number ORDER BY Staff_Number) AS RN\n",
					"\n",
					"FROM odw_standardised_db.hr_email\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_email\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT \r\n",
					"    CASE \r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 5\r\n",
					"        THEN CONCAT('00',Staff_Number)\r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 4\r\n",
					"        THEN CONCAT('50',Staff_Number)        \r\n",
					"        ELSE Staff_Number\r\n",
					"    END as Staff_Number,\r\n",
					"    first_name,\r\n",
					"    last_name,\r\n",
					"    email_address,\r\n",
					"    text_line_manager,\r\n",
					"    lm_e_mail,\r\n",
					"    ingested_datetime,\r\n",
					"    expected_from,\r\n",
					"    expected_to\r\n",
					"\r\n",
					"FROM odw_standardised_db.hr_email_temp\r\n",
					"WHERE RN = 1"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_leave\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT \r\n",
					"    CASE \r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 5\r\n",
					"        THEN CONCAT('00',Staff_Number)\r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 4\r\n",
					"        THEN CONCAT('50',Staff_Number)        \r\n",
					"        ELSE Staff_Number\r\n",
					"    END as Staff_Number,\r\n",
					"    number,\r\n",
					"    deduction,\r\n",
					"    to_timestamp(ded_from) AS ded_from,\r\n",
					"    to_timestamp(ded_to) AS ded_to,\r\n",
					"    absence_quota_type,\r\n",
					"    ingested_datetime,\r\n",
					"    expected_from,\r\n",
					"    expected_to\r\n",
					"\r\n",
					"FROM odw_standardised_db.hr_leave\r\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Creates a view odw_standardised_db.vw_leavers_temp \n",
					"#### Creates the view with a column RN (Row Number) to be able to select non-duplicates. This is a temporary view and will be deleted after being utilised in the harmonised layer"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_leavers_temp \n",
					"\n",
					"AS\n",
					"\n",
					"SELECT  \n",
					"    *,\n",
					"    ROW_NUMBER() OVER (PARTITION BY Pers_No, Leaving ORDER BY Pers_No) AS RN\n",
					"\n",
					"FROM odw_standardised_db.hr_leavers\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \n",
					"\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_leavers\n",
					"\n",
					"AS\n",
					"\n",
					"SELECT \n",
					"    CASE \n",
					"        WHEN LENGTH(Pers_No) = 6 AND SUBSTR(Pers_No,1,1) = 5\n",
					"        THEN CONCAT('00',Pers_No)\n",
					"        WHEN LENGTH(Pers_No) = 6 AND SUBSTR(Pers_No,1,1) = 4\n",
					"        THEN CONCAT('50',Pers_No)        \n",
					"        ELSE Pers_No\n",
					"    END as Pers_No,\n",
					"    Last_name,\n",
					"    First_name,\n",
					"    CoCd,\n",
					"    Company_Code,\n",
					"    Loc,\n",
					"    Location,\n",
					"    PS_group,\n",
					"    Pay_Band_Description,\n",
					"    Org_unit,\n",
					"    Organizational_Unit,\n",
					"    PA,\n",
					"    Personnel_Area,\n",
					"    Personnel_Subarea,\n",
					"    WorkC,\n",
					"    Work_Contract,\n",
					"    to_timestamp(Org_Start_Date) AS Org_Start_Date,\n",
					"    Leaving,\n",
					"    Act,\n",
					"    Action_Type,\n",
					"    ActR,\n",
					"    Reason_for_Action,\n",
					"    S,\n",
					"    Employment_Status,\n",
					"    Employee_No,\n",
					"    Position,\n",
					"    Position_1,\n",
					"    Annual_salary,\n",
					"    Curr,\n",
					"    User_ID,\n",
					"    Email_Address,\n",
					"    Pers_No_1,\n",
					"    Name_of_Manager_OM,\n",
					"    Manager_Position,\n",
					"    MAnager_Position_Text,\n",
					"    LM_E_mail,\n",
					"    ingested_datetime,\n",
					"    expected_from,\n",
					"    expected_to\n",
					"\n",
					"FROM odw_standardised_db.vw_leavers_temp\n",
					"WHERE RN = 1;"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_protected_characteristics\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT \r\n",
					"    ref_no,\r\n",
					"    ethnic_origin,\r\n",
					"    religious_denomination_key,\r\n",
					"    sxo,\r\n",
					"    disability_text,\r\n",
					"    disability_code_description,\r\n",
					"    disabled,\r\n",
					"    ethnicity,\r\n",
					"    religion,\r\n",
					"    sexual_orientation,\r\n",
					"    grade\r\n",
					"    ingested_datetime,\r\n",
					"    expected_from,\r\n",
					"    expected_to\r\n",
					"\r\n",
					"FROM odw_standardised_db.hr_protected_characteristics T1\r\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_saphr\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT \r\n",
					"    CASE \r\n",
					"        WHEN LENGTH(Pers_No) = 6 AND SUBSTR(Pers_No,1,1) = 5\r\n",
					"        THEN CONCAT('00',Pers_No)\r\n",
					"        WHEN LENGTH(Pers_No) = 6 AND SUBSTR(Pers_No,1,1) = 4\r\n",
					"        THEN CONCAT('50',Pers_No)        \r\n",
					"        ELSE Pers_No\r\n",
					"    END as Pers_No,\r\n",
					"    First_name,\r\n",
					"    Last_name,\r\n",
					"    Employee_No,\r\n",
					"    CoCd,\r\n",
					"    Company_Code,\r\n",
					"    PA,\r\n",
					"    Personnel_Area,\r\n",
					"    PSubarea,\r\n",
					"    Personnel_Subarea,\r\n",
					"    Org_Unit,\r\n",
					"    Organizational_Unit,\r\n",
					"    Organizational_key1,\r\n",
					"    Organizational_key2,\r\n",
					"    WorkC,\r\n",
					"    Work_Contract,\r\n",
					"    CT,\r\n",
					"    Contract_Type,\r\n",
					"    PS_Group,\r\n",
					"    Pay_Band_Description,\r\n",
					"    FTE,\r\n",
					"    Wk_hrs,\r\n",
					"    Indicator_Part_Time_Employee,\r\n",
					"    S,\r\n",
					"    Employment_Status,\r\n",
					"    Gender_Key,\r\n",
					"    to_timestamp(TRA_Start_Date) AS TRA_Start_Date,\r\n",
					"    to_timestamp(TRA_End_Date) AS TRA_End_Date,\r\n",
					"    TRA_Status,\r\n",
					"    TRA_Grade,\r\n",
					"    Prev_PersNo,\r\n",
					"    ActR,\r\n",
					"    Reason_for_Action,\r\n",
					"    Position,\r\n",
					"    Position_1,\r\n",
					"    Cost_Ctr,\r\n",
					"    Cost_Centre,\r\n",
					"    to_timestamp(Civil_Service_Start) AS Civil_Service_Start,\r\n",
					"    to_timestamp(Date_to_Current_Job) AS Date_to_Current_Job,\r\n",
					"    to_timestamp(Seniority_Date) AS Seniority_Date,\r\n",
					"    to_timestamp(Date_to_Subst_Grade) AS Date_to_Subst_Grade,\r\n",
					"    Pers_No_1,\r\n",
					"    Name_of_Manager_OM,\r\n",
					"    Manager_Position,\r\n",
					"    Manager_Position_Text,\r\n",
					"    Counter_Sign_Manager,\r\n",
					"    Loc,\r\n",
					"    Location,\r\n",
					"    to_timestamp(Org_Start_Date) AS Org_Start_Date,\r\n",
					"    to_timestamp(Fix_Term_End_Date) AS Fix_Term_End_Date,\r\n",
					"    to_timestamp(Loan_Start_Date) AS Loan_Start_Date,\r\n",
					"    to_timestamp(Loan_End_Date) AS Loan_End_Date,\r\n",
					"    EEGrp,\r\n",
					"    Employee_Group,\r\n",
					"    Annual_salary,\r\n",
					"    Curr,\r\n",
					"    NI_number,\r\n",
					"    Birth_date,\r\n",
					"    Age_of_employee,\r\n",
					"    EO,\r\n",
					"    Ethnic_origin,\r\n",
					"    NID,\r\n",
					"    Rel,\r\n",
					"    Religious_Denomination_Key,\r\n",
					"    SxO,\r\n",
					"    Wage_Type,\r\n",
					"    Employee_Subgroup,\r\n",
					"    LOA_Abs_Type,\r\n",
					"    LOA_Absence_Type_Text,\r\n",
					"    Scheme_reference,\r\n",
					"    Pension_Scheme_Name,\r\n",
					"    Disability_Code,\r\n",
					"    Disability_Text,\r\n",
					"    Disability_Code_Description,\r\n",
					"    PArea,\r\n",
					"    Payroll_Area,\r\n",
					"    Assignment_Number,\r\n",
					"    FTE_2,\r\n",
					"    ingested_datetime,\r\n",
					"    expected_from,\r\n",
					"    expected_to\r\n",
					"\r\n",
					"FROM odw_standardised_db.hr_saphr\r\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_specialisms\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT \r\n",
					"    CASE \r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 5\r\n",
					"        THEN CONCAT('00',Staff_Number)\r\n",
					"        WHEN LENGTH(Staff_Number) = 6 AND SUBSTR(Staff_Number,1,1) = 4\r\n",
					"        THEN CONCAT('50',Staff_Number)        \r\n",
					"        ELSE Staff_Number\r\n",
					"    END as Staff_Number,\r\n",
					"    first_name,\r\n",
					"    last_name,\r\n",
					"    qualification_name,\r\n",
					"    proficien,\r\n",
					"    ingested_datetime,\r\n",
					"    expected_from,\r\n",
					"    expected_to\r\n",
					"\r\n",
					"FROM odw_standardised_db.hr_specialisms\r\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			}
		]
	}
}