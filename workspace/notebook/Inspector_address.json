{
	"name": "Inspector_address",
	"properties": {
		"folder": {
			"name": "odw-harmonised"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "a05d5efd-0628-4633-a637-97130f19e7a1"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Entity Name : Inspector Address \n",
					"### Author: Prathap A\n",
					"### Date: 25/02/2025\n",
					"\n",
					"#### version : 0001\n",
					"\n",
					"###### <u>Description</u>:\n",
					"This template is designed to facilitate the monthly processing and harmonization of Inspector Address data. It includes steps for initializing the environment, creating and managing Delta tables, and inserting data into harmonized tables. The template ensures that Inspector Address  is accurately transformed, stored, and made available for reporting and analysis."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Intialisations"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import udf, col, lit, when, coalesce, concat, sum, avg, max, min, count, countDistinct, date_format, to_date, datediff, months_between, year, month,  hour, minute, second, expr, asc, desc\n",
					"from pyspark.sql.types import DateType, TimestampType, StringType, IntegerType, FloatType, DoubleType, BooleanType, StructType, StructField, ArrayType, MapType\n",
					"from pyspark.sql.window import Window\n",
					"from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead, ntile\n",
					"from pyspark.sql import SQLContext\n",
					"from pyspark.sql import DataFrame\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.avro.functions import from_avro, to_avro\n",
					"from pyspark.sql.streaming import DataStreamReader, DataStreamWriter\n",
					"from pyspark.sql.utils import AnalysisException\n",
					"from pyspark.sql.catalog import Catalog\n",
					"from pyspark.sql.column import Column\n",
					"from pyspark.sql.group import GroupedData\n",
					"from pyspark.sql.pandas.functions import pandas_udf\n",
					"\n",
					"from datetime import datetime, timedelta\n",
					"import pandas as pd\n",
					"import numpy as np"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"ALTER TABLE odw_harmonised_db.inspector_address SET TBLPROPERTIES (\n",
					"   'delta.columnMapping.mode' = 'name',\n",
					"   'delta.minReaderVersion' = '2',\n",
					"   'delta.minWriterVersion' = '5')"
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.types import DateType\n",
					"\n",
					"# Set legacy time parser policy\n",
					"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
					"\n",
					"# Load data from the source table\n",
					"source_df = spark.table(\"odw_standardised_db.inspector_addresses_monthly\")\n",
					"\n",
					"# Transform the data\n",
					"transformed_df = source_df.select(\n",
					"    F.col(\"StaffNumber\"),\n",
					"    F.col(\"StreetandHouseNumber\"),\n",
					"    F.col(\"2ndAddressLine\"),\n",
					"    F.col(\"City\"),\n",
					"    F.col(\"District\"),\n",
					"    F.col(\"PostalCode\"),\n",
					"    F.col(\"RegionStateProvinceCount\"),\n",
					"    F.to_timestamp(F.col(\"StartDate\"), \"M/d/yy\").alias(\"StartDate\"),  # Cast to DateType\n",
					"    F.to_timestamp(F.col(\"EndDate\"), \"M/d/yy\").alias(\"EndDate\"),      # Cast to DateType\n",
					"    F.col(\"ChartingOfficer\"),\n",
					"    F.col(\"ChartingOfficerforInspector\"),\n",
					"    F.col(\"SubsPSgroup\"),\n",
					"    F.col(\"TelNo\"),\n",
					"    F.col(\"PersonalMobile\"),\n",
					"    F.col(\"WorkMobile\"),\n",
					"    F.to_timestamp(F.col(\"Chngdon\"), \"M/d/yy\").alias(\"Chngdon\"),      # Cast to DateType\n",
					"    F.lit(\"saphr\").alias(\"SourceSystemID\"),\n",
					"    F.current_timestamp().alias(\"IngestionDate\"),\n",
					"    F.current_timestamp().alias(\"ValidTo\"),\n",
					"    F.lit(None).cast(\"string\").alias(\"RowID\"),\n",
					"    F.lit(\"Y\").alias(\"IsActive\")\n",
					")\n",
					"\n",
					"# Overwrite the target table with the transformed data\n",
					"transformed_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"odw_harmonised_db.inspector_address\")"
				],
				"execution_count": 68
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"drop table odw_harmonised_db.sap_hr_inspector_address"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"display(transformed_df)"
				],
				"execution_count": 69
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Data Load into inspector_address"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"editable": true,
					"run_control": {
						"frozen": false
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"SET spark.sql.legacy.timeParserPolicy = LEGACY;\n",
					"\n",
					"delete from odw_harmonised_db.sap_hr_inspector_address ;\n",
					"\n",
					"-- Insert new data into the table\n",
					"INSERT INTO odw_harmonised_db.sap_hr_inspector_address \n",
					"(\n",
					"    StaffNumber,\n",
					"    StreetandHouseNumber,\n",
					"    2ndAddressLine,\n",
					"    City,\n",
					"    District,\n",
					"    PostalCode,\n",
					"    RegionStateProvinceCount,\n",
					"    StartDate,\n",
					"    EndDate,\n",
					"    ChartingOfficer,\n",
					"    ChartingOfficerforInspector,\n",
					"    SubsPSgroup,\n",
					"    TelNo,\n",
					"    PersonalMobile,\n",
					"    WorkMobile,\n",
					"    Chngdon,\n",
					"    SourceSystemID,\n",
					"    IngestionDate,\n",
					"    ValidTo,\n",
					"    RowID,\n",
					"    IsActive\n",
					")\n",
					"SELECT \n",
					"    StaffNumber,\n",
					"    StreetandHouseNumber,\n",
					"    2ndAddressLine,\n",
					"    City,\n",
					"    District,\n",
					"    PostalCode,\n",
					"    RegionStateProvinceCount,\n",
					"    \n",
					"TO_DATE(StartDate, 'M/d/yy') as  StartDate,\n",
					"TO_DATE(EndDate, 'M/d/yy') as  StartDate,    \n",
					"\n",
					"    ChartingOfficer,\n",
					"    ChartingOfficerforInspector,\n",
					"    SubsPSgroup,\n",
					"    TelNo,\n",
					"    PersonalMobile,\n",
					"    WorkMobile,\n",
					"   \n",
					"    TO_DATE(Chngdon, 'M/d/yy') as Chngdon,\n",
					"    'saphr' as SourceSystemID,\n",
					"    current_timestamp() as IngestionDate,\n",
					"    current_date() as ValidTo,\n",
					"    NULL AS RowID ,\n",
					"    'Y' as IsActive\n",
					"FROM odw_standardised_db.inspector_addresses_monthly;"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# HashKey build"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"UPDATE odw_harmonised_db.sap_hr_inspector_address \n",
					"SET RowID = md5(\n",
					"    concat_ws('|',\n",
					"        StaffNumber,\n",
					"        StreetandHouseNumber,\n",
					"        2ndAddressLine,\n",
					"        City,\n",
					"        District,\n",
					"        PostalCode,\n",
					"        RegionStateProvinceCount,\n",
					"        StartDate,\n",
					"        EndDate,\n",
					"        ChartingOfficer,\n",
					"        ChartingOfficerforInspector,\n",
					"        --SubSSPgroup,\n",
					"        TelNo,\n",
					"        PersonalMobile,\n",
					"        WorkMobile,\n",
					"        Chngdon\n",
					"    )\n",
					")"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"select * from odw_harmonised_db.sap_hr_inspector_address "
				],
				"execution_count": 1
			}
		]
	}
}