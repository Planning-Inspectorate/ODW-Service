{
	"name": "service-user-publish",
	"properties": {
		"folder": {
			"name": "odw-esb"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "a1e1cc88-e578-471e-8585-dbbb415daf73"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Service-User Publish\n",
					"Checks the Service Bus for topics last accessed timestamp, gets all changes from the Change Data Feed and sends each record to the service bus topic. \n",
					"See https://learn.microsoft.com/en-us/samples/azure/azure-sdk-for-python/servicebus-samples/ for servicebus samples\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\n",
					"import pandas as pd\n",
					"\n",
					"def get_topic_accessed_at(servicebus_mgmt_client):\n",
					"    get_topic_runtime_properties = servicebus_mgmt_client.get_topic_runtime_properties(topic_name)\n",
					"    return(get_topic_runtime_properties.accessed_at_utc)    \n",
					"\n",
					"def send_single_message(sender,content,custom_props_attributes):\n",
					"    json_dict = json.loads(content)\n",
					"    custom_props = { key: json_dict[key] for key in json_dict if key in custom_props_attributes}\n",
					"    message = ServiceBusMessage(content,content_type='application/json',application_properties=custom_props)\n",
					"    sender.send_messages(message)\n",
					"\n",
					"def add_single_message(sender,content,custom_props_attributes):\n",
					"    json_dict = json.loads(content)\n",
					"    custom_props = { key: json_dict[key] for key in json_dict if key in custom_props_attributes}\n",
					"    message = ServiceBusMessage(content,content_type='application/json',application_properties=custom_props)\n",
					"    batch_message.add_message(message)\n",
					"\n",
					"def publish_full_message(msg):\n",
					"    from azure.servicebus import ServiceBusClient, ServiceBusMessage\n",
					"    servicebus_client = ServiceBusClient.from_connection_string(conn_str=conn_str, logging_enable=True)\n",
					"    try:\n",
					"        with servicebus_client:\n",
					"            sender = servicebus_client.get_topic_sender(topic_name=topic_name)\n",
					"            with sender:\n",
					"                message = ServiceBusMessage(msg)\n",
					"                sender.send_messages(message)\n",
					"    except Exception as e:  \n",
					"            print(f\"{e}\") \n",
					""
				],
				"execution_count": 79
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Sets the notebook variables"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"secret_name=\"servicebus-connectionstring\"\n",
					"kv_linked_service=\"ls_kv\"\n",
					"topic_name=\"service-user\"\n",
					"table_name=\"odw_curated_db.service_user\"\n",
					"custom_props_attributes=[\"_change_type\"]"
				],
				"execution_count": 80
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Get Servicebus connectionstring from Key Vault"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql import SparkSession\n",
					"spark = SparkSession.builder.getOrCreate()\n",
					"akv_name=spark.sparkContext.environment.get('keyVaultName', 'get')\n",
					"from notebookutils import mssparkutils\n",
					"conn_str = mssparkutils.credentials.getSecret(akv_name, secret_name, kv_linked_service)\n",
					""
				],
				"execution_count": 81
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Get Topic Accessed At timestamp"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from azure.servicebus.management import ServiceBusAdministrationClient\n",
					"with ServiceBusAdministrationClient.from_connection_string(conn_str) as servicebus_mgmt_client:\n",
					"    topic_accessed_at=get_topic_accessed_at(servicebus_mgmt_client)\n",
					"print(topic_accessed_at)"
				],
				"execution_count": 82
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Get the latest changes from CDF and send split messages by lines"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# from azure.servicebus import ServiceBusClient, ServiceBusMessage\n",
					"# servicebus_client = ServiceBusClient.from_connection_string(conn_str=conn_str, logging_enable=True)\n",
					"\n",
					"# try:\n",
					"#     cdf_df=(spark.read.format(\"delta\")\n",
					"#         .table(table_name))\n",
					"#     with servicebus_client:\n",
					"#         sender = servicebus_client.get_topic_sender(topic_name=topic_name)\n",
					"#         with sender:\n",
					"#             df_json = cdf_df.toJSON()\n",
					"#             row_count=df_json.count()\n",
					"#             for row in df_json.collect(): \n",
					"#                 send_single_message(sender,row,custom_props_attributes)\n",
					"#             print(\"Sent {} messages.\".format(row_count))\n",
					"\n",
					"# except Exception as e:  \n",
					"#         print(f\"{e}\") "
				],
				"execution_count": 83
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Get the latest changes from CDF and send the file in one message"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import json\n",
					"\n",
					"df = spark.sql(f\"SELECT * FROM {table_name}\")\n",
					"json_data = df.toPandas().to_json(orient='records')\n",
					"publish_full_message(json_data)\n",
					""
				],
				"execution_count": 84
			}
		]
	}
}