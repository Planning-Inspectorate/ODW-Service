{
	"name": "sap-hr-views-leavers",
	"properties": {
		"folder": {
			"name": "odw-harmonised/SAP-HR"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw34",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "0119111c-82c3-4fe3-813f-9e19494fb937"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw34",
				"name": "pinssynspodw34",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw34",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 32,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"expected_from=''"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**The expected_from parameter above is the month which we want to ingest. For example, if we want data from January 2023, we can query this data from standardised by setting the expected_from as the start of next month (February)**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"if expected_from != '':\n",
					"    spark.sql(f\"SET DATE_VAR = '{expected_from}'\")\n",
					"else:\n",
					"    spark.sql(f\"SET DATE_VAR = (SELECT MAX(expected_from) FROM odw_standardised_db.hr_saphr)\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Creates a view odw_standardised_db.vw_leavers_temp \n",
					"#### Creates the view with a column RN (Row Number) to be able to select non-duplicates. This is a temporary view and will be deleted after being utilised in the harmonised layer"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_leavers_temp \n",
					"\n",
					"AS\n",
					"\n",
					"SELECT  \n",
					"    *,\n",
					"    ROW_NUMBER() OVER (PARTITION BY Pers_No, Leaving ORDER BY Pers_No) AS RN\n",
					"\n",
					"FROM odw_standardised_db.hr_leavers\n",
					"WHERE expected_from = ${DATE_VAR}"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql   \n",
					"\n",
					"CREATE OR REPLACE VIEW odw_standardised_db.vw_leavers\n",
					"\n",
					"AS\n",
					"\n",
					"SELECT \n",
					"    CASE \n",
					"        WHEN LENGTH(Pers_No) = 6 AND SUBSTR(Pers_No,1,1) = 5\n",
					"        THEN CONCAT('00',Pers_No)\n",
					"        WHEN LENGTH(Pers_No) = 6 AND SUBSTR(Pers_No,1,1) = 4\n",
					"        THEN CONCAT('50',Pers_No)        \n",
					"        ELSE Pers_No\n",
					"    END as Pers_No,\n",
					"    Last_name,\n",
					"    First_name,\n",
					"    CoCd,\n",
					"    Company_Code,\n",
					"    Loc,\n",
					"    Location,\n",
					"    PS_group,\n",
					"    Pay_Band_Description,\n",
					"    Org_unit,\n",
					"    Organizational_Unit,\n",
					"    PA,\n",
					"    Personnel_Area,\n",
					"    Personnel_Subarea,\n",
					"    WorkC,\n",
					"    Work_Contract,\n",
					"    to_timestamp(Org_Start_Date) AS Org_Start_Date,\n",
					"    Leaving,\n",
					"    Act,\n",
					"    Action_Type,\n",
					"    ActR,\n",
					"    Reason_for_Action,\n",
					"    S,\n",
					"    Employment_Status,\n",
					"    Employee_No,\n",
					"    Position,\n",
					"    Position_1,\n",
					"    Annual_salary,\n",
					"    Curr,\n",
					"    User_ID,\n",
					"    Email_Address,\n",
					"    Pers_No_1,\n",
					"    Name_of_Manager_OM,\n",
					"    Manager_Position,\n",
					"    MAnager_Position_Text,\n",
					"    LM_E_mail,\n",
					"    ingested_datetime,\n",
					"    expected_from,\n",
					"    expected_to\n",
					"\n",
					"FROM odw_standardised_db.vw_leavers_temp\n",
					"WHERE RN = 1;"
				],
				"execution_count": null
			}
		]
	}
}