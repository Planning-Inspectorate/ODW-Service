{
	"name": "py_utils_data_validation_functions",
	"properties": {
		"folder": {
			"name": "archive/utils/data-validation"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw34",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "31deb021-4192-41c8-a5f0-3befe055e956"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw34",
				"name": "pinssynspodw34",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw34",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 32,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Data validation functions notebook  \r\n",
					"\r\n",
					"This notebook contains variables and functions that are imported and used in the py_utils_data_validation_final notebook. \r\n",
					"\r\n",
					"This notebook contains no imports so will not run on its own.  \r\n",
					"\r\n",
					"Any new global variables or new functions for data validation can be created here and then used in the other notebook."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Set global variables"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"account_name = 'pinsstodwdevuks9h80mb'\r\n",
					"container_name = 'odw-config'\r\n",
					"jobId = mssparkutils.env.getJobId()\r\n",
					"data_validation_relative_path = \"data_validation\"\r\n",
					"test_results_relative_path = \"/outputs/test_results/\"\r\n",
					"test_results_file_name = \"test_results.csv\"\r\n",
					"data_validation_json_files = [\"test_results_dict\", \"table_mapping\", \"table_keys\"]\r\n",
					"akv_name = 'pinskvsynwodwdevuks'\r\n",
					"secret_name = 'sql-mipins-password'\r\n",
					"kv_linked_service = 'ls_kv'\r\n",
					"source_password = mssparkutils.credentials.getSecret(akv_name, secret_name, kv_linked_service)\r\n",
					"source_servername = \"jdbc:sqlserver://pins-prod-pdac-sql.database.windows.net:1433\"\r\n",
					"source_dbname = \"MiPINS-PRD-ISS\"\r\n",
					"source_url = source_servername + \";\" + \"databaseName=\" + source_dbname + \";\"\r\n",
					"source_user = \"kincarta\"\r\n",
					"target_database = 'odw_curated_db'\r\n",
					"mount_path = f'synfs:/{jobId}/data_validation'"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to create adls path"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def create_adls_path(account_name: str, container_name: str, relative_path: str):\r\n",
					"    '''\r\n",
					"    Function to create the path to Azure Data Lake Storage\r\n",
					"    '''\r\n",
					"    file_path = f'abfss://{container_name}@{account_name}.dfs.core.windows.net/{relative_path}'\r\n",
					"    return file_path"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Mount storage to work with json files as python dictionaries rather than use spark or pandas DataFrames"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run /utils/py_mount_storage"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def mount_storage(relative_path: str, jobId):\r\n",
					"    '''\r\n",
					"    Function to mount the storage path\r\n",
					"    '''\r\n",
					"    path = create_adls_path(account_name, container_name, relative_path)\r\n",
					"    mount_storage(path=path, mount_point=relative_path)\r\n",
					"\r\n",
					"    spark_fs_path = f\"synfs:/{jobId}/{relative_path}\"\r\n",
					"    local_fs_path = f\"/synfs/{jobId}/{relative_path}\""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Mount the storage path"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mount_storage(data_validation_relative_path, jobId)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Set the json reference files in storage to dictionaries to work with"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def load_json_file_to_dict(json_file: str, jobId):\r\n",
					"    '''\r\n",
					"    Function to load a json file to a dictionary\r\n",
					"    '''\r\n",
					"    json_path = f\"/synfs/{jobId}/{data_validation_relative_path}/{json_file}.json\"\r\n",
					"    # print(f\"json path: {json_path}\")\r\n",
					"    with open(f'{json_path}', \"r\", encoding=\"utf-8\") as data:\r\n",
					"        json_file_dict = json.load(data)\r\n",
					"\r\n",
					"    return json_file_dict"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Load the json reference files to a dictionary"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"json_file_dicts = {}\r\n",
					"for json_file in data_validation_json_files:\r\n",
					"    json_dict = load_json_file_to_dict(json_file=json_file, jobId=jobId)\r\n",
					"    json_file_dicts[json_file] = json_dict\r\n",
					"\r\n",
					"table_mapping = json_file_dicts[\"table_mapping\"]\r\n",
					"test_results_dict = json_file_dicts[\"test_results_dict\"]\r\n",
					"table_keys = json_file_dicts[\"table_keys\"]"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to define target dataset"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def targetdataset(target_database: str, target_dbtable: str):\r\n",
					"    '''\r\n",
					"    Function to define the target dataset\r\n",
					"    '''\r\n",
					"    query = f\"SELECT * FROM `{target_database}`.`{target_dbtable}`\"\r\n",
					"    target_df = spark.sql(query)\r\n",
					"    target_df = target_df.toPandas()\r\n",
					"\r\n",
					"    return target_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to define source dataset"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def sourcedataset(source_dbtable: str):\r\n",
					"        '''\r\n",
					"        Function to define the source dataset\r\n",
					"        '''\r\n",
					"        sourceData = spark.read \\\r\n",
					"                .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n",
					"                .option(\"url\", source_url) \\\r\n",
					"                .option(\"dbtable\", source_dbtable) \\\r\n",
					"                .option(\"user\", source_user) \\\r\n",
					"                .option(\"password\", source_password).load()\r\n",
					"\r\n",
					"        source_df = sourceData.toPandas()\r\n",
					"\r\n",
					"        return source_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test1_rows_in_source_not_in_target"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test1_rows_in_source_not_in_target(test_source_df, test_target_df) -> bool:\r\n",
					"    '''\r\n",
					"    Function to return True or False for whether rows exist in the source dataset but not in the target dataset\r\n",
					"    '''\r\n",
					"    result_df = test_source_df[~test_source_df.index.isin(test_target_df.index)]\r\n",
					"    if len(result_df) > 0:\r\n",
					"        result = True\r\n",
					"    else:\r\n",
					"        result = False\r\n",
					"    return result"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test1_export_values"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test1_export_values(test_source_df, test_target_df):\r\n",
					"    '''\r\n",
					"    Function to return the rows that exist in the source dataset but not in the target dataset\r\n",
					"    '''\r\n",
					"    result_df = test_source_df[~test_source_df.index.isin(test_target_df.index)]\r\n",
					"    if len(result_df) > 0:\r\n",
					"        return result_df\r\n",
					"    else:\r\n",
					"        pass"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test2_rows_in_target_not_in_source"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test2_rows_in_target_not_in_source(test_source_df, test_target_df) -> bool:\r\n",
					"    '''\r\n",
					"    Function to return True or False for whether rows exist in the target dataset but not in the source dataset\r\n",
					"    '''\r\n",
					"    result_df = test_target_df[~test_target_df.index.isin(test_source_df.index)]\r\n",
					"    if len(result_df) > 0:\r\n",
					"        result = True\r\n",
					"    else:\r\n",
					"        result = False\r\n",
					"    return result"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test2_export_values"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test2_export_values(test_source_df, test_target_df):\r\n",
					"    '''\r\n",
					"    Function to return the rows that exist in the target dataset but not in the source dataset\r\n",
					"    '''\r\n",
					"    result_df = test_target_df[~test_target_df.index.isin(test_source_df.index)]\r\n",
					"    if len(result_df) > 0:\r\n",
					"        return result_df\r\n",
					"    else:\r\n",
					"        pass"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test3_count_source_table_rows"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test3_count_source_table_rows(test_source_df):\r\n",
					"    '''\r\n",
					"    Function to count the source table rows\r\n",
					"    '''\r\n",
					"    return len(test_source_df)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test4_count_target_table_rows"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test4_count_target_table_rows(test_target_df):\r\n",
					"    '''\r\n",
					"    Function to count the target table rows\r\n",
					"    '''\r\n",
					"    return len(test_target_df)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test5_count_source_table_columns"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test5_count_source_table_columns(test_source_df):\r\n",
					"    '''\r\n",
					"    Function to count the source table columns\r\n",
					"    '''\r\n",
					"    return len(test_source_df.columns)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test6_count_target_table_columns"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test6_count_target_table_columns(test_target_df):\r\n",
					"    '''\r\n",
					"    Function to count the target table columns\r\n",
					"    '''\r\n",
					"    return len(test_target_df.columns)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test7_duplicates_in_odw"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test7_duplicates_in_odw(test_target_df) -> bool:\r\n",
					"    '''\r\n",
					"    Function to check for duplicates in the target dataset. Returns True or False.\r\n",
					"    '''\r\n",
					"    duplicates_count = test_target_df.duplicated().sum()\r\n",
					"    if duplicates_count > 0:\r\n",
					"        duplicates = True\r\n",
					"    else:\r\n",
					"        duplicates = False\r\n",
					"\r\n",
					"    return duplicates"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test8_source_target_shape_match"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test8_source_target_shape_match(test_source_df, test_target_df) -> bool:\r\n",
					"    '''\r\n",
					"    Function to check if 2 pandas DataFrames match in shape. Returns True or False.\r\n",
					"    '''\r\n",
					"    if test_source_df.shape == test_target_df.shape:\r\n",
					"        shape_match = True\r\n",
					"    else:\r\n",
					"        shape_match = False\r\n",
					"    \r\n",
					"    return shape_match"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test9_values_mismatch"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test9_values_mismatch(df_compare) -> bool:\r\n",
					"    '''\r\n",
					"    Function to check if there are value differences between 2 pandas DataFrames. Returns True or False.\r\n",
					"    '''\r\n",
					"    if len(df_compare) > 0:\r\n",
					"        values_mismatch = True\r\n",
					"    else:\r\n",
					"        values_mismatch = False\r\n",
					"\r\n",
					"    return values_mismatch"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test10_count_values_mismatch"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test10_count_values_mismatch():\r\n",
					"    '''\r\n",
					"    Not yet defined.\r\n",
					"    Might be useful to show the number of records that are not matching.\r\n",
					"    Do we just use the records that are in both source and target for this?\r\n",
					"    '''"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### test11_values_match_percentage"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def test11_values_match_percentage():\r\n",
					"    '''\r\n",
					"    Not yet defined.\r\n",
					"    Might be useful to show the % accuracy of each table.\r\n",
					"    '''"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to add a new test to the test results dictionary\r\n",
					"\r\n",
					"Pass a test name into the function and it sets the test result initially to \"\" (empty string)"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def add_new_test_to_results_dict(test_name: str) -> None:\r\n",
					"    '''\r\n",
					"    Needs re-writing so the dictionary is saved to storage once a new test is added.\r\n",
					"    '''\r\n",
					"    # for k, v in test_results_dict.items():\r\n",
					"    #     value_dict = v\r\n",
					"    #     value_dict[test_name] = \"\""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to add a new source table to the test results dictionary\r\n",
					"\r\n",
					"Pass the name of the new source table into the function and it will get added to the test results dictionary with the same values as the other source tables"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def add_new_source_table_to_test_results_dict(new_source_table: str) -> None:\r\n",
					"    '''\r\n",
					"    Needs re-writing so the dictionary is saved to storage once a new test is added.\r\n",
					"    '''\r\n",
					"    # for k, v in test_results_dict.copy().items():\r\n",
					"    #     if new_source_table not in test_results_dict.keys():\r\n",
					"    #         test_results_dict[new_source_table] = v"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Write to storage account - spark DataFrame"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def write_to_storage(account_name: str, container_name: str, relative_path: str, data) -> None:\r\n",
					"    '''\r\n",
					"    Function that writes a spark DataFrame to storage as a csv file.\r\n",
					"    '''\r\n",
					"\r\n",
					"    path = create_adls_path(account_name, container_name, relative_path)\r\n",
					"\r\n",
					"    # Write spark dataframe as a csv file \r\n",
					"    print(\"adls path is \" + path)\r\n",
					"    data.write.csv(path, mode = 'overwrite', header = 'true', sep = \",\")\r\n",
					"\r\n",
					"# # Write spark dataframe as a parquet file \r\n",
					"# parquet_path = adls_path + ' Your file name ' \r\n",
					"# data.write.parquet(parquet_path, mode = 'overwrite') \r\n",
					"\r\n",
					"# # Write spark dataframe as a json file \r\n",
					"# json_path = adls_path + 'Your file name ' \r\n",
					"# data.write.json(json_path, mode = 'overwrite')"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to rename csv files"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def rename_csv_files(old_path: str, new_path: str) -> None:\r\n",
					"    '''\r\n",
					"    Function that renames a csv file. Pass in the old path and new path to rename it. \r\n",
					"    Uses mssparkutils.fs.mv\r\n",
					"    '''\r\n",
					"    # rename the file to a sensible name using the mssparkutils mv function\r\n",
					"    files = list(mssparkutils.fs.ls(old_path))\r\n",
					"    csv_files = [f for f in files if f.name.endswith('.csv')]\r\n",
					"    file_path = csv_files[0].path\r\n",
					"    mssparkutils.fs.mv(file_path, new_path)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to remove _SUCCESS files"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def remove_success_files(old_path: str, new_path: str) -> None:\r\n",
					"    '''\r\n",
					"    Function that removes the _SUCCESS file that is created when spark DataFrames are written to storage and partitioned.\r\n",
					"    Uses mssparkutils.fs.mv\r\n",
					"    '''\r\n",
					"    # delete the _SUCCESS file as it's not needed\r\n",
					"    files = list(mssparkutils.fs.ls(old_path))\r\n",
					"    success_files = [f for f in files if f.name.endswith('_SUCCESS')]\r\n",
					"    success_file_path = success_files[0].path\r\n",
					"    mssparkutils.fs.rm(success_file_path)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to write records to csv - using spark DataFrame"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def write_records_to_csv(export_values_test, folder: str):\r\n",
					"    \r\n",
					"    '''\r\n",
					"    This function writes records from a spark DataFrame to csv files in Azure Storage.\r\n",
					"    '''\r\n",
					"\r\n",
					"    # create a DataFrame of the mismatched records\r\n",
					"    values_df = export_values_test(test_source_df, test_target_df)\r\n",
					"\r\n",
					"    # pass in the source table name to the file path so the records for each source table are saved in their own folder\r\n",
					"    relative_path = f'data_validation/outputs/test_results_records/{folder}/{source}'\r\n",
					"    data = spark.createDataFrame(values_df)\r\n",
					"\r\n",
					"    # cast null columns to string to avoid errors\r\n",
					"    data = data.select([f.lit(None).cast('string').alias(i.name) if isinstance(i.dataType, NullType) else i.name for i in data.schema])\r\n",
					"\r\n",
					"    # repartition so all data is written to a single file\r\n",
					"    data = data.repartition(1)\r\n",
					"\r\n",
					"    # call the write_to_storage function, passing in the account, path and data variables\r\n",
					"    path = create_adls_path(account_name, container_name, relative_path)\r\n",
					"    write_to_storage(account_name, container_name, relative_path, data)\r\n",
					"\r\n",
					"    print(f'File {source} written to storage')\r\n",
					"    print(\"Renaming file...\")\r\n",
					"\r\n",
					"    # rename the file to a sensible name using the mssparkutils mv function\r\n",
					"    relative_path_new = f'data_validation/outputs/test_results_records/{folder}/{source}/{source}.csv'\r\n",
					"    new_path = create_adls_path(account_name, container_name, relative_path_new)\r\n",
					"    rename_csv_files(old_path=path, new_path=new_path)\r\n",
					"\r\n",
					"    print(f'File renamed - new file path: {new_path}')\r\n",
					"\r\n",
					"    print(\"Deleting _SUCCESS file\")\r\n",
					"\r\n",
					"    remove_success_files(old_path=path, new_path=new_path)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to write records to csv - using pandas DataFrame"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def write_to_csv_pandas():\r\n",
					"\r\n",
					"    '''\r\n",
					"    This function writes records from a pandas DataFrame to a csv file in Azure storage\r\n",
					"    '''\r\n",
					"    \r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Write to storage - generic function"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def write_file_to_storage(path: str, filename: str, data):\r\n",
					"    '''\r\n",
					"    Function to write a file to storage using mssparkutils.fs.put.\r\n",
					"    Requires a path, filename and data / content.\r\n",
					"    '''\r\n",
					"    mssparkutils.fs.put(f'{path}/{filename}', data, overwrite=True)\r\n",
					"    return print(f'File - {filename} - written to storage - path - {path}')"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### pandas_compare_dataframes"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def pandas_compare_dataframes(test_source_df, test_target_df):\r\n",
					"    '''\r\n",
					"    Function that compares 2 pandas DataFrames and returns the comparison as a new DataFrame showing the differences.\r\n",
					"    DataFrames must have the same shape and columns and indexes must be in the same order and have the same names. \r\n",
					"    '''\r\n",
					"    comparison_df = test_source_df.compare(test_target_df, result_names=('MiPINS', 'ODW'), keep_shape=False, keep_equal=False)\r\n",
					"    if len(comparison_df) > 0:\r\n",
					"        return comparison_df\r\n",
					"    else:\r\n",
					"        return print(\"No differences\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### create_dataframes_to_compare"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def create_dataframes_to_compare(test_source_df, test_target_df, table_key: list):\r\n",
					"    '''\r\n",
					"    Function that performs some pre-processing to create 2 pandas DataFrames that can be compared. \r\n",
					"    '''\r\n",
					"    # rename ODW columns (just in DataFrame) with the MiPINS column names so they can be compared\r\n",
					"    test_target_df.columns = [col for col in test_source_df.columns]\r\n",
					"    \r\n",
					"    # cast all columns to string for ease of comparison\r\n",
					"    test_source_df = test_source_df.astype('string')\r\n",
					"    test_target_df = test_target_df.astype('string')\r\n",
					"    print(f'Source DataFrame and target DataFrame data types set to string to enable comparison')\r\n",
					"\r\n",
					"    # set the key for the table to be used for joining purposes and as the DataFrame index\r\n",
					"    table_key = table_key\r\n",
					"    print(\"Table key set\")\r\n",
					"\r\n",
					"    # merge the 2 DataFrames using an outer join on the table key passed to the function, setting suffixes and an indicator column\r\n",
					"    merge_df = test_source_df.merge(test_target_df, how='outer', on=table_key, suffixes=('_MiPINS', '_ODW'), indicator='Table?')\r\n",
					"    print(\"DataFrames merged successfully\")\r\n",
					"\r\n",
					"    # Set the index of the merged DataFrame to the table key passed to the function, keeping the columns in the DataFrame as well as the index\r\n",
					"    merge_df.set_index(table_key, inplace=True, drop=False)\r\n",
					"    print(\"Index set on merged DataFrame\")\r\n",
					"\r\n",
					"    # Set merge_df columns to string to enable comparison\r\n",
					"    merge_df = merge_df.astype('string')\r\n",
					"    print(\"Merged DataFrame data types set to string to enable comparison\")\r\n",
					"\r\n",
					"    # Replace N/A values with 'UNKNOWN'\r\n",
					"    merge_df = merge_df.fillna('UNKNOWN')\r\n",
					"    print(\"N/A values replaced with 'UNKNOWN'\")\r\n",
					"\r\n",
					"    # Create a list of MiPINS and ODW columns from the merged DataFrame and rename them, removing the suffix\r\n",
					"    MiPINS_cols = table_key + ['Table?'] + [col for col in merge_df.columns if (col[-7:]=='_MiPINS')]\r\n",
					"    MiPINS_renamed = list([col.replace('_MiPINS', '') for col in MiPINS_cols])\r\n",
					"    odw_cols = table_key + ['Table?'] + [col for col in merge_df.columns if (col[-4:]=='_ODW')]\r\n",
					"    odw_renamed = list([col.replace('_ODW', '') for col in odw_cols])\r\n",
					"    print(\"MiPINS and ODW columns defined and renamed\")\r\n",
					"\r\n",
					"    # Assign column names to each DataFrame so they match exactly for comparison purposes\r\n",
					"    merge_df_mipins = merge_df[MiPINS_cols]\r\n",
					"    merge_df_mipins.columns = [col for col in MiPINS_renamed]\r\n",
					"    merge_df_odw = merge_df[odw_cols]\r\n",
					"    merge_df_odw.columns = [col for col in odw_renamed]\r\n",
					"    print(\"Column names assigned for each DataFrame\")\r\n",
					"\r\n",
					"    # Check the new DataFrames have a matching shape\r\n",
					"    shape_match = test8_source_target_shape_match(merge_df_mipins, merge_df_odw)\r\n",
					"    print(f'Shape match: {shape_match}')\r\n",
					"\r\n",
					"    # Create resulting comparison DataFrame\r\n",
					"    df_compare = pandas_compare_dataframes(merge_df_mipins, merge_df_odw) \r\n",
					"    \r\n",
					"    # Replace N/A values with 'EQUAL' for df_compare\r\n",
					"    df_compare = df_compare.fillna('EQUAL')\r\n",
					"    print(\"N/A values replaced with 'EQUAL' for df_compare\")\r\n",
					"\r\n",
					"    # join column names together (rather than a tuple, have one name with _MiPINS or _ODW)\r\n",
					"    df_compare.columns = df_compare.columns.map('_'.join)\r\n",
					"    print(\"Column names joined\")\r\n",
					"\r\n",
					"    print(\"df_compare DataFrame created\")\r\n",
					"\r\n",
					"    return df_compare"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Set flag for pandas.compare ability (DataFrames must be same shape) \r\n",
					"\r\n",
					"Not needed really, just a test I wrote, might be useful at some point."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# def pandas_compare_flag(row):\r\n",
					"#     if row['test8_source_target_shape_match'] == True:\r\n",
					"#         return True\r\n",
					"#     else:\r\n",
					"#         return False\r\n",
					"\r\n",
					"# result_df['pandas_compare_flag'] = result_df.apply(pandas_compare_flag, axis = 1)\r\n",
					"# result_df"
				],
				"execution_count": null
			}
		]
	}
}