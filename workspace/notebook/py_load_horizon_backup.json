{
	"name": "py_load_horizon_backup",
	"properties": {
		"folder": {
			"name": "utils"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "1acce663-2de6-43f0-819e-17e0a8b545a3"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Load Horizon data all in one notebook\r\n",
					"\r\n",
					"Load the required notebooks that host the Horizon load functions, i.e. `py_1_raw_to_standardised_hr_functions` and `py_raw_to_std`.    \r\n",
					"\r\n",
					"`py_raw_to_std` now contains an async function called `ingest_horizon` which can be called asynchronously for all the Horizon csv files.  \r\n",
					"\r\n",
					"Mount the storage path to the Horizon date folder once and only once.  \r\n",
					"\r\n",
					"Load all the Horizon data asynchronously. Date folder can be amended for testing. Currently this will write to tables prefixed with `zzz_test`. This can be converted back (remove the prefix) in the `ingest_adhoc` function in `py_1_raw_to_standardised_hr_functions` before merging back to main.  \r\n",
					"\r\n",
					"Unmount the storage path.  \r\n",
					"\r\n",
					"TODO: Add error handling and make sure 1 file can't fail the rest of them.  "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run 1-odw-raw-to-standardised/Fileshare/SAP_HR/py_1_raw_to_standardised_hr_functions"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run 1-odw-raw-to-standardised/py_raw_to_std"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run utils/py_mount_storage"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import asyncio\r\n",
					"import nest_asyncio\r\n",
					"import tracemalloc\r\n",
					"tracemalloc.start()\r\n",
					"\r\n",
					"storage_account=mssparkutils.notebook.run('/utils/py_utils_get_storage_account')\r\n",
					"raw_container = \"abfss://odw-raw@\" + storage_account"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"print(raw_container)"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"date_folder='2024-11-20'\r\n",
					"source_folder='Horizon'\r\n",
					"source_frequency_folder=''\r\n",
					"specific_file=''\r\n",
					"isMultiLine = True\r\n",
					"delete_existing_table=False\r\n",
					"dataAttribute = \"\"\r\n",
					"source_path = f\"{raw_container}{source_folder}/{date_folder}\"\r\n",
					"print(source_path)"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"files = mssparkutils.fs.ls(source_path)\r\n",
					"horizon_files = [file.name for file in files]\r\n",
					"horizon_files"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"jobId = mssparkutils.env.getJobId()\r\n",
					"mount_storage(path=source_path)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Load horizon standardised\r\n",
					"\r\n",
					"Sequentially, this took around 12 mins for all tables to be loaded using the original notebook and running it per file.  \r\n",
					"\r\n",
					"Using async functions this can be reduced to around 5 mins."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"async def load_horizon_async():\r\n",
					"    tasks: list = [\r\n",
					"        ingest_horizon(date_folder=date_folder, file=file) for file in horizon_files\r\n",
					"    ]\r\n",
					"    await asyncio.gather(*tasks)\r\n",
					"\r\n",
					"nest_asyncio.apply()\r\n",
					"loop = asyncio.get_event_loop()\r\n",
					"loop.run_until_complete(load_horizon_async())"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"unmount_storage()"
				],
				"execution_count": null
			}
		]
	}
}