{
	"name": "casework_nsip_advice_dim",
	"properties": {
		"description": "This is the advice dimension for NSIP ",
		"folder": {
			"name": "odw-harmonised/Casework"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodwpr",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "5a9824a4-1756-476d-9a16-13231c8bab8f"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodwpr",
				"name": "pinssynspodwpr",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodwpr",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Check for new, updated or deleted data\n",
					"- This script checks for new, updated or deleted data by checking the source data (horizon tables) against the target (odw_harmonised_db.casework tables)\n",
					"- **New Data:** where an main Reference in the source does not exist in the target, then NewData flag is set to 'Y'\n",
					"- **Updated data:** Comparison occurs on Reference Fields in source and in target where the row hash is different i.e. there is a change in one of the columns. NewData flag is set to 'Y'\n",
					"- **Deleted data:** where an Reference info in the target exists but the same identifyers don't exist in the source. DeletedData flag is set to 'Y'\n",
					"\n",
					"## View casework_nsip_advice_dim_new is created"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"-- Build casework_nsip_advice_dim_new table\r\n",
					"-- Gets modified or deleted from source rows\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW casework_nsip_advice_dim_new \r\n",
					"AS\r\n",
					"\r\n",
					"-- gets data that matches of SourceID and flags that it is modified based on a row (md5) hash. Flags as \"NewData\"\r\n",
					"-- gets data that is in the target but not in source. Flags as \"DeletedData\"\r\n",
					"\r\n",
					"SELECT \r\n",
					"    CASE\r\n",
					"        WHEN T1.advicenodeid IS NULL\r\n",
					"        THEN T3.NSIPAdviceID\r\n",
					"        ELSE NULL\r\n",
					"    END                                         AS NSIPAdviceID,\r\n",
					"    T1.advicenodeid                             AS AdviceNodeID,\r\n",
					"    T1.casereference                            AS CaseReference,\r\n",
					"    T1.advicereference                          AS AdviceReference,\r\n",
					"    T1.advicestatus                             AS AdviceStatus,\r\n",
					"    T1.section51advice                          AS Section51Advice,\r\n",
					"    T1.enquirerfirstname                        AS EnquirerFirstName,\r\n",
					"    T1.enquirerlastname                         AS EnquirerLastName,\r\n",
					"    T1.enquirerorganisation                     AS EnquirerOrganisation,\r\n",
					"    T1.enquirydate                              AS EnquiryDate,\r\n",
					"    T1.enqirymethod                             AS EnquiryMethod,\r\n",
					"    T1.enquiry                                  AS Enquiry,\r\n",
					"    T1.advicefrom                               AS AdviceFrom,\r\n",
					"    T1.advicedate                               AS AdviceDate,\r\n",
					"    T1.advice                                   AS Advice,\r\n",
					"    T1.advicelastmodified                       AS AdviceLastModified,\r\n",
					"    T1.attachmentcount                          AS AttachmentCount,\r\n",
					"    T1.attachmentslastmodified                  AS AttachmentLastModified,\r\n",
					"    T1.lastpublisheddate                        AS LastPublishedDate,\r\n",
					"    T1.casenodeid                               AS CaseNodeID,\r\n",
					"    T1.welshlanguage                            AS WelshLanguage,\r\n",
					"    T1.caseWorktype                             AS CaseWorkType,\r\n",
					"    T2.SourceSystemID,\r\n",
					"    to_timestamp(T1.expected_from)              AS IngestionDate,\r\n",
					"    NULL                                        AS ValidTo,\r\n",
					"    md5(concat(IFNULL(T1.advicenodeid,'.'),\t\r\n",
					"        IFNULL(T1.casereference,'.'),\t\r\n",
					"        IFNULL(T1.advicereference,'.'),\t\r\n",
					"        IFNULL(T1.advicestatus,'.'),\t\r\n",
					"        IFNULL(T1.section51advice,'.'),\t\r\n",
					"        IFNULL(T1.enquirerfirstname,'.'),\t\r\n",
					"        IFNULL(T1.enquirerlastname,'.'),\t\r\n",
					"        IFNULL(T1.enquirerorganisation,'.'),\t\r\n",
					"        IFNULL(T1.enquirydate,'.'),\t\r\n",
					"        IFNULL(T1.enqirymethod,'.'),\t\r\n",
					"        IFNULL(T1.enquiry,'.'),\t\r\n",
					"        IFNULL(T1.advicefrom,'.'),\t\r\n",
					"        IFNULL(T1.advicedate,'.'),\t\r\n",
					"        IFNULL(T1.advice,'.'),\t\r\n",
					"        IFNULL(T1.advicelastmodified,'.'),\t\r\n",
					"        IFNULL(T1.attachmentcount,'.'),\t\r\n",
					"        IFNULL(T1.attachmentslastmodified,'.'),\t\r\n",
					"        IFNULL(T1.lastpublisheddate,'.'),\t\r\n",
					"        IFNULL(T1.casenodeid,'.'),\t\r\n",
					"        IFNULL(T1.welshlanguage,'.'),\t\r\n",
					"        IFNULL(T1.caseWorktype,'.')))           AS RowID, -- this hash should contain all the defining fields\r\n",
					"    'Y' AS IsActive,\r\n",
					"    T3.IsActive AS HistoricIsActive\r\n",
					"FROM odw_standardised_db.horizon_nsip_advice T1\r\n",
					"\r\n",
					"LEFT JOIN odw_harmonised_db.main_sourcesystem_fact T2   \r\n",
					"    ON \"Casework\" = T2.Description      \r\n",
					"        AND T2.IsActive = 'Y'\r\n",
					"\r\n",
					"FULL JOIN odw_harmonised_db.casework_nsip_advice_dim T3 \r\n",
					"    ON T1.advicenodeid = T3.AdviceNodeID      \r\n",
					"        AND T3.IsActive = 'Y'\r\n",
					"WHERE\r\n",
					"        -- flags new data        \r\n",
					"        (   CASE\r\n",
					"                WHEN T1.advicenodeid = T3.AdviceNodeID \r\n",
					"                AND  \r\n",
					"                md5(concat(IFNULL(T1.advicenodeid,'.'),\t\r\n",
					"                IFNULL(T1.casereference,'.'),\t\r\n",
					"                IFNULL(T1.advicereference,'.'),\t\r\n",
					"                IFNULL(T1.advicestatus,'.'),\t\r\n",
					"                IFNULL(T1.section51advice,'.'),\t\r\n",
					"                IFNULL(T1.enquirerfirstname,'.'),\t\r\n",
					"                IFNULL(T1.enquirerlastname,'.'),\t\r\n",
					"                IFNULL(T1.enquirerorganisation,'.'),\t\r\n",
					"                IFNULL(T1.enquirydate,'.'),\t\r\n",
					"                IFNULL(T1.enqirymethod,'.'),\t\r\n",
					"                IFNULL(T1.enquiry,'.'),\t\r\n",
					"                IFNULL(T1.advicefrom,'.'),\t\r\n",
					"                IFNULL(T1.advicedate,'.'),\t\r\n",
					"                IFNULL(T1.advice,'.'),\t\r\n",
					"                IFNULL(T1.advicelastmodified,'.'),\t\r\n",
					"                IFNULL(T1.attachmentcount,'.'),\t\r\n",
					"                IFNULL(T1.attachmentslastmodified,'.'),\t\r\n",
					"                IFNULL(T1.lastpublisheddate,'.'),\t\r\n",
					"                IFNULL(T1.casenodeid,'.'),\t\r\n",
					"                IFNULL(T1.welshlanguage,'.'),\t\r\n",
					"                IFNULL(T1.caseWorktype,'.')))\r\n",
					"                <> T3.RowID  -- same row, changed data\r\n",
					"                THEN 'Y'\r\n",
					"                WHEN T3.AdviceNodeID IS NULL -- new AdviceNodeID\r\n",
					"                THEN 'Y'\r\n",
					"            ELSE 'N'\r\n",
					"            END  = 'Y' ) \r\n",
					";"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Run tests to check integrity of data by numbers\r\n",
					"- This script checks for the total number of current codes in the harmonised table, and compare against the numbers for new data to be added and data to be set as inactive.\r\n",
					"- **Changes tracking:** where it checks the data against active records in harmonised and compares with records to add and records to be set as inactive.\r\n",
					"- **Changes tolerance levels:** if the total amount to be added and deleted surpasses the tolerance limit, it will interrupt the process of loading the data"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# from pyspark.sql import SparkSession\r\n",
					"# spark = SparkSession.builder.getOrCreate()\r\n",
					"\r\n",
					"# Source_Number = spark.sql(\"SELECT COUNT(*) AS Source_Number FROM pins_casework_nsip_relevant_representation_grouped\")\r\n",
					"# Current_Number = spark.sql(\"SELECT COUNT (DISTINCT RowID) AS Current_Number FROM odw_harmonised_db.casework_nsip_advice_dim where IsActive = 'Y' \")\r\n",
					"# New_Data_Number = spark.sql(\"SELECT COUNT (DISTINCT RowID) AS New_Data_Number FROM casework_nsip_advice_dim WHERE NewData = 'Y'\")\r\n",
					"# Deleted_Data_Number = spark.sql(\"SELECT COUNT (DISTINCT RowID) AS Deleted_Data_Number FROM casework_nsip_advice_dim WHERE DeletedData = 'Y'\")\r\n",
					"\r\n",
					"# Source_Number_Pandas = Source_Number.toPandas()\r\n",
					"# Current_Number_Pandas =  Current_Number.toPandas()\r\n",
					"# New_Data_Number_Pandas = New_Data_Number.toPandas()\r\n",
					"# Deleted_Data_Number_Pandas = Deleted_Data_Number.toPandas()\r\n",
					"\r\n",
					"# # checking if new total number of registers matches the previously loaded, plus New ones, minus Deleted ones\r\n",
					"# print(\"SET 1:\")\r\n",
					"# Total_Number = Source_Number_Pandas['Source_Number'].tolist() \r\n",
					"# Current_Loaded_Number = Current_Number_Pandas['Current_Number'].tolist() \r\n",
					"# New_Data_Number = New_Data_Number_Pandas['New_Data_Number'].tolist() \r\n",
					"# Deleted_Data_Number = Deleted_Data_Number_Pandas['Deleted_Data_Number'].tolist() \r\n",
					"\r\n",
					"# if Total_Number[0] != (Current_Loaded_Number[0] + New_Data_Number[0] - Deleted_Data_Number[0]):\r\n",
					"#     raise RuntimeError(\"Loading Number do not match\")\r\n",
					"# else:\r\n",
					"#     print(\"Loading number matches with existing codes plus new, minus deleted!\")\r\n",
					"\r\n",
					"# if New_Data_Number[0] > 1000:\r\n",
					"#     raise RuntimeError(\"ALERT: Too many new codes\")\r\n",
					"# else:\r\n",
					"#     print(\"New data under tolerance levels\")\r\n",
					"\r\n",
					"# if Deleted_Data_Number[0] > 500:\r\n",
					"#     raise RuntimeError(\"ALERT: Too many deleted codes\")\r\n",
					"# else:\r\n",
					"#     print(\"Unused codes under tolerance levels\")"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Run tests to check integrity of data by comparison of codes\r\n",
					"- This script checks for the total list of current codes in the harmonised table, and compare against the list for new data to be added and data to be set as inactive.\r\n",
					"- **Changes tracking:** where it checks the data against active records in harmonised and compares with records to add and records to be set as inactive."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# from pyspark.sql import SparkSession\r\n",
					"# spark = SparkSession.builder.getOrCreate()\r\n",
					"\r\n",
					"# Current_Records = spark.sql(\"SELECT DISTINCT RowID AS Current_Records FROM odw_harmonised_db.casework_nsip_advice_dim where IsActive = 'Y' \")\r\n",
					"# New_Data_Records = spark.sql(\"SELECT DISTINCT RowID AS New_Data_Records FROM casework_nsip_advice_dim WHERE NewData = 'Y'\")\r\n",
					"# Deleted_Data_Records = spark.sql(\"SELECT DISTINCT RowID AS Deleted_Data_Records FROM casework_nsip_advice_dim WHERE DeletedData = 'Y'\")\r\n",
					"\r\n",
					"# Current_Records_Pandas =  Current_Records.toPandas()\r\n",
					"# New_Data_Records_Pandas = New_Data_Records.toPandas()\r\n",
					"# Deleted_Data_Records_Pandas = Deleted_Data_Records.toPandas()\r\n",
					"\r\n",
					"# # checking if a deleted records are correcly flagged, not existing in the new data, but existing inpreviously loaded\r\n",
					"# print(\"TEST 2:\")\r\n",
					"\r\n",
					"# Current_Records = Current_Records_Pandas['Current_Records'].tolist() \r\n",
					"# Deleted_Records = Deleted_Data_Records_Pandas['Deleted_Data_Records'].tolist()\r\n",
					"# New_Records = New_Data_Records_Pandas['New_Data_Records'].tolist()\r\n",
					"\r\n",
					"# print(Current_Records)\r\n",
					"# print(Deleted_Records)\r\n",
					"# print(New_Records)\r\n",
					"\r\n",
					"# for i in Deleted_Records:\r\n",
					"#     if i in Current_Records: \r\n",
					"#         print(i + \" to be deleted is in the current records\")\r\n",
					"#     else:\r\n",
					"#         raise RuntimeError(\"Records to Delete do not match\")\r\n",
					"\r\n",
					"# for j in New_Records:\r\n",
					"#     if j not in Current_Records: \r\n",
					"#         print(j + \" to be added is not in the current records\")\r\n",
					"#     else:\r\n",
					"#         raise RuntimeError(\"Records to Add do not match\")"
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Dataset is created that contains changed data and corresponding target data\n",
					"- This script combines data that has been updated, Deleted or is new, with corresponding target data\n",
					"- View **casework_nsip_advice_dim_new** is unioned to the target data filter to only those rows where changes have been detected\n",
					"## View casework_nsip_advice_dim_changed_rows is created"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"-- Create new and updated dataset\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW casework_nsip_advice_dim_changed_rows\r\n",
					"AS\r\n",
					"\r\n",
					"-- gets updated, deleted and new rows \r\n",
					"SELECT \r\n",
					"    NSIPAdviceID,\r\n",
					"    AdviceNodeID,\r\n",
					"    CaseReference,\r\n",
					"    AdviceReference,\r\n",
					"    AdviceStatus,\r\n",
					"    Section51Advice,\r\n",
					"    EnquirerFirstName,\r\n",
					"    EnquirerLastName,\r\n",
					"    EnquirerOrganisation,\r\n",
					"    EnquiryDate,\r\n",
					"    EnquiryMethod,\r\n",
					"    Enquiry,\r\n",
					"    AdviceFrom,\r\n",
					"    AdviceDate,\r\n",
					"    Advice,\r\n",
					"    AdviceLastModified,\r\n",
					"    AttachmentCount,\r\n",
					"    AttachmentLastModified,\r\n",
					"    LastPublishedDate,\r\n",
					"    CaseNodeID,\r\n",
					"    WelshLanguage,\r\n",
					"    CaseWorkType,\r\n",
					"    SourceSystemID,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"FROM casework_nsip_advice_dim_new \r\n",
					"WHERE HistoricIsActive = 'Y' \r\n",
					"    OR HistoricIsActive IS NULL\r\n",
					"UNION ALL\r\n",
					"-- gets original versions of updated rows so we can update EndDate and set IsActive flag to 'N'\r\n",
					"SELECT\r\n",
					"    NSIPAdviceID,\r\n",
					"    AdviceNodeID,\r\n",
					"    CaseReference,\r\n",
					"    AdviceReference,\r\n",
					"    AdviceStatus,\r\n",
					"    Section51Advice,\r\n",
					"    EnquirerFirstName,\r\n",
					"    EnquirerLastName,\r\n",
					"    EnquirerOrganisation,\r\n",
					"    EnquiryDate,\r\n",
					"    EnquiryMethod,\r\n",
					"    Enquiry,\r\n",
					"    AdviceFrom,\r\n",
					"    AdviceDate,\r\n",
					"    Advice,\r\n",
					"    AdviceLastModified,\r\n",
					"    AttachmentCount,\r\n",
					"    AttachmentLastModified,\r\n",
					"    LastPublishedDate,\r\n",
					"    CaseNodeID,\r\n",
					"    WelshLanguage,\r\n",
					"    CaseWorkType,\r\n",
					"    SourceSystemID,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"    \r\n",
					"FROM odw_harmonised_db.casework_nsip_advice_dim\r\n",
					"WHERE AdviceNodeID IN \r\n",
					"(\r\n",
					"    SELECT AdviceNodeID \r\n",
					"    FROM casework_nsip_advice_dim_new \r\n",
					"    WHERE NSIPAdviceID IS NULL\r\n",
					") \r\n",
					"AND IsActive = 'Y'; "
				],
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# View casework_nsip_advice_dim_changed_rows is used in a merge (Upsert) statement into the target table\n",
					"- **WHEN MATCHED** ON the surrogate Key (i.e. NSIPRelevantRepresentationID), EndDate is set to today -1 day and the IsActive flag is set to 'N'\n",
					"- **WHEN NOT MATCHED** ON the surrogate Key, insert rows\n",
					"## Table odw_harmonised_db.casework_nsip_advice_dim is updated"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"-- merge into dim table\r\n",
					"\r\n",
					"MERGE INTO odw_harmonised_db.casework_nsip_advice_dim AS Target\r\n",
					"USING casework_nsip_advice_dim_changed_rows AS Source\r\n",
					"ON Source.NSIPAdviceID = Target.NSIPAdviceID\r\n",
					"\r\n",
					"-- For Updates existing rows\r\n",
					"\r\n",
					"WHEN MATCHED\r\n",
					"    THEN \r\n",
					"    UPDATE SET\r\n",
					"    Target.ValidTo = date_sub(current_timestamp,1),\r\n",
					"    Target.IsActive = 'N'"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Fix the IDs\n",
					"- No auto-increment feature is available in delta tables, therefore we need to create new IDs for the inserted rows\n",
					"- This is done by select the target data and using INSERT OVERWRITE to re-insert the data is a new Row Number\n",
					"## Table odw_harmonised_db.casework_nsip_advice_dim is updated"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"-- Insert new casework_nsip_advice_dim\r\n",
					"\r\n",
					"INSERT INTO odw_harmonised_db.casework_nsip_advice_dim\r\n",
					"\r\n",
					"SELECT \r\n",
					"    ROW_NUMBER() OVER (ORDER BY NSIPAdviceID NULLS LAST) AS NSIPAdviceID,\r\n",
					"    NSIPAdviceID,\r\n",
					"    AdviceNodeID,\r\n",
					"    CaseReference,\r\n",
					"    AdviceReference,\r\n",
					"    AdviceStatus,\r\n",
					"    Section51Advice,\r\n",
					"    EnquirerFirstName,\r\n",
					"    EnquirerLastName,\r\n",
					"    EnquirerOrganisation,\r\n",
					"    EnquiryDate,\r\n",
					"    EnquiryMethod,\r\n",
					"    Enquiry,\r\n",
					"    AdviceFrom,\r\n",
					"    AdviceDate,\r\n",
					"    Advice,\r\n",
					"    AdviceLastModified,\r\n",
					"    AttachmentCount,\r\n",
					"    AttachmentLastModified,\r\n",
					"    LastPublishedDate,\r\n",
					"    CaseNodeID,\r\n",
					"    WelshLanguage,\r\n",
					"    CaseWorkType,\r\n",
					"    SourceSystemID,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"    FROM casework_nsip_advice_dim_changed_rows;\r\n",
					""
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"This last cell is just to check count of rows between source and target on first load, to be deleted!"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql \n",
					"\n",
					"SELECT COUNT(*) FROM odw_standardised_db.horizon_nsip_advice;\n",
					"SELECT COUNT(*) FROM odw_harmonised_db.casework_nsip_advice_dim;"
				],
				"execution_count": 7
			}
		]
	}
}