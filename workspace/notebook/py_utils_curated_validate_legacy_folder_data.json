{
	"name": "py_utils_curated_validate_legacy_folder_data",
	"properties": {
		"description": "Validation notebook for validating curated layer tables against the json schema.",
		"folder": {
			"name": "utils/data-validation"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "54bcf48f-97da-4f86-b89c-9fd1d3ec3004"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Validation notebook for validating curated layer tables against the json schema\r\n",
					"\r\n",
					"#### NB: PLEASE ATTACH TO THE SPARK POOL \"PINSSYNSPODW\" AS THIS IS RUNNING PYTHON 3.10 WHICH IS NEEDED"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Install packages"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%pip install --quiet --upgrade pip\r\n",
					"%pip install --quiet jsonschema==4.20.0 iso8601==2.1.0 git+https://github.com/Planning-Inspectorate/data-model@main#egg=pins_data_model"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Imports"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pandas as pd\r\n",
					"import json\r\n",
					"from collections import defaultdict\r\n",
					"import pprint\r\n",
					"from jsonschema import validate, FormatChecker, ValidationError, Draft202012Validator\r\n",
					"from iso8601 import parse_date, ParseError\r\n",
					"from pins_data_model import load_schemas"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Import validation funcitons notebook"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run utils/data-validation/py_utils_curated_validate_functions"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Define constants"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"SCHEMAS = load_schemas.load_all_schemas()[\"schemas\"]\r\n",
					"SCHEMA = SCHEMAS[\"folder.schema.json\"]\r\n",
					"PRIMARY_KEY = \"id\" \r\n",
					"DATABASE = \"odw_curated_db\"\r\n",
					"TABLE = \"legacy_folder_data\"\r\n",
					"QUERY = f\"SELECT * FROM `{DATABASE}`.`{TABLE}`\"\r\n",
					"OUTPUT_FILE = f\"{TABLE}.txt\""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Create dataframe of the data from the table\r\n",
					"\r\n",
					"For certain tables it may be necessary to rename a column or two in order to create the array and avoid duplicate field names.\r\n",
					"\r\n",
					"It's also necessary to convert None and NaT values to empty strings. A NULL value in SQL is shown as None for strings or NaT for timestamps in pandas so converting to an empty string will match the expected schema as we're validating using a pandas dataframe.\r\n",
					"\r\n",
					"The replace() function is used to convert NaT values to None and then these are converted to empty strings using fillna()."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df = spark.sql(QUERY)\r\n",
					"data = df.toPandas()\r\n",
					"for column in data:\r\n",
					"    data[column].replace({pd.NaT: None},inplace=True)\r\n",
					"    data[column].fillna('', inplace=True)\r\n",
					"# check if any rows contain values classed as NULL, i.e. NaN, NaT, None. There should be 0 rows.\r\n",
					"nullrows = data[data.isna().any(axis=1)]\r\n",
					"nullrows"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data.head(5)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Validate against the schema\r\n",
					"\r\n",
					"%%capture magic command is used to capture the cell output and assign it to the variable \"output\". This can then be used later as the data to be written to file.\r\n",
					"\r\n",
					"The validate variable can be used and returned as the exit value of the notebook."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%%capture output\r\n",
					"\r\n",
					"validate = validate_data(data=create_json_from_table_flat(data),\r\n",
					"                        schema = SCHEMA,\r\n",
					"                        primary_key = PRIMARY_KEY)\r\n",
					"result = output.stdout"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Print the validation output\r\n",
					"\r\n",
					"Output is sent to storage so commented out but can be printed here if need be"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# print(result)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Write output to storage"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"write_file_to_storage(path, OUTPUT_FILE, result)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Set notebook exit value to the validate variable above\r\n",
					"\r\n",
					"True for successful validation\r\n",
					"False for faield validation"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mssparkutils.notebook.exit(validate)"
				],
				"execution_count": null
			}
		]
	}
}