{
	"name": "contract_dim",
	"properties": {
		"folder": {
			"name": "odw-harmonised/SAP-HR"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "006c35e2-70a5-4d25-87cc-6b0ba0f9531e"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Check for new, updated or deleted data\n",
					"- This script checks for new, updated or deleted data by checking the source data (sap hr) against the target (odw_harmonised_db.contract_dim)\n",
					"- **New Data:** where a workc in the source does not exist as an ContractCode in the target. NewData flag is set to 'Y'\n",
					"- **Updated data:** Comparison occurs on workc in source and ContractCode in target where the row hash is different i.e. there is a change in one of the columns. NewData flag is set to 'Y'\n",
					"- **Deleted data:** where an ContractCode in the target exists but the same workc doesn't exist in the source. DeletedData flag is set to 'Y'\n",
					"\n",
					"## View contract_dim_new is created"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW contract_grouped\r\n",
					"\r\n",
					"    AS\r\n",
					"\r\n",
					"SELECT  WorkC as ContractCode,\r\n",
					"        First(Work_Contract) as Description, \r\n",
					"        CASE \r\n",
					"            WHEN CT IS NULL\r\n",
					"            THEN 'N/A'\r\n",
					"            ELSE CT\r\n",
					"        END as ContractTypeCode,\r\n",
					"        First(Contract_Type) as ContractType\r\n",
					"       \r\n",
					"FROM odw_standardised_db.vw_saphr\r\n",
					"WHERE WorkC IS NOT NULL\r\n",
					"GROUP BY WorkC, CT;"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW contract_dim_new\r\n",
					"\r\n",
					"    AS\r\n",
					"\r\n",
					"-- gets data that matches of SourceID and flags that it is modified based on a row (md5) hash. Flags as \"NewData\"\r\n",
					"-- gets data that is in the target but not in source. Flags as \"DeletedData\"\r\n",
					"SELECT \r\n",
					"    CASE\r\n",
					"        WHEN T1.ContractCode IS NULL\r\n",
					"        THEN T7.ContractID\r\n",
					"        ELSE NULL\r\n",
					"    END as ContractID, \r\n",
					"    T1.ContractCode,\r\n",
					"    T1.Description,\r\n",
					"    T1.ContractTypeCode,\r\n",
					"    T1.ContractType,\r\n",
					"    T2.SourceSystemID,\r\n",
					"    CURRENT_TIMESTAMP AS StartDate,\r\n",
					"    NULL AS EndDate,\r\n",
					"    CURRENT_TIMESTAMP AS IngestionDate,\r\n",
					"    NULL AS ValidTo,\r\n",
					"    md5(concat(IFNULL(T1.ContractCode,'.'), IFNULL(T1.Description,'.'), IFNULL(T1.ContractTypeCode,'.'), IFNULL(T1.ContractType,'.'))) as RowID,\r\n",
					"    'Y' as IsActive,\r\n",
					"    CASE\r\n",
					"        WHEN T1.ContractCode = T7.ContractCode AND T1.ContractTypeCode = T7.ContractTypeCode\r\n",
					"            AND md5(concat(IFNULL(T1.ContractCode,'.'), IFNULL(T1.Description,'.'), IFNULL(T1.ContractTypeCode,'.'), IFNULL(T1.ContractType,'.'))) <> T7.RowID   -- same employee, changed data\r\n",
					"        THEN 'Y'\r\n",
					"        WHEN T7.ContractCode IS NULL -- new employee\r\n",
					"        THEN 'Y'\r\n",
					"        ELSE 'N'\r\n",
					"    END as NewData,\r\n",
					"    CASE\r\n",
					"        WHEN T1.ContractCode IS NULL\r\n",
					"        THEN 'Y'\r\n",
					"        ELSE 'N'\r\n",
					"    END AS  DeletedData\r\n",
					"\r\n",
					"FROM contract_grouped T1\r\n",
					"LEFT JOIN odw_harmonised_db.sourcesystem_fact T2 ON \"SAP HR\" = T2.Description AND T2.IsActive = 'Y'\r\n",
					"FULL JOIN odw_harmonised_db.contract_dim T7 ON T1.ContractCode = T7.ContractCode AND\r\n",
					"                                                T1.ContractTypeCode = T7.ContractTypeCode     \r\n",
					"WHERE  (T7.IsActive = 'Y' or T7.IsActive IS NULL)\r\n",
					"    \r\n",
					"        AND (\r\n",
					"        \r\n",
					"        -- flags new data        \r\n",
					"        (  CASE\r\n",
					"                WHEN T1.ContractCode = T7.ContractCode AND T1.ContractTypeCode = T7.ContractTypeCode\r\n",
					"                    AND md5(concat(IFNULL(T1.ContractCode,'.'), IFNULL(T1.Description,'.'), IFNULL(T1.ContractTypeCode,'.'), IFNULL(T1.ContractType,'.'))) <> T7.RowID   -- same employee, changed data\r\n",
					"                THEN 'Y'\r\n",
					"                WHEN T7.ContractCode IS NULL -- new employee\r\n",
					"                THEN 'Y'\r\n",
					"                ELSE 'N'\r\n",
					"            END  = 'Y' ) OR\r\n",
					"        \r\n",
					"        -- flags deleted data\r\n",
					"        (   CASE\r\n",
					"                WHEN T1.ContractCode IS NULL\r\n",
					"                THEN 'Y'\r\n",
					"                ELSE 'N'\r\n",
					"            END = 'Y' )\r\n",
					")\r\n",
					"\r\n",
					";"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Run tests to check integrity of data by numbers\n",
					"- This script checks for the total number of current codes in the harmonised table, and compare against the numbers for new data to be added and data to be set as inactive.\n",
					"- **Changes tracking:** where it checks the data against active records in harmonised and compares with records to add and records to be set as inactive.\n",
					"- **Changes tolerance levels:** if the total amount to be added and deleted surpasses the tolerance limit, it will interrupt the process of loading the data"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql import SparkSession\n",
					"spark = SparkSession.builder.getOrCreate()\n",
					"\n",
					"Source_Number = spark.sql(\"SELECT COUNT (DISTINCT WorkC) AS Source_Number FROM odw_standardised_db.vw_saphr\")\n",
					"Current_Number = spark.sql(\"SELECT COUNT (DISTINCT ContractCode) AS Current_Number FROM odw_harmonised_db.contract_dim where IsActive = 'Y' \")\n",
					"New_Data_Number = spark.sql(\"SELECT COUNT (DISTINCT ContractCode) AS New_Data_Number FROM contract_dim_new WHERE NewData = 'Y'\")\n",
					"Deleted_Data_Number = spark.sql(\"SELECT COUNT (DISTINCT ContractCode) AS Deleted_Data_Number FROM contract_dim_new WHERE DeletedData = 'Y'\")\n",
					"\n",
					"Source_Number_Pandas = Source_Number.toPandas()\n",
					"Current_Number_Pandas =  Current_Number.toPandas()\n",
					"New_Data_Number_Pandas = New_Data_Number.toPandas()\n",
					"Deleted_Data_Number_Pandas = Deleted_Data_Number.toPandas()\n",
					"\n",
					"# checking if new total number of registers matches the previously loaded, plus New ones, minus Deleted ones\n",
					"print(\"SET 1:\")\n",
					"Total_Number = Source_Number_Pandas['Source_Number'].tolist() \n",
					"Current_Loaded_Number = Current_Number_Pandas['Current_Number'].tolist() \n",
					"New_Data_Number = New_Data_Number_Pandas['New_Data_Number'].tolist() \n",
					"Deleted_Data_Number = Deleted_Data_Number_Pandas['Deleted_Data_Number'].tolist() \n",
					"\n",
					"print(Total_Number) \n",
					"print(Current_Loaded_Number) \n",
					"print(New_Data_Number) \n",
					"print(Deleted_Data_Number)\n",
					"\n",
					"if Total_Number[0] != (Current_Loaded_Number[0] + New_Data_Number[0] - Deleted_Data_Number[0]):\n",
					"    raise RuntimeError(\"Loading Number do not match\")\n",
					"else:\n",
					"    print(\"Loading number matches with existing codes plus new, minus deleted!\")\n",
					"\n",
					"if New_Data_Number[0] > 10:\n",
					"    raise RuntimeError(\"ALERT: Too many new codes\")\n",
					"else:\n",
					"    print(\"New data under tolerance levels\")\n",
					"\n",
					"if Deleted_Data_Number[0] > 5:\n",
					"    raise RuntimeError(\"ALERT: Too many deleted codes\")\n",
					"else:\n",
					"    print(\"Unused codes under tolerance levels\")\n",
					""
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Run tests to check integrity of data by comparison of codes\n",
					"- This script checks for the total list of current codes in the harmonised table, and compare against the list for new data to be added and data to be set as inactive.\n",
					"- **Changes tracking:** where it checks the data against active records in harmonised and compares with records to add and records to be set as inactive."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql import SparkSession\n",
					"spark = SparkSession.builder.getOrCreate()\n",
					"\n",
					"Current_Records = spark.sql(\"SELECT DISTINCT ContractCode AS Current_Records FROM odw_harmonised_db.contract_dim where IsActive = 'Y' \")\n",
					"New_Data_Records = spark.sql(\"SELECT DISTINCT ContractCode AS New_Data_Records FROM contract_dim_new WHERE NewData = 'Y'\")\n",
					"Deleted_Data_Records = spark.sql(\"SELECT DISTINCT ContractCode AS Deleted_Data_Records FROM contract_dim_new WHERE DeletedData = 'Y'\")\n",
					"\n",
					"Current_Records_Pandas =  Current_Records.toPandas()\n",
					"New_Data_Records_Pandas = New_Data_Records.toPandas()\n",
					"Deleted_Data_Records_Pandas = Deleted_Data_Records.toPandas()\n",
					"\n",
					"# checking if a deleted records are correcly flagged, not existing in the new data, but existing inpreviously loaded\n",
					"print(\"TEST 2:\")\n",
					"\n",
					"Current_Records = Current_Records_Pandas['Current_Records'].tolist() \n",
					"Deleted_Records = Deleted_Data_Records_Pandas['Deleted_Data_Records'].tolist()\n",
					"New_Records = New_Data_Records_Pandas['New_Data_Records'].tolist()\n",
					"\n",
					"print(Current_Records)\n",
					"print(Deleted_Records)\n",
					"print(New_Records)\n",
					"\n",
					"for i in Deleted_Records:\n",
					"    if i in Current_Records: \n",
					"        print(i + \" to be deleted is in the current records\")\n",
					"    else:\n",
					"        raise RuntimeError(\"Records to Delete do not match\")\n",
					"\n",
					"for j in New_Records:\n",
					"    if j not in Current_Records: \n",
					"        print(j + \" to be added is not in the current records\")\n",
					"    else:\n",
					"        raise RuntimeError(\"Records to Add do not match\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Dataset is created that contains changed data and corresponding target data\n",
					"- This script combines data that has been updated, Deleted or is new, with corresponding target data\n",
					"- View **contract_dim_new** is unioned to the target data filter to only those rows where changes have been detected\n",
					"## View contract_dim_changed_rows is created"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW contract_dim_changed_rows\r\n",
					"\r\n",
					"    AS\r\n",
					"\r\n",
					"Select \r\n",
					"    ContractID,\r\n",
					"    ContractCode,\r\n",
					"    Description,\r\n",
					"    ContractTypeCode,\r\n",
					"    ContractType,\r\n",
					"    SourceSystemID,\r\n",
					"    StartDate,\r\n",
					"    EndDate,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"From contract_dim_new\r\n",
					"\r\n",
					"    UNION ALL\r\n",
					"\r\n",
					"SELECT\r\n",
					"    T1.ContractID,\r\n",
					"    T1.ContractCode,\r\n",
					"    T1.Description,\r\n",
					"    T1.ContractTypeCode,\r\n",
					"    T1.ContractType,\r\n",
					"    T1.SourceSystemID,\r\n",
					"    T1.StartDate,\r\n",
					"    T1.EndDate,\r\n",
					"    T1.IngestionDate,\r\n",
					"    T1.ValidTo,\r\n",
					"    T1.RowID,\r\n",
					"    T1.IsActive\r\n",
					"FROM odw_harmonised_db.contract_dim T1\r\n",
					"INNER JOIN contract_dim_new T2 ON T1.ContractCode = T2.ContractCode AND T1.ContractTypeCode = T2.ContractTypeCode; \r\n",
					""
				],
				"execution_count": 35
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# View contract_dim_changed_rows is used in a merge (Upsert) statement into the target table\n",
					"- **WHEN MATCHED** ON the Business Key (i.e. workc from SAPHR), EndDate is set to today -1 day and the IsActive flag is set to 'N'\n",
					"- **WHEN NOT MATCHED** ON the business key, insert rows\n",
					"## Table odw_harmonised.contract_dim is updated"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"-- merge into fact table\r\n",
					"\r\n",
					"MERGE INTO odw_harmonised_db.contract_dim AS Target\r\n",
					"USING contract_dim_changed_rows AS Source\r\n",
					"\r\n",
					"ON Source.ContractID = Target.ContractID\r\n",
					"\r\n",
					"-- For Updates existing rows\r\n",
					"\r\n",
					"WHEN MATCHED\r\n",
					"    THEN \r\n",
					"    UPDATE SET\r\n",
					"    Target.EndDate = date_sub(current_timestamp,1),\r\n",
					"    Target.IsActive = 'N'\r\n",
					"\r\n",
					"-- Insert completely new rows\r\n",
					"WHEN NOT MATCHED \r\n",
					"    THEN INSERT * ;  \r\n",
					""
				],
				"execution_count": 31
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Fix the IDs\n",
					"- No auto-increment feature is available in delta tables, therefore we need to create new IDs for the inserted rows\n",
					"- This is done by select the target data and using INSERT OVERWRITE to re-insert the data is a new Row Number\n",
					"## Table odw_harmonised.contract_dim is updated"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"-- Insert new ContractID\r\n",
					"\r\n",
					"INSERT OVERWRITE odw_harmonised_db.contract_dim\r\n",
					"\r\n",
					"SELECT \r\n",
					"    ROW_NUMBER() OVER (ORDER BY ContractID NULLS LAST) AS ContractID,\r\n",
					"    ContractCode,\r\n",
					"    Description,\r\n",
					"    ContractTypeCode,\r\n",
					"    ContractType,\r\n",
					"    SourceSystemID,\r\n",
					"    StartDate,\r\n",
					"    EndDate,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"FROM odw_harmonised_db.contract_dim;\r\n",
					""
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"SELECT *\n",
					"from odw_harmonised_db.contract_dim;"
				],
				"execution_count": 33
			}
		]
	}
}