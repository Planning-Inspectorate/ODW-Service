{
	"name": "appeal_document",
	"properties": {
		"folder": {
			"name": "odw-curated"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "f0e25c9b-4a24-4add-90ec-d40f12acdd8c"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.functions import *\n",
					"from pyspark.sql.types import *"
				],
				"execution_count": 14
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Create a view for the data, joining harmonised tables where necessary"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"CREATE OR REPLACE VIEW odw_curated_db.vw_appeal_document\n",
					"\n",
					"AS\n",
					"\n",
					"SELECT DISTINCT \n",
					"    documentId,\n",
					"    caseId,\n",
					"    caseReference,\n",
					"    version,\n",
					"    filename,\n",
					"    originalFilename,\n",
					"    size,\n",
					"    COALESCE(mime, '') AS mime,\n",
					"    COALESCE(documentURI, '') AS documentURI,\n",
					"    publishedDocumentURI,\n",
					"    virusCheckStatus,\n",
					"    fileMD5,\n",
					"    dateCreated,\n",
					"    dateReceived,\n",
					"    datePublished,\n",
					"    lastModified,\n",
					"    CASE\n",
					"        WHEN caseType = 'Planning Listed Building and Conservation Area Appeal (Y)' THEN 'Y'\n",
					"        WHEN caseType = 'Lawful Development Certificate Appeal' THEN 'X'\n",
					"        WHEN caseType = 'Planning Obligation Appeal' THEN 'Q'\n",
					"        WHEN caseType = 'Commercial (CAS) Appeal' THEN 'Z'\n",
					"        WHEN caseType = 'Enforcement Listed Building and Conservation Area Appeal' THEN 'F'\n",
					"        WHEN caseType = 'Advertisement Appeal' THEN 'H'\n",
					"        WHEN caseType = 'Planning Appeal (A)' THEN 'W'\n",
					"        WHEN caseType = 'Enforcement Notice Appeal' THEN 'C'\n",
					"        WHEN caseType = 'Discontinuance Notice Appeal' THEN 'G'\n",
					"        WHEN caseType = 'Community Infrastructure Levy' THEN 'L'\n",
					"        WHEN caseType = 'Planning Appeal (W)' THEN 'W'\n",
					"        WHEN caseType = 'Call-In Application' THEN 'V'\n",
					"        WHEN caseType = 'Affordable Housing Obligation Appeal' THEN 'S'\n",
					"        WHEN caseType = 'Householder (HAS) Appeal' THEN 'D'\n",
					"        ELSE CAST(NULL AS String) \n",
					"    END\n",
					"    AS caseType,\n",
					"    redactedStatus,\n",
					"    documentType,\n",
					"    sourceSystem,\n",
					"    origin,\n",
					"    owner,\n",
					"    author,\n",
					"    description,\n",
					"    caseStage,\n",
					"    horizonFolderId\n",
					"    \n",
					"FROM odw_harmonised_db.appeal_document\n",
					"WHERE IsActive = 'Y'"
				],
				"execution_count": 16
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Create a DataFrame of the data from the view"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data: DataFrame = spark.sql(\"SELECT * FROM odw_curated_db.vw_appeal_document\")"
				],
				"execution_count": 17
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Specify the schema for the data, taken from the curated table which has already been created in advance from the data model"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"schema: StructType = spark.table(\"odw_curated_db.appeal_document\").schema"
				],
				"execution_count": 18
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Cast all field data types in the data to the data types from the curated table schema\n",
					"\n",
					"This is necessary because the view generated above is joining harmonised tables, many of which are sourced from Horizon and will have a different schema to the final table and fields will have different data types. Therefore, taking the curated schema as defined in thr data model and casting all fields correctly, ensures accuracy."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df: DataFrame = data.select(\n",
					"    *[\n",
					"        col(field.name).cast(field.dataType).alias(field.name)\n",
					"        for field in schema.fields\n",
					"    ]\n",
					")"
				],
				"execution_count": 19
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Print the schema as a visual check"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df.printSchema()"
				],
				"execution_count": 20
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Write the data to the curated table"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df.write.mode(\"overwrite\").saveAsTable(\"odw_curated_db.appeal_document\")"
				],
				"execution_count": 21
			}
		]
	}
}