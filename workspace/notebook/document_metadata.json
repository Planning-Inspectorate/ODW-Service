{
	"name": "document_metadata",
	"properties": {
		"folder": {
			"name": "odw-curated"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "d0aad763-bdb2-465b-8d7d-3a5e5038042a"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.functions import *\n",
					"from pyspark.sql.types import *\n",
					"from pyspark.sql import DataFrame"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Create a view for the data, joining harmonised tables where necessary"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"CREATE OR REPLACE VIEW odw_curated_db.vw_nsip_document\r\n",
					"\r\n",
					"AS\r\n",
					"\r\n",
					"SELECT DISTINCT \r\n",
					"MD.documentId,\r\n",
					"MD.caseId,\r\n",
					"DT.caseReference\t                    AS caseRef,\r\n",
					"MD.documentReference,\r\n",
					"MD.version,\r\n",
					"MD.ExaminationRefNo,\r\n",
					"MD.filename,\r\n",
					"MD.originalFilename,\r\n",
					"MD.size,\r\n",
					"MD.mime,\r\n",
					"MD.documentURI,\r\n",
					"MD.publishedDocumentURI,\r\n",
					"MD.path,\r\n",
					"MD.VirusCheckStatus,\r\n",
					"MD.fileMD5,\r\n",
					"MD.dateCreated,\r\n",
					"MD.lastModified,\r\n",
					"LOWER(MD.caseType)\t                AS caseType,\r\n",
					"CASE\r\n",
					"    WHEN MD.redactedStatus = ' '   \r\n",
					"    THEN NULL\r\n",
					"    ELSE MD.redactedStatus                \r\n",
					"END                                     AS redactedStatus,\r\n",
					"CASE\r\n",
					"    WHEN MD.PublishedStatus = 'Depublished'\r\n",
					"    THEN 'unpublished'\r\n",
					"    ELSE REPLACE(\r\n",
					"        LOWER(MD.PublishedStatus),\r\n",
					"        ' ',\r\n",
					"        '_')\r\n",
					"END                  \t                AS publishedStatus,\r\n",
					"MD.datePublished,\r\n",
					"MD.documentType,\r\n",
					"CASE\r\n",
					"    WHEN MD.securityClassification = ' '\r\n",
					"    THEN NULL\r\n",
					"    ELSE MD.securityClassification\r\n",
					"END\t                                    AS securityClassification,\r\n",
					"MD.sourceSystem,\r\n",
					"CASE\r\n",
					"    WHEN MD.origin  = ' '\r\n",
					"    THEN NULL\r\n",
					"    ELSE MD.origin\r\n",
					"END\t                                    AS origin,\r\n",
					"MD.owner,\r\n",
					"MD.author,\r\n",
					"MD.authorWelsh,\r\n",
					"MD.representative,\r\n",
					"MD.description,\r\n",
					"MD.descriptionWelsh,\r\n",
					"CASE\r\n",
					"    WHEN MD.DocumentCaseStage = \"Developer's Application\"\r\n",
					"    THEN 'developers_application'\r\n",
					"    WHEN MD.DocumentCaseStage = 'Post decision'\r\n",
					"    THEN 'post_decision'\r\n",
					"    ELSE LOWER(MD.DocumentCaseStage)\t            \r\n",
					"END                                     AS documentCaseStage,\r\n",
					"MD.filter1,\r\n",
					"filter1Welsh,\r\n",
					"MD.filter2,\r\n",
					"MD.horizonFolderId,\r\n",
					"transcriptId\t\r\n",
					"\r\n",
					"FROM odw_harmonised_db.nsip_document   AS MD\r\n",
					"LEFT JOIN  odw_curated_db.nsip_data DT\r\n",
					"    ON DT.casereference = MD.caseRef\r\n",
					"-- LEFT JOIN odw_harmonised_db.aie_document_data    AS AMD\r\n",
					"--     ON MD.DataID = AMD.DocumentID \r\n",
					"--         AND AMD.Version = MD.Version \r\n",
					"--         AND AMD.Size = MD.DataSize\r\n",
					"WHERE MD.IsActive = 'Y' \r\n",
					"    -- AND MD.IsActive = 'Y'\r\n",
					";"
				],
				"execution_count": 40
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Create a DataFrame of the data from the view"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql import SparkSession\r\n",
					"spark = SparkSession.builder.getOrCreate()\r\n",
					"view_df = spark.sql('SELECT * FROM odw_curated_db.vw_nsip_document')\r\n",
					"view_df.write.mode(\"overwrite\").saveAsTable('odw_curated_db.nsip_document')"
				],
				"execution_count": 41
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"view_df.printSchema()"
				],
				"execution_count": 42
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## THE BELOW IS OLDER CODE, AND IT CHANGED THE SCHEMA"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Specify the schema for the data, taken from the curated table which has already been created in advance from the data model"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data: DataFrame = spark.sql(\"SELECT * FROM odw_curated_db.vw_nsip_document\")\r\n",
					"schema: StructType = spark.table(\"odw_curated_db.nsip_document\").schema"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Cast all field data types in the data to the data types from the curated table schema\n",
					"\n",
					"This is necessary because the view generated above is joining harmonised tables, many of which are sourced from Horizon and will have a different schema to the final table and fields will have different data types. Therefore, taking the curated schema as defined in thr data model and casting all fields correctly, ensures accuracy."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df: DataFrame = data.select(\n",
					"    *[\n",
					"        col(field.name).cast(field.dataType).alias(field.name)\n",
					"        for field in schema.fields\n",
					"    ]\n",
					")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Print the schema as a visual check"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"df.printSchema()"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Write the data to the curated table"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"odw_curated_db.nsip_document\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}