{
	"name": "Harmonised1",
	"properties": {
		"folder": {
			"name": "archive"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "55c340df-0d45-4855-bad9-751a35936889"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "sql"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"df_standardized = spark.sql(\"SELECT StaffNumber,Firstname,Lastname,EmailAddress FROM odw_standardised_db.sap_email_monthly\")\n",
					""
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"df_standardized.show(truncate=False)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"harmonised_schema = StructType([\n",
					"    StructField(\"StaffNumber\", StringType(), True),\n",
					"    StructField(\"Nickname\", StringType(), True),\n",
					"    StructField(\"Lastname\", StringType(), True),\n",
					"    StructField(\"EmailAddress\", StringType(), True)\n",
					"])\n",
					"\n",
					"# Create empty DataFrame with the harmonised schema\n",
					"df_harmonised = spark.createDataFrame([], schema=harmonised_schema)\n",
					"\n",
					"# Create harmonised Lake DB table if it doesn't exist\n",
					"spark.sql(\"\"\"\n",
					"    CREATE TABLE IF NOT EXISTS odw_harmonised_db.SAP_PINS_email_weekly (\n",
					"        StaffNumber STRING,\n",
					"        Nickname STRING,\n",
					"        Lastname STRING,\n",
					"        EmailAddress STRING\n",
					"    )\n",
					"    USING DELTA\n",
					"\"\"\")"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import col\n",
					"\n",
					"# Rename Firstname to Nickname\n",
					"df_to_harmonised = df_standardized.withColumnRenamed(\"Firstname\", \"Nickname\")\n",
					"\n",
					"# Write the DataFrame with overwrite mode\n",
					"df_to_harmonised.write.format(\"delta\") \\\n",
					"    .mode(\"overwrite\") \\\n",
					"    .option(\"overwriteSchema\", \"true\") \\\n",
					"    .saveAsTable(\"odw_harmonised_db.SAP_PINS_email_weekly\")"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"source": [
					"df_to_harmonised.show()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"\n",
					"### Read data from the standardized Lake DB\n",
					"\n",
					"\n",
					"# Apply schema and clean data\n",
					"df_standardized = df_standardized.select(\n",
					"    trim(regexp_replace(col(\"StaffNumber\"), '[^\\x20-\\x7E]', '')).alias(\"StaffNumber\"),\n",
					"    trim(col(\"Firstname\")).alias(\"Firstname\"),\n",
					"    trim(col(\"Lastname\")).alias(\"Lastname\"),\n",
					"    trim(col(\"EmailAddress\")).alias(\"EmailAddress\")\n",
					")\n",
					"\n",
					"# Display the data\n",
					"df_standardized.show(truncate=False)\n",
					"df_standardized.printSchema()\n",
					"\n",
					"\n",
					"# Define schema for harmonised table\n",
					"harmonised_schema = StructType([\n",
					"    StructField(\"StaffNumber\", StringType(), True),\n",
					"    StructField(\"Nickname\", StringType(), True),\n",
					"    StructField(\"Lastname\", StringType(), True),\n",
					"    StructField(\"EmailAddress\", StringType(), True)\n",
					"])\n",
					"\n",
					"# Create empty DataFrame with the harmonised schema\n",
					"df_harmonised = spark.createDataFrame([], schema=harmonised_schema)\n",
					"\n",
					"# Create harmonised Lake DB table if it doesn't exist\n",
					"spark.sql(\"\"\"\n",
					"    CREATE TABLE IF NOT EXISTS odw_harmonised_db.SAP_PINS_email_weekly (\n",
					"        StaffNumber STRING,\n",
					"        Nickname STRING,\n",
					"        Lastname STRING,\n",
					"        EmailAddress STRING\n",
					"    )\n",
					"    USING DELTA\n",
					"\"\"\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import col, when, concat_ws, max as spark_max, md5, row_number\n",
					"from pyspark.sql.window import Window\n",
					"\n",
					"# Initialize Spark session\n",
					"spark = SparkSession.builder.appName(\"SAP_HR_Transformations\").getOrCreate()\n",
					"\n",
					"# Step 1: Update [Charting Officer for Inspector] to NULL where it is an empty string\n",
					"stg_inspector_address_df = spark.table(\"odw_standardised_db.inspector_addresses_monthly\")\n",
					"stg_inspector_address_df = stg_inspector_address_df.withColumn(\n",
					"    \"ChartingOfficerforInspector\",\n",
					"    when(col(\"ChartingOfficerforInspector\") == \"\", None).otherwise(col(\"ChartingOfficerforInspector\"))\n",
					"stg_inspector_address_df.write.mode(\"overwrite\").saveAsTable(\"odw_harmonised_db.inspector_addresses_monthly\")\n",
					"\n",
					"# Step 2: Truncate the [transform_inspector_address] table\n",
					"spark.sql(\"TRUNCATE TABLE odw_harmonised_db.inspector_addresses_monthly\")\n",
					"\n",
					"# Step 3: Insert data into [transform_inspector_address] with transformations\n",
					"# Subquery to get the max [Start Date] for each [Staff Number]\n",
					"window_spec = Window.partitionBy(\"StaffNumber\")\n",
					"max_start_date_df = stg_inspector_address_df.withColumn(\"max_start_date\", spark_max(\"Start Date\").over(window_spec))\n",
					"\n",
					"# Filter rows where [Start Date] matches the max [Start Date] for each [Staff Number]\n",
					"filtered_df = max_start_date_df.filter(col(\"Start Date\") == col(\"max_start_date\"))\n",
					"\n",
					"# Apply transformations and select columns\n",
					"transform_inspector_address_df = filtered_df.select(\n",
					"    col(\"Staff Number\"),\n",
					"    col(\"Street and House Number\"),\n",
					"    col(\"2nd Address Line\"),\n",
					"    col(\"City\"),\n",
					"    col(\"District\"),\n",
					"    col(\"Postal Code\"),\n",
					"    col(\"Region (State, Province, Count)\").alias(\"Region\"),\n",
					"    col(\"Start Date\"),\n",
					"    col(\"End Date\"),\n",
					"    when(col(\"Charting Officer\").rlike(\"^50\"), concat_ws(\"\", \"00\", col(\"Charting Officer\")))\n",
					"        .when(col(\"Charting Officer\").rlike(\"^42\"), concat_ws(\"\", \"50\", col(\"Charting Officer\")))\n",
					"        .otherwise(col(\"Charting Officer\")).alias(\"Charting Officer\"),\n",
					"    col(\"Charting Officer for Inspector\"),\n",
					"    col(\"Subs PS group\"),\n",
					"    col(\"Tel No.\").alias(\"Telephone no\"),\n",
					"    col(\"Personal Mobile\"),\n",
					"    col(\"Work Mobile\"),\n",
					"    col(\"Chngd on\")\n",
					")\n",
					"\n",
					"# Write the transformed data to the target table\n",
					"transform_inspector_address_df.write.mode(\"append\").saveAsTable(\"sap_hr.transform_inspector_address\")\n",
					"\n",
					"# Step 4: Update [ValHashKey] using an MD5 hash\n",
					"transform_inspector_address_df = spark.table(\"sap_hr.transform_inspector_address\")\n",
					"transform_inspector_address_df = transform_inspector_address_df.withColumn(\n",
					"    \"ValHashKey\",\n",
					"    md5(concat_ws(\n",
					"        \"|\",\n",
					"        col(\"Staff Number\"),\n",
					"        col(\"Street and House Number\"),\n",
					"        col(\"2nd Address Line\"),\n",
					"        col(\"City\"),\n",
					"        col(\"District\"),\n",
					"        col(\"Postal Code\"),\n",
					"        col(\"Region\"),\n",
					"        col(\"Start Date\"),\n",
					"        col(\"End Date\"),\n",
					"        col(\"Charting Officer\"),\n",
					"        col(\"Charting Officer for Inspector\"),\n",
					"        col(\"Subs PS group\"),\n",
					"        col(\"Telephone no\"),\n",
					"        col(\"Personal Mobile\"),\n",
					"        col(\"Work Mobile\"),\n",
					"        col(\"Chngd on\")\n",
					"    ))\n",
					")\n",
					"transform_inspector_address_df.write.mode(\"overwrite\").saveAsTable(\"sap_hr.transform_inspector_address\")\n",
					"\n",
					"# Step 5: Remove duplicates using a ROW_NUMBER() window function\n",
					"window_spec_dup = Window.partitionBy(\"Staff Number\").orderBy(col(\"Chngd on\").desc())\n",
					"deduplicated_df = transform_inspector_address_df.withColumn(\"RN\", row_number().over(window_spec_dup)) \\\n",
					"    .filter(col(\"RN\") == 1) \\\n",
					"    .drop(\"RN\")\n",
					"\n",
					"# Write the deduplicated data back to the target table\n",
					"deduplicated_df.write.mode(\"overwrite\").saveAsTable(\"sap_hr.transform_inspector_address\")\n",
					"\n",
					"# Stop the Spark session\n",
					"spark.stop()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"%%sql\n",
					"spark.sql(`drop table odw_harmonised_db.inspector_addresses_monthly`)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"drop table odw_harmonised_db.inspector_addresses_monthly"
				],
				"execution_count": 77
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"# Initialize Spark Session\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()\n",
					"\n",
					"# Define the schema\n",
					"harmonised_schema = StructType([\n",
					"    \n",
					"    StructField(\"StaffNumber\", StringType(), True),\n",
					"    StructField(\"StreetandHouseNumber\", StringType(), True),\n",
					"    StructField(\"2ndAddressline\", StringType(), True),\n",
					"    StructField(\"City\", StringType(), True),\n",
					"    StructField(\"District\", StringType(), True),\n",
					"    StructField(\"PostalCode\", StringType(), True),\n",
					"    StructField(\"RegionStateProvinceCounty\", StringType(), True),\n",
					"    StructField(\"StartDate\", StringType(), True),\n",
					"    StructField(\"EndDate\", StringType(), True),\n",
					"    StructField(\"ChartingOfficer\", StringType(), True),\n",
					"    StructField(\"ChartingOfficerforInspection\", StringType(), True),\n",
					"    StructField(\"SubsPSgroup\", StringType(), True),\n",
					"    StructField(\"TelNo\", StringType(), True),\n",
					"    StructField(\"PersonalMobile\", StringType(), True),\n",
					"    StructField(\"WorkMobile\", StringType(), True),\n",
					"    StructField(\"Chngdon\", StringType(), True)\n",
					"    \n",
					"])\n",
					"\n",
					"df_harmonised = spark.createDataFrame([], schema=harmonised_schema)\n",
					"\n",
					"# Create harmonised Lake DB table if it doesn't exist\n",
					"spark.sql(\"\"\"\n",
					"CREATE TABLE IF NOT EXISTS odw_harmonised_db.inspector_addresses_monthly (\n",
					"\n",
					"StaffNumber\tstring,\n",
					"StreetandHouseNumber\tstring,\n",
					"2ndAddressLine\tstring,\n",
					"City\tstring,\n",
					"District\tstring,\n",
					"PostalCode\tstring,\n",
					"RegionStateProvinceCount\tstring,\n",
					"StartDate\tstring,\n",
					"EndDate\tstring,\n",
					"ChartingOfficer\tstring,\n",
					"ChartingOfficerforInspector\tstring,\n",
					"SubsPSgroup\tstring,\n",
					"TelNo\tstring,\n",
					"PersonalMobile\tstring,\n",
					"WorkMobile\tstring,\n",
					"Chngdon\tstring\n",
					"\n",
					" )\n",
					"    USING DELTA\n",
					"\"\"\")"
				],
				"execution_count": 27
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"df_harmonised.printSchema"
				],
				"execution_count": 79
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"---update odw_harmonised_db.inspector_addresses_monthly set [ChartingOfficerforInspector] = NULL where [ChartingOfficerforInspector] =''\n",
					"\n",
					"\n",
					"delete from  odw_harmonised_db.inspector_addresses_monthly where 1=1;"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"\n",
					"\n",
					"delete from  odw_harmonised_db.inspector_addresses_monthly;\n",
					"\n",
					"insert into odw_harmonised_db.inspector_addresses_monthly\n",
					"\t(\n",
					"                StaffNumber,\n",
					"\t\t\t\tStreetandHouseNumber,\n",
					"\t\t\t\t2ndAddressLine,\n",
					"\t\t\t\tCity,\n",
					"\t\t\t\tDistrict,\n",
					"\t\t\t\tPostalCode,\n",
					"\t\t\t\tRegionStateProvinceCount,\n",
					"\t\t\t\tStartDate ,\n",
					"\t\t\t\tEndDate,\n",
					"\t\t\t\tChartingOfficer,\n",
					"\t\t\t\tChartingOfficerforInspector,\n",
					"\t\t\t\tSubsPSgroup,\n",
					"\t\t\t\tTelNo,\n",
					"\t\t\t\tPersonalMobile,\n",
					"\t\t\t\tWorkMobile,\n",
					"\t\t\t\tChngdon\n",
					"\t\t\t\t\n",
					"\t)\n",
					"select \n",
					"\t \n",
					"\t\t        StaffNumber,\n",
					"\t\t\t\tStreetandHouseNumber,\n",
					"\t\t\t\t2ndAddressLine,\n",
					"\t\t\t\tCity,\n",
					"\t\t\t\tDistrict,\n",
					"\t\t\t\tPostalCode,\n",
					"\t\t\t\tRegionStateProvinceCount,\n",
					"\t\t        StartDate ,\n",
					"\t\t\t\tEndDate,\n",
					"\tcase len(ChartingOfficer)\n",
					"\t when 6 then\n",
					"\tcase when ChartingOfficer like '50%' then concat('00',ChartingOfficer) \n",
					"\t when ChartingOfficer like '42%' then concat('50',ChartingOfficer)  \n",
					"\telse ChartingOfficer -- RV added length part for 6 and 8 \n",
					"\tend \n",
					"\t when 8 then ChartingOfficer\n",
					"\telse ChartingOfficer end as\n",
					"\t\tChartingOfficer,\n",
					"\t\tChartingOfficerforInspector,\n",
					"\t\tSubsPSgroup,\n",
					"\t\tTelNo,\n",
					"\t\tnull as PersonalMobile,\n",
					"\t\tWorkMobile,\n",
					"\t\tmax(Chngdon) as Chngdon\n",
					"\tfrom odw_standardised_db.inspector_addresses_monthly t1\n",
					"\twhere t1.StartDate=(select max(t2.StartDate) from odw_standardised_db.inspector_addresses_monthly t2 where t2.StaffNumber=t1.StaffNumber)\n",
					"\tgroup by\n",
					"\t\t    StaffNumber,\n",
					"\t\t\t\tStreetandHouseNumber,\n",
					"\t\t\t\t2ndAddressLine,\n",
					"\t\t\t\tCity,\n",
					"\t\t\t\tDistrict,\n",
					"\t\t\t\tPostalCode,\n",
					"\t\t\t\tRegionStateProvinceCount,\n",
					"\t\t\t\tStartDate ,\n",
					"\t\t\t\tEndDate,\n",
					"\t\t\t\tChartingOfficer,\n",
					"\t\t\t\tChartingOfficerforInspector,\n",
					"\t\t\t\tSubsPSgroup,\n",
					"\t\t\t\tTelNo,\n",
					"\t\t\t\tPersonalMobile,\n",
					"\t\t\t\tWorkMobile\n",
					"\t;\n",
					"Update odw_harmonised_db.inspector_addresses_monthly\n",
					"\tset ValHashKey=\n",
					"\t\thashbytes('MD5',\n",
					"\t\t\tconcat_ws('|',\n",
					"\t\t\t    StaffNumber,\n",
					"\t\t\t\tStreetandHouseNumber,\n",
					"\t\t\t\t2ndAddressLine,\n",
					"\t\t\t\tCity,\n",
					"\t\t\t\tDistrict,\n",
					"\t\t\t\tPostalCode,\n",
					"\t\t\t\tRegionStateProvinceCount,\n",
					"\t\t\t\tStartDate ,\n",
					"\t\t\t\tEndDate,\n",
					"\t\t\t\tChartingOfficer,\n",
					"\t\t\t\tChartingOfficerforInspector,\n",
					"\t\t\t\tSubsPSgroup,\n",
					"\t\t\t\tTelNo,\n",
					"\t\t\t\tPersonalMobile,\n",
					"\t\t\t\tWorkMobile,\n",
					"\t\t\t\tChngdon\n",
					"\t\t\t\t) )\n",
					"\t\t\t\t;\n",
					"\n",
					"\t\t\tWITH CTE AS(\n",
					"\t\t\t\tSELECT \n",
					"\t\t\t\tStaffNumber,\n",
					"\t\t\t\tStreetandHouseNumber,\n",
					"\t\t\t\t2ndAddressLine,\n",
					"\t\t\t\tCity,\n",
					"\t\t\t\tDistrict,\n",
					"\t\t\t\tPostalCode,\n",
					"\t\t\t\tRegionStateProvinceCount,\n",
					"\t\t\t\tStartDate ,\n",
					"\t\t\t\tEndDate,\n",
					"\t\t\t\tChartingOfficer,\n",
					"\t\t\t\tChartingOfficerforInspector,\n",
					"\t\t\t\tSubsPSgroup,\n",
					"\t\t\t\tTelNo,\n",
					"\t\t\t\tPersonalMobile,\n",
					"\t\t\t\tWorkMobile,\n",
					"\t\t\t\tChngdon,\n",
					"    RN = ROW_NUMBER()OVER(PARTITION BY StaffNumber ORDER BY Chngdon)\n",
					"   FROM odw_standardised_db.inspector_addresses_monthly\n",
					")\n",
					"DELETE FROM CTE WHERE RN > 1\n",
					"update odw_harmonised_db.inspector_addresses_monthly set ChartingOfficerforInspector = NULL where ChartingOfficerforInspector =''\n",
					"\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"describe odw_standardised_db.inspector_addresses_monthly"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"drop table odw_harmonised_db.transform_inspector_Specialisms"
				],
				"execution_count": 55
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"# Initialize Spark Session\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()\n",
					"\n",
					"stg_inspector_Specialisms_schema = StructType([\n",
					"    StructField(\"StaffNumber\", StringType(), True),\n",
					"    StructField(\"Firstname\", StringType(), True),\n",
					"    StructField(\"Lastname\", StringType(), True),\n",
					"    StructField(\"QualificationName\", StringType(), True),\n",
					"    StructField(\"Proficien\", StringType(), True),\n",
					"    StructField(\"ValidFrom\", StringType(), True),\n",
					"    StructField(\"ValidTo\", StringType(), True),\n",
					"    StructField(\"Current\", StringType(), True),\n",
					"    StructField(\"ValHashKey\", StringType(), True),\n",
					"     StructField(\"LastUpdated\", StringType(), True)\n",
					"])\n",
					"\n",
					"df_harmonised = spark.createDataFrame([], schema=stg_inspector_Specialisms_schema)\n",
					"\n",
					"# Create harmonised Lake DB table if it doesn't exist\n",
					"spark.sql(\"\"\"\n",
					"CREATE TABLE IF NOT EXISTS odw_harmonised_db.transform_inspector_Specialisms (\n",
					"    StaffNumber string,\n",
					"    Firstname string,\n",
					"    Lastname string,\n",
					"    QualificationName string,\n",
					"    Proficien string,\n",
					"    ValidFrom  string,\n",
					"\tValidTo  string,\n",
					"\tCurrent  string,\n",
					"\tValHashKey string,\n",
					"    LastUpdated string\n",
					") \n",
					" USING DELTA;\n",
					"\"\"\")"
				],
				"execution_count": 56
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"DELETE from odw_harmonised_db.transform_inspector_Specialisms;\n",
					"\n",
					"insert into odw_harmonised_db.transform_inspector_Specialisms\n",
					"\t(\n",
					"    StaffNumber ,\n",
					"    Firstname ,\n",
					"    Lastname ,\n",
					"    QualificationName ,\n",
					"    Proficien,\n",
					"    ValidFrom ,\n",
					"\tValidTo  ,\n",
					"\tCurrent  ,\n",
					"\tValHashKey ,\n",
					"    LastUpdated \n",
					"\t)\n",
					"select \n",
					"\tcase len(StaffNumber)\n",
					"\t when 6 then\n",
					"\tcase when StaffNumber like '50%' then concat('00',StaffNumber) \n",
					"\twhen StaffNumber like '42%' then concat('50',StaffNumber)  \n",
					"\telse StaffNumber -- RV added length part for 6 and 8 \n",
					"\tend \n",
					"\t when 8 then StaffNumber\n",
					"\telse StaffNumber end as\n",
					"\t\tStaffNumber,\n",
					"\t\tFirstname ,\n",
					"\t\tLastname ,\n",
					"\t\tQualificationName ,\n",
					"\t\tProficien ,\n",
					"\t\tnull as ValidFrom ,\n",
					"\tnull as ValidTo  ,\n",
					"\tnull as Current  ,\n",
					"\tnull as ValHashKey ,\n",
					"    null as LastUpdated \n",
					"\tfrom odw_standardised_db.inspector_specialisms_monthly t1\n",
					"\twhere StaffNumber is not null\n",
					""
				],
				"execution_count": 58
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"UPDATE odw_harmonised_db.transform_inspector_Specialisms\n",
					"SET ValHashKey = md5(concat_ws('|', \n",
					"    coalesce(cast(StaffNumber as string), ''), \n",
					"    coalesce(cast(Firstname as string), ''), \n",
					"    coalesce(cast(Lastname as string), ''), \n",
					"    coalesce(cast(QualificationName as string), ''), \n",
					"    coalesce(cast(Proficien as string), '')\n",
					"))"
				],
				"execution_count": 59
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"# Initialize Spark Session\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()\n",
					"\n",
					"stg_inspector_Specialisms_schema = StructType([\n",
					"    StructField(\"StaffNumber\", StringType(), True),\n",
					"    StructField(\"Firstname\", StringType(), True),\n",
					"    StructField(\"Lastname\", StringType(), True),\n",
					"    StructField(\"QualificationName\", StringType(), True),\n",
					"    StructField(\"Proficien\", StringType(), True),\n",
					"    StructField(\"ValidFrom\", StringType(), True),\n",
					"    StructField(\"ValidTo\", StringType(), True),\n",
					"    StructField(\"Current\", StringType(), True),\n",
					"    StructField(\"ValHashKey\", StringType(), True),\n",
					"     StructField(\"LastUpdated\", StringType(), True)\n",
					"])\n",
					"\n",
					"df_harmonised = spark.createDataFrame([], schema=stg_inspector_Specialisms_schema)\n",
					"\n",
					"# Create harmonised Lake DB table if it doesn't exist\n",
					"spark.sql(\"\"\"\n",
					"CREATE TABLE IF NOT EXISTS odw_harmonised_db.inspector_Specialisms (\n",
					"    StaffNumber string,\n",
					"    Firstname string,\n",
					"    Lastname string,\n",
					"    QualificationName string,\n",
					"    Proficien string,\n",
					"    ValidFrom  string,\n",
					"\tValidTo  string,\n",
					"\tCurrent  string,\n",
					"\tValHashKey string,\n",
					"    LastUpdated string\n",
					") \n",
					" USING DELTA;\n",
					"\"\"\")"
				],
				"execution_count": 62
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Update Statements in Order !!!!"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"MERGE INTO odw_harmonised_db.inspector_Specialisms AS target\n",
					"\n",
					"USING (\n",
					"\n",
					"    SELECT oldSpe.StaffNumber, oldSpe.QualificationName\n",
					"\n",
					"    FROM odw_harmonised_db.inspector_Specialisms oldSpe\n",
					"\n",
					"    LEFT OUTER JOIN odw_harmonised_db.transform_inspector_Specialisms souSpe\n",
					"\n",
					"        ON oldSpe.StaffNumber = souSpe.StaffNumber\n",
					"\n",
					"        AND oldSpe.QualificationName = souSpe.QualificationName\n",
					"\n",
					"    WHERE souSpe.StaffNumber IS NULL\n",
					"\n",
					") AS source\n",
					"\n",
					"ON target.StaffNumber = source.StaffNumber\n",
					"\n",
					"   AND target.QualificationName = source.QualificationName\n",
					"\n",
					"   AND target.Current = 1\n",
					"\n",
					"WHEN MATCHED THEN\n",
					"\n",
					"UPDATE SET \n",
					"\n",
					"    target.Current = 0,\n",
					"\n",
					"    target.ValidTo = CURRENT_DATE();\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"insert INTO odw_harmonised_db.inspector_Specialisms (StaffNumber, Firstname, Lastname, QualificationName, Proficien, ValidFrom, ValidTo, Current, ValHashKey, LastUpdated)\n",
					"select souSpe.StaffNumber, souSpe.Firstname, souSpe.Lastname, souSpe.QualificationName, souSpe.Proficien, current_date(), '9999-12-31', 1, souSpe.ValHashKey, current_date()\n",
					"from odw_harmonised_db.transform_inspector_Specialisms souSpe\n",
					"left outer join odw_harmonised_db.inspector_Specialisms tarSpe\n",
					"\ton souSpe.StaffNumber = tarSpe.StaffNumber\n",
					"\tand tarSpe.Current = 1\n",
					"\tand souSpe.QualificationName = tarSpe.QualificationName\n",
					"where tarSpe.StaffNumber is null\n",
					""
				],
				"execution_count": 74
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"insert INTO odw_harmonised_db.inspector_Specialisms (StaffNumber, Firstname, Lastname, QualificationName, Proficien, ValidFrom, ValidTo, Current, ValHashKey, LastUpdated)\n",
					"select souSpe.StaffNumber, souSpe.Firstname, souSpe.Lastname, souSpe.QualificationName, souSpe.Proficien, current_date(), '9999-12-31', 1, souSpe.ValHashKey, current_date()\n",
					"from odw_harmonised_db.transform_inspector_Specialisms souSpe\n",
					"inner join odw_harmonised_db.inspector_Specialisms tarSpe\n",
					"\ton souSpe.StaffNumber = tarSpe.StaffNumber\n",
					"\tand tarSpe.Current = 1\n",
					"\tand souSpe.QualificationName = tarSpe.QualificationName\n",
					"where tarSpe.ValHashKey <> souSpe.ValHashKey"
				],
				"execution_count": 80
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"MERGE INTO odw_harmonised_db.inspector_Specialisms AS oldSpe\n",
					"\n",
					"USING odw_harmonised_db.inspector_Specialisms AS newSpe\n",
					"\n",
					"ON oldSpe.StaffNumber = newSpe.StaffNumber\n",
					"\n",
					"   AND oldSpe.QualificationName = newSpe.QualificationName\n",
					"\n",
					"   AND oldSpe.Current = 1\n",
					"\n",
					"   AND newSpe.Current = 1\n",
					"\n",
					"   AND newSpe.ValidFrom = CURRENT_DATE()\n",
					"\n",
					"   AND oldSpe.ValidFrom < CURRENT_DATE()\n",
					"\n",
					"WHEN MATCHED THEN\n",
					"\n",
					"UPDATE SET \n",
					"\n",
					"   oldSpe.Current = 0,\n",
					"\n",
					"   oldSpe.ValidTo = CURRENT_DATE();"
				],
				"execution_count": 83
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"select * from odw_harmonised_db.inspector_Specialisms"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"select * from odw_harmonised_db.transform_inspector_Specialisms"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"describe odw_harmonised_db.inspector_Specialisms"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"drop table odw_harmonised_db.stage_SAP_HR_Leavers"
				],
				"execution_count": 45
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# HR_LEAVERS"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
					"from pyspark.sql.functions import col, trim, regexp_replace\n",
					"\n",
					"# Initialize Spark Session\n",
					"spark = SparkSession.builder.appName(\"LakeDB_Transfer\").getOrCreate()\n",
					"\n",
					"# Define the schema for the table\n",
					"stage_SAP_HR_Leavers_schema = StructType([\n",
					"    StructField(\"PersNo\", StringType(), True),\n",
					"    StructField(\"Lastname\", StringType(), True),\n",
					"    StructField(\"Firstname\", StringType(), True),\n",
					"    StructField(\"CoCd\", StringType(), True),\n",
					"    StructField(\"CompanyCode\", StringType(), True),\n",
					"    StructField(\"Loc\", StringType(), True),\n",
					"    StructField(\"Location\", StringType(), True),\n",
					"    StructField(\"PSgroup\", StringType(), True),\n",
					"    StructField(\"PayBandDescription\", StringType(), True),\n",
					"    StructField(\"Orgunit\", StringType(), True),\n",
					"    StructField(\"OrganizationalUnit\", StringType(), True),\n",
					"    StructField(\"PA\", StringType(), True),\n",
					"    StructField(\"PersonnelArea\", StringType(), True),\n",
					"    StructField(\"PSubarea\", StringType(), True),\n",
					"    StructField(\"PersonnelSubarea\", StringType(), True),\n",
					"    StructField(\"WorkC\", StringType(), True),\n",
					"    StructField(\"WorkContract\", StringType(), True),\n",
					"    StructField(\"OrgStartDate\", TimestampType(), True),\n",
					"    StructField(\"Leaving\", TimestampType(), True),\n",
					"    StructField(\"Act\", StringType(), True),\n",
					"    StructField(\"ActionType\", StringType(), True),\n",
					"    StructField(\"ActR\", StringType(), True),\n",
					"    StructField(\"ReasonforAction\", StringType(), True),\n",
					"    StructField(\"S\", StringType(), True),\n",
					"    StructField(\"EmploymentStatus\", StringType(), True),\n",
					"    StructField(\"EmployeeNo\", StringType(), True),\n",
					"    StructField(\"Position\", StringType(), True),\n",
					"    StructField(\"Position1\", StringType(), True),\n",
					"    StructField(\"Curr\", StringType(), True),\n",
					"    StructField(\"UserID\", StringType(), True),\n",
					"    StructField(\"EmailAddress\", StringType(), True),\n",
					"    StructField(\"PersNo1\", StringType(), True),\n",
					"    StructField(\"NameofManagerOM\", StringType(), True),\n",
					"    StructField(\"ManagerPosition\", StringType(), True),\n",
					"    StructField(\"ManagerPositionText\", StringType(), True),\n",
					"    StructField(\"LMEmail\", StringType(), True)\n",
					"])\n",
					"\n",
					"\n",
					"df_harmonised = spark.createDataFrame([], schema=stage_SAP_HR_Leavers_schema)\n",
					"\n",
					"# Create harmonised Lake DB table if it doesn't exist\n",
					"spark.sql(\"\"\"\n",
					"CREATE TABLE IF NOT EXISTS odw_harmonised_db.stage_SAP_HR_Leavers (\n",
					"\n",
					"PersNo                 string,\n",
					"Lastname               string,\n",
					"Firstname               string,\n",
					"CoCd                   string,\n",
					"CompanyCode            string,\n",
					"Loc                    string,\n",
					"Location               string,\n",
					"PSgroup                string,\n",
					"PayBandDescription     string,\n",
					" Orgunit               string,\n",
					" OrganizationalUnit    string,\n",
					" PA                    string,\n",
					" PersonnelArea         string,\n",
					" PSubarea              string,\n",
					" PersonnelSubarea      string,\n",
					" WorkC                 string,\n",
					" WorkContract          string,\n",
					" OrgStartDate          string,\n",
					" Leaving               string,\n",
					" Act                   string,\n",
					" ActionType            string,\n",
					" ActR                  string,\n",
					" ReasonforAction       string,\n",
					" S                     string,\n",
					" EmploymentStatus      string,\n",
					" EmployeeNo            string,\n",
					" Position              string,\n",
					" Position1             string,\n",
					" Curr                  string,\n",
					" UserID                string,\n",
					" EmailAddress          string,\n",
					" PersNo1               string,\n",
					" NameofManagerOM       string,\n",
					" ManagerPosition       string,\n",
					" ManagerPositionText    string,\n",
					" LMEmail                string\n",
					") \n",
					" USING DELTA;\n",
					"\"\"\")"
				],
				"execution_count": 46
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"\n",
					"\n",
					"--delete from [load].[stage_SAP_HR_Leavers_ads] where [Pers.No.] is null;\n",
					"\n",
					"--update [load].[stage_SAP_HR_Leavers_ads] set [Employee No.] = '' where [Employee No.] is null\n",
					"\n",
					"---update [load].[stage_SAP_HR_Leavers_ads] set [Leaving] = '2024-02-29' where [Pers.No.] = '50426514'\n",
					"\n",
					"\n",
					"--update [load].[stage_SAP_HR_Leavers_ads] set [Leaving] = convert(date,getdate()) where [Leaving] is null\n",
					"\n",
					"INSERT INTO odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"(\n",
					"    PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract,       \n",
					"    OrgStartDate,  -- Added OrgStartDate here\n",
					"    Leaving,       -- Added Leaving here\n",
					"    Act,                \n",
					"    ActionType,         \n",
					"    ActR,               \n",
					"    ReasonforAction,    \n",
					"    S,                  \n",
					"    EmploymentStatus,  \n",
					"    EmployeeNo,         \n",
					"    Position,           \n",
					"    Position1,          \n",
					"    Curr,               \n",
					"    UserID,             \n",
					"    EmailAddress,       \n",
					"    PersNo1,            \n",
					"    NameofManagerOM,    \n",
					"    ManagerPosition,    \n",
					"    ManagerPositionText,  -- Corrected column name\n",
					"    LMEmail   \n",
					")          \n",
					"SELECT \n",
					"    PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract, \n",
					"CASE \n",
					"    WHEN instr(OrgStartDate, '/') = 0 THEN CAST(OrgStartDate AS DATE)\n",
					"    ELSE CAST(\n",
					"        concat(\n",
					"            substring(OrgStartDate, length(OrgStartDate) - 3 + 1, 4), '-', \n",
					"            substring(OrgStartDate, instr(OrgStartDate, '/') + 1, 2), '-', \n",
					"            substring(OrgStartDate, 1, instr(OrgStartDate, '/') - 1)\n",
					"        ) AS DATE\n",
					"    )\n",
					"END AS OrgStartDate,\n",
					"\n",
					"CASE \n",
					"    WHEN instr(Leaving, '/') = 0 THEN CAST(Leaving AS DATE)\n",
					"    ELSE CAST(\n",
					"        concat(\n",
					"            substring(Leaving, length(Leaving) - 3 + 1, 4), '-', \n",
					"            substring(Leaving, instr(Leaving, '/') + 1, 2), '-', \n",
					"            substring(Leaving, 1, instr(Leaving, '/') - 1)\n",
					"        ) AS DATE\n",
					"    )\n",
					"END AS Leaving,\n",
					"    Act,                \n",
					"    ActionType,         \n",
					"    ActR,               \n",
					"    ReasonforAction,    \n",
					"    S,                  \n",
					"    EmploymentStatus,  \n",
					"    EmployeeNo,         \n",
					"    Position,           \n",
					"    Position1,          \n",
					"    Curr,               \n",
					"    UserID,             \n",
					"    EmailAddress,       \n",
					"    PersNo1,            \n",
					"    NameofManagerOM,    \n",
					"    ManagerPosition,    \n",
					"    ManagerPositionText,  -- Corrected column name\n",
					"    LMEmail      \n",
					"FROM \n",
					"    odw_standardised_db.sap_hr_leavers_monthly;"
				],
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"DESCRIBE odw_standardised_db.sap_hr_history_monthly;"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"drop table odw_harmonised_db.sap_hr"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"CREATE TABLE IF NOT EXISTS odw_harmonised_db.sap_hr (\n",
					"    PersNo                  STRING,\n",
					"    Firstname               STRING,\n",
					"    Lastname                STRING,\n",
					"    EmployeeNo              STRING,\n",
					"    CoCd                    STRING,\n",
					"    CompanyCode             STRING,\n",
					"    PA                      STRING,\n",
					"    PersonnelArea           STRING,\n",
					"    PSubarea                STRING,\n",
					"    PersonnelSubarea        STRING,\n",
					"    Orgunit                 STRING,\n",
					"    OrganizationalUnit      STRING,\n",
					"    Organizationalkey       STRING,\n",
					"    OrganizationalKey1      STRING,\n",
					"    WorkC                   STRING,\n",
					"    WorkContract            STRING,\n",
					"    CT                      STRING,\n",
					"    ContractType            STRING,\n",
					"    PSgroup                 STRING,\n",
					"    PayBandDescription      STRING,\n",
					"    FTE                     DOUBLE,\n",
					"    Wkhrs                   DOUBLE,\n",
					"    IndicatorPartTimeEmployee BOOLEAN,\n",
					"    S                       STRING,\n",
					"    EmploymentStatus        STRING,\n",
					"    GenderKey               STRING,\n",
					"    TRAStartDate            DATE,\n",
					"    TRAEndDate              DATE,\n",
					"    TRAStatus               STRING,\n",
					"    TRAGrade                STRING,\n",
					"    PrevPersNo              STRING,\n",
					"    ActR                    STRING,\n",
					"    ReasonforAction         STRING,\n",
					"    Position                STRING,\n",
					"    Position1               STRING,\n",
					"    CostCtr                 STRING,\n",
					"    CostCentre              STRING,\n",
					"    CivilServiceStart        DATE,\n",
					"    DatetoCurrentJob        DATE,\n",
					"    SeniorityDate           DATE,\n",
					"    DatetoSubstGrade        DATE,\n",
					"    PersNo1                 STRING,\n",
					"    NameofManagerOM         STRING,\n",
					"    ManagerPosition         STRING,\n",
					"    ManagerPositionText     STRING,\n",
					"    CounterSignManager      STRING,\n",
					"    Loc                      STRING,\n",
					"    Location                STRING,\n",
					"    OrgStartDate            DATE,\n",
					"    FixTermEndDate           DATE,\n",
					"    LoanStartDate           DATE,\n",
					"    LoanEndDate             DATE,\n",
					"    EEGrp                   STRING,\n",
					"    EmployeeGroup           STRING,\n",
					"    Annualsalary            DOUBLE,\n",
					"    Curr                    STRING,\n",
					"    NInumber                STRING,\n",
					"    Birthdate               DATE,\n",
					"    Ageofemployee           INT,\n",
					"    EO                      STRING,\n",
					"    Ethnicorigin            STRING,\n",
					"    NID                     STRING,\n",
					"    Rel                     STRING,\n",
					"    ReligiousDenominationKey STRING,\n",
					"    SxO                     STRING,\n",
					"    WageType                STRING,\n",
					"    EmployeeSubgroup        STRING,\n",
					"    LOAAbsType              STRING,\n",
					"    LOAAbsenceTypeText      STRING,\n",
					"    Schemereference         STRING,\n",
					"    PensionSchemeName       STRING,\n",
					"    DisabilityCode          STRING,\n",
					"    DisabilityText          STRING,\n",
					"    DisabilityCodeDescription STRING,\n",
					"    PArea                   STRING,\n",
					"    PayrollArea             STRING,\n",
					"    AssignmentNumber        STRING,\n",
					"    FTE2                    DOUBLE,\n",
					"    Report_MonthEnd_Date    DATE,\n",
					"    PDAC_ETL_Date            DATE\n",
					")\n",
					"USING delta\n",
					"LOCATION 'abfss://odw-harmonised@pinsstodwdevuks9h80mb.dfs.core.windows.net/sap_hr';"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"\n",
					"\n",
					"spark.sql(\"\"\"\n",
					"INSERT INTO odw_harmonised_db.SAP_HR\n",
					"(\n",
					"    PersNo,\n",
					"    Firstname,\n",
					"    Lastname,\n",
					"    EmployeeNo,\n",
					"    CoCd,\n",
					"    CompanyCode,\n",
					"    PA,\n",
					"    PersonnelArea,\n",
					"    PSubarea,\n",
					"    PersonnelSubarea,\n",
					"    Orgunit,\n",
					"    OrganizationalUnit,\n",
					"    Organizationalkey,\n",
					"    OrganizationalKey1,\n",
					"    WorkC,\n",
					"    WorkContract,\n",
					"    CT,\n",
					"    ContractType,\n",
					"    PSgroup,\n",
					"    PayBandDescription,\n",
					"    FTE,\n",
					"    Wkhrs,\n",
					"    IndicatorPartTimeEmployee,\n",
					"    S,\n",
					"    EmploymentStatus,\n",
					"    GenderKey,\n",
					"    TRAStartDate,\n",
					"    TRAEndDate,\n",
					"    TRAStatus,\n",
					"    TRAGrade,\n",
					"    PrevPersNo,\n",
					"    ActR,\n",
					"    ReasonforAction,\n",
					"    Position,\n",
					"    Position1,\n",
					"    CostCtr,\n",
					"    CostCentre,\n",
					"    CivilServiceStart,\n",
					"    DatetoCurrentJob,\n",
					"    SeniorityDate,\n",
					"    DatetoSubstGrade,\n",
					"    PersNo1,\n",
					"    NameofManagerOM,\n",
					"    ManagerPosition,\n",
					"    ManagerPositionText,\n",
					"    CounterSignManager,\n",
					"    Loc,\n",
					"    Location,\n",
					"    OrgStartDate,\n",
					"    FixTermEndDate,\n",
					"    LoanStartDate,\n",
					"    LoanEndDate,\n",
					"    EEGrp,\n",
					"    EmployeeGroup,\n",
					"    Annualsalary,\n",
					"    Curr,\n",
					"    NInumber,\n",
					"    Birthdate,\n",
					"    Ageofemployee,\n",
					"    EO,\n",
					"    Ethnicorigin,\n",
					"    NID,\n",
					"    Rel,\n",
					"    ReligiousDenominationKey,\n",
					"    SxO,\n",
					"    WageType,\n",
					"    EmployeeSubgroup,\n",
					"    LOAAbsType,\n",
					"    LOAAbsenceTypeText,\n",
					"    Schemereference,\n",
					"    PensionSchemeName,\n",
					"    DisabilityCode,\n",
					"    DisabilityText,\n",
					"    DisabilityCodeDescription,\n",
					"    PArea,\n",
					"    PayrollArea,\n",
					"    AssignmentNumber,\n",
					"    FTE2,\n",
					"    Report_MonthEnd_Date,\n",
					"    PDAC_ETL_Date\n",
					")\n",
					"SELECT\n",
					"    PersNo,\n",
					"    Firstname,\n",
					"    Lastname,\n",
					"    EmployeeNo,\n",
					"    CoCd,\n",
					"    CompanyCode,\n",
					"    PA,\n",
					"    PersonnelArea,\n",
					"    PSubarea,\n",
					"    PersonnelSubarea,\n",
					"    Orgunit,\n",
					"    OrganizationalUnit,\n",
					"    Organizationalkey,\n",
					"    OrganizationalKey1,\n",
					"    WorkC,\n",
					"    WorkContract,\n",
					"    CT,\n",
					"    ContractType,\n",
					"    PSgroup,\n",
					"    PayBandDescription,\n",
					"    cast(FTE AS FLOAT),\n",
					"    cast(Wkhrs AS FLOAT),\n",
					"    cast(IndicatorPartTimeEmployee AS BOOLEAN),\n",
					"    S,\n",
					"    EmploymentStatus,\n",
					"    GenderKey,\n",
					"    try_cast(TRAStartDate AS DATE),\n",
					"    try_cast(TRAEndDate AS DATE),\n",
					"    TRAStatus,\n",
					"    TRAGrade,\n",
					"    PrevPersNo,\n",
					"    ActR,\n",
					"    ReasonforAction,\n",
					"    Position,\n",
					"    Position1,\n",
					"    CostCtr,\n",
					"    CostCentre,\n",
					"    try_cast(CivilServiceStart AS DATE),\n",
					"    try_cast(DatetoCurrentJob AS DATE),\n",
					"    try_cast(SeniorityDate AS DATE),\n",
					"    try_cast(DatetoSubstGrade AS DATE),\n",
					"    PersNo1,\n",
					"    NameofManagerOM,\n",
					"    ManagerPosition,\n",
					"    ManagerPositionText,\n",
					"    CounterSignManager,\n",
					"    Loc,\n",
					"    Location,\n",
					"    try_cast(OrgStartDate AS DATE),\n",
					"    try_cast(FixTermEndDate AS DATE),\n",
					"    try_cast(LoanStartDate AS DATE),\n",
					"    try_cast(LoanEndDate AS DATE),\n",
					"    EEGrp,\n",
					"    EmployeeGroup,\n",
					"    cast(Annualsalary AS DOUBLE),\n",
					"    Curr,\n",
					"    NULL AS NInumber,\n",
					"    try_cast(Birthdate AS DATE),\n",
					"    cast(Ageofemployee AS INT),\n",
					"    EO,\n",
					"    Ethnicorigin,\n",
					"    NID,\n",
					"    Rel,\n",
					"    ReligiousDenominationKey,\n",
					"    SxO,\n",
					"    WageType,\n",
					"    EmployeeSubgroup,\n",
					"    LOAAbsType,\n",
					"    LOAAbsenceTypeText,\n",
					"    Schemereference,\n",
					"    PensionSchemeName,\n",
					"    DisabilityCode,\n",
					"    DisabilityText,\n",
					"    DisabilityCodeDescription,\n",
					"    PArea,\n",
					"    PayrollArea,\n",
					"    AssignmentNumber,\n",
					"    cast(FTE2 AS FLOAT),\n",
					"    NULL AS Report_MonthEnd_Date,\n",
					"    current_timestamp() AS PDAC_ETL_Date\n",
					"FROM odw_standardised_db.sap_hr_history_monthly\n",
					"\"\"\")"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"describe table odw_harmonised_db.SAP_HR"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"SELECT  * from odw_harmonised_db.SAP_HR"
				],
				"execution_count": 8
			}
		]
	}
}