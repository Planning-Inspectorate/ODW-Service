{
	"name": "appeals_has",
	"properties": {
		"folder": {
			"name": "odw-curated"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "2a4602aa-ea92-445a-9412-ba308e147671"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Import Packages"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.functions import *\n",
					"from pyspark.sql.types import *\n",
					"from pyspark.sql import DataFrame\n",
					"import json"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run utils/py_logging_decorator"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"db_name: str = \"odw_curated_db\"\n",
					"entity_name: str = \"appeal-has\"\n",
					"table_name: str = \"odw_curated_db.appeal_has\""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Create a view for the data, joining harmonised tables where necessary"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"df = spark.sql(\"\"\"\n",
					"\n",
					"SELECT DISTINCT \n",
					"\n",
					"AH.caseId                                   AS caseId,\n",
					"AH.caseReference                            AS caseReference,\n",
					"AH.submissionId                             AS submissionId,\n",
					"AH.caseStatus                               AS caseStatus,\n",
					"AH.caseType                                 AS caseType,\n",
					"AH.caseProcedure                            AS caseProcedure,\n",
					"AH.lpaCode                                  AS lpaCode,\n",
					"AH.caseOfficerId                            AS caseOfficerId,\n",
					"AH.inspectorId                              AS inspectorId,\n",
					"AH.allocationLevel                          AS allocationLevel,\n",
					"AH.allocationBand                           AS allocationBand,\n",
					"AH.caseSpecialisms                          AS caseSpecialisms,\n",
					"AH.caseSubmittedDate                        AS caseSubmittedDate,\n",
					"AH.caseCreatedDate                          AS caseCreatedDate,\n",
					"AH.caseUpdatedDate                          AS caseUpdatedDate,\n",
					"AH.caseValidDate                            AS caseValidDate,\n",
					"AH.caseValidationDate                       AS caseValidationDate,\n",
					"AH.caseValidationOutcome                    AS caseValidationOutcome,\n",
					"AH.caseValidationInvalidDetails             AS caseValidationInvalidDetails,\n",
					"AH.caseValidationIncompleteDetails          AS caseValidationIncompleteDetails,\n",
					"AH.caseExtensionDate                        AS caseExtensionDate,\n",
					"AH.caseStartedDate                          AS caseStartedDate,\n",
					"AH.casePublishedDate                        AS casePublishedDate,\n",
					"AH.linkedCaseStatus                         AS linkedCaseStatus,\n",
					"AH.leadCaseReference                        AS leadCaseReference,\n",
					"AH.lpaQuestionnaireDueDate                  AS lpaQuestionnaireDueDate,\n",
					"AH.lpaQuestionnaireSubmittedDate            AS lpaQuestionnaireSubmittedDate,\n",
					"AH.lpaQuestionnaireCreatedDate              AS lpaQuestionnaireCreatedDate,\n",
					"AH.lpaQuestionnairePublishedDate            AS lpaQuestionnairePublishedDate,\n",
					"AH.lpaQuestionnaireValidationOutcome        AS lpaQuestionnaireValidationOutcome,\n",
					"AH.lpaQuestionnaireValidationOutcomeDate    AS lpaQuestionnaireValidationOutcomeDate,\n",
					"AH.lpaQuestionnaireValidationDetails        AS lpaQuestionnaireValidationDetails,\n",
					"AH.lpaStatement                             AS lpaStatement,\n",
					"AH.caseWithdrawnDate                        AS caseWithdrawnDate,\n",
					"AH.caseTransferredDate                      AS caseTransferredDate,\n",
					"AH.transferredCaseClosedDate                AS transferredCaseClosedDate,\n",
					"AH.caseDecisionOutcomeDate                  AS caseDecisionOutcomeDate,\n",
					"AH.caseDecisionPublishedDate                AS caseDecisionPublishedDate,\n",
					"AH.caseDecisionOutcome                      AS caseDecisionOutcome,\n",
					"AH.caseCompletedDate                        AS caseCompletedDate,\n",
					"AH.enforcementNotice                        AS enforcementNotice,\n",
					"AH.applicationReference                     AS applicationReference,\n",
					"AH.applicationDate                          AS applicationDate,\n",
					"AH.applicationDecision                      AS applicationDecision,\n",
					"AH.applicationDecisionDate                  AS applicationDecisionDate,\n",
					"AH.caseSubmissionDueDate                    AS caseSubmissionDueDate,\n",
					"AH.siteAddressLine1                         AS siteAddressLine1,\n",
					"AH.siteAddressLine2                         AS siteAddressLine2,\n",
					"AH.siteAddressTown                          AS siteAddressTown,\n",
					"AH.siteAddressCounty                        AS siteAddressCounty,\n",
					"AH.siteAddressPostcode                      AS siteAddressPostcode,\n",
					"AH.siteAccessDetails                        AS siteAccessDetails,\n",
					"AH.siteSafetyDetails                        AS siteSafetyDetails,\n",
					"AH.siteAreaSquareMetres                     AS siteAreaSquareMetres,\n",
					"AH.floorSpaceSquareMetres                   AS floorSpaceSquareMetres,\n",
					"AH.isCorrectAppealType                      AS isCorrectAppealType,\n",
					"AH.isGreenBelt                              AS isGreenBelt,\n",
					"AH.inConservationArea                       AS inConservationArea,\n",
					"AH.ownsAllLand                              AS ownsAllLand,\n",
					"AH.ownsSomeLand                             AS ownsSomeLand,\n",
					"AH.knowsOtherOwners                         AS knowsOtherOwners,\n",
					"AH.knowsAllOwners                           AS knowsAllOwners,\n",
					"AH.advertisedAppeal                         AS advertisedAppeal,\n",
					"AH.notificationMethod                       AS notificationMethod,\n",
					"AH.ownersInformed                           AS ownersInformed,\n",
					"AH.originalDevelopmentDescription           AS originalDevelopmentDescription,\n",
					"AH.changedDevelopmentDescription            AS changedDevelopmentDescription,\n",
					"AH.newConditionDetails                      AS newConditionDetails,\n",
					"AH.nearbyCaseReferences                     AS nearbyCaseReferences,\n",
					"AH.neighbouringSiteAddresses                AS neighbouringSiteAddresses,\n",
					"AH.affectedListedBuildingNumbers            AS affectedListedBuildingNumbers,\n",
					"AH.appellantCostsAppliedFor                 AS appellantCostsAppliedFor,\n",
					"AH.lpaCostsAppliedFor                       AS lpaCostsAppliedFor\n",
					"\n",
					"FROM odw_harmonised_db.sb_appeal_has AS AH\n",
					"WHERE AH.IsActive = 'Y'\n",
					"\"\"\"\n",
					")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Define schema"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"schema = mssparkutils.notebook.run(\"py_create_spark_schema\", 30, {\"db_name\": db_name, \"entity_name\": entity_name})\n",
					"spark_schema = StructType.fromJson(json.loads(schema))"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Create DataFrame with the correct schema"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"data = spark.createDataFrame(df.rdd, schema=spark_schema)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Print the schema as a visual check"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df.printSchema()"
				],
				"execution_count": 17
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Write DataFrame to table"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"logInfo(f\"Writing to {table_name}\")\n",
					"df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(table_name)\n",
					"logInfo(f\"Written to {table_name}\")"
				],
				"execution_count": null
			}
		]
	}
}