{
	"name": "SAP_HR_LEAVERS",
	"properties": {
		"folder": {
			"name": "odw-harmonised"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "13fa34d9-49b0-463d-a7ed-e49afd43d745"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Entity Name : SAP_HR_LEAVERS\n",
					"###### Author: Prathap A\n",
					"###### Date: 25/02/2025\n",
					"\n",
					"###### version : 0001\n",
					"###### <u>Description</u>:\n",
					"This template is designed to facilitate the monthly processing and harmonization of SAP HR data. It includes steps for initializing the environment, creating and managing Delta tables, and inserting data into harmonized tables. The template ensures that HR data is accurately transformed, stored, and made available for reporting and analysis."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Intialisations"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import udf, col, lit, when, coalesce, concat, sum, avg, max, min, count, countDistinct, date_format, to_date, datediff, months_between, year, month,  hour, minute, second, expr, asc, desc\n",
					"from pyspark.sql.types import DateType, TimestampType, StringType, IntegerType, FloatType, DoubleType, BooleanType, StructType, StructField, ArrayType, MapType\n",
					"from pyspark.sql.window import Window\n",
					"from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead, ntile\n",
					"from pyspark.sql import SQLContext\n",
					"from pyspark.sql import DataFrame\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.avro.functions import from_avro, to_avro\n",
					"from pyspark.sql.streaming import DataStreamReader, DataStreamWriter\n",
					"from pyspark.sql.utils import AnalysisException\n",
					"from pyspark.sql.catalog import Catalog\n",
					"from pyspark.sql.column import Column\n",
					"from pyspark.sql.group import GroupedData\n",
					"from pyspark.sql.pandas.functions import pandas_udf\n",
					"\n",
					"from datetime import datetime, timedelta\n",
					"import pandas as pd\n",
					"import numpy as np"
				],
				"execution_count": 27
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# staging load"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"SET spark.sql.legacy.timeParserPolicy = LEGACY; -- Enables support for flexible date parsing\n",
					"\n",
					"-- Delete records where PersNo is null\n",
					"DELETE FROM odw_harmonised_db.stage_SAP_HR_Leavers \n",
					"WHERE PersNo IS NULL;\n",
					"\n",
					"-- Insert data into the harmonised table\n",
					"INSERT INTO odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"(\n",
					"    PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract,       \n",
					"    OrgStartDate,  \n",
					"    Leaving,       \n",
					"    Act,                \n",
					"    ActionType,         \n",
					"    ActR,               \n",
					"    ReasonforAction,    \n",
					"    S,                  \n",
					"    EmploymentStatus,  \n",
					"    EmployeeNo,         \n",
					"    Position,           \n",
					"    Position1,  \n",
					"    Annualsalary,        \n",
					"    Curr,               \n",
					"    UserID,             \n",
					"    EmailAddress,       \n",
					"    PersNo1,            \n",
					"    NameofManagerOM,    \n",
					"    ManagerPosition,    \n",
					"    ManagerPositionText, \n",
					"    LMEmail,\n",
					"    SourceSystemID,\n",
					"    IngestionDate,\n",
					"    ValidTo,\n",
					"    RowID,\n",
					"    IsActive   \n",
					")              \n",
					"SELECT \n",
					"    PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract,  \n",
					"    CASE \n",
					"        WHEN OrgStartDate IS NULL OR TRIM(OrgStartDate) = '' THEN NULL -- Handle NULL or empty values\n",
					"        WHEN OrgStartDate LIKE '%/%' THEN \n",
					"            TO_DATE(OrgStartDate, 'd/M/yy') -- Convert dates with slashes (handles single-digit days/months)\n",
					"        ELSE \n",
					"            TO_DATE(OrgStartDate, 'yyyy-MM-dd') -- Convert dates with dashes \n",
					"    END AS OrgStartDate,\n",
					"    CASE \n",
					"        WHEN Leaving IS NULL OR TRIM(Leaving) = '' THEN NULL -- Handle NULL \n",
					"        WHEN Leaving LIKE '%/%' THEN \n",
					"            TO_DATE(Leaving, 'd/M/yy') -- Convert dates with slashes (handles single-digit days/months)\n",
					"        ELSE \n",
					"            TO_DATE(Leaving, 'yyyy-MM-dd') -- Convert dates with dashes (standard format)\n",
					"    END AS Leaving,\n",
					"    Act,                \n",
					"    ActionType,         \n",
					"    ActR,               \n",
					"    ReasonforAction,    \n",
					"    S,                  \n",
					"    EmploymentStatus,  \n",
					"    EmployeeNo,         \n",
					"    Position,           \n",
					"    Position1, \n",
					"    NULL AS Annualsalary,       \n",
					"    Curr,               \n",
					"    UserID,             \n",
					"    EmailAddress,       \n",
					"    PersNo1,            \n",
					"    NameofManagerOM,    \n",
					"    ManagerPosition,    \n",
					"    ManagerPositionText,  -- Corrected column name\n",
					"    LMEmail,\n",
					"    'saphr' AS SourceSystemID,\n",
					"    CURRENT_DATE() AS IngestionDate,\n",
					"    CURRENT_TIMESTAMP() AS ValidTo,\n",
					"    NULL AS RowID,\n",
					"    'Y' AS IsActive\n",
					"FROM \n",
					"    odw_standardised_db.sap_hr_leavers_monthly;"
				],
				"execution_count": 37
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Update Statements"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"set EmployeeNo = '' \n",
					"where EmployeeNo is null\n",
					""
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"set Leaving = '2024-02-29'\n",
					" where PersNo = '50426514'"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"\n",
					"%%sql\n",
					"\n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"set Leaving = current_date()\n",
					""
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"\t%%sql\n",
					"    \n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers \n",
					" set Annualsalary = null;"
				],
				"execution_count": 33
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# HashKey Build"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"UPDATE odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"SET RowID = md5(\n",
					"    concat_ws('|',\n",
					" PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract\n",
					"    )\n",
					")"
				],
				"execution_count": 34
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"delete   from odw_harmonised_db.SAP_HR_Leavers"
				],
				"execution_count": 35
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# odw_harmonised_db.SAP_HR_Leavers"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from delta.tables import DeltaTable\n",
					"from pyspark.sql import Window\n",
					"from pyspark.sql.functions import row_number,col\n",
					"\n",
					"# Step 1: Update Annualsalary to null\n",
					"delta_table = DeltaTable.forName(spark, \"odw_harmonised_db.stage_SAP_HR_Leavers\")\n",
					"delta_table.update(\"Annualsalary IS NOT NULL\", {\"Annualsalary\": \"null\"})\n",
					"\n",
					"# Step 2: Delete duplicates\n",
					"# Create a DataFrame from the Delta table\n",
					"df = delta_table.toDF()\n",
					"\n",
					"# Add a row number column to identify duplicates\n",
					"window_spec = Window.partitionBy(\"PersNo\", \"Leaving\").orderBy(\"PersNo\", \"Leaving\")\n",
					"df_with_row_number = df.withColumn(\"val\", row_number().over(window_spec))\n",
					"\n",
					"# Filter out duplicates (keep only the first occurrence)\n",
					"df_filtered = df_with_row_number.filter(col(\"val\") == 1).drop(\"val\")\n",
					"\n",
					"# Overwrite the Delta table with the cleaned data\n",
					"df_filtered.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"odw_harmonised_db.stage_SAP_HR_Leavers\")\n",
					"\n",
					"# Step 3: Delete records from SAP_HR_Leavers within the date range\n",
					"# Calculate min and max dates\n",
					"min_year = df.selectExpr(\"YEAR(MIN(Leaving))\").collect()[0][0]\n",
					"max_year = df.selectExpr(\"YEAR(MAX(Leaving))\").collect()[0][0]\n",
					"mindate = f\"{min_year}-04-01\"\n",
					"maxdate = f\"{max_year + 1}-03-31\"\n",
					"\n",
					"# Delete records from the target table\n",
					"target_table = DeltaTable.forName(spark, \"odw_harmonised_db.SAP_HR_Leavers\")\n",
					"target_table.delete(f\"Leaving BETWEEN '{mindate}' AND '{maxdate}'\")\n",
					"\n",
					"# Step 4: Insert records into SAP_HR_Leavers\n",
					"df_filtered.write.format(\"delta\").mode(\"append\").saveAsTable(\"odw_harmonised_db.SAP_HR_Leavers\")"
				],
				"execution_count": 36
			}
		]
	}
}