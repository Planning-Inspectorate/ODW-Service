{
	"name": "SAP_HR_LEAVERS",
	"properties": {
		"folder": {
			"name": "odw-harmonised"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "b3d74331-a113-4e55-9642-9f7929f0e8c3"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Entity Name : SAP_HR_LEAVERS\n",
					"###### Author: Prathap A\n",
					"###### Date: 25/02/2025\n",
					"\n",
					"###### version : 0001\n",
					"###### <u>Description</u>:\n",
					"This template is designed to facilitate the monthly processing and harmonization of SAP HR data. It includes steps for initializing the environment, creating and managing Delta tables, and inserting data into harmonized tables. The template ensures that HR data is accurately transformed, stored, and made available for reporting and analysis."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Intialisations"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import udf, col, lit, when, coalesce, concat, sum, avg, max, min, count, countDistinct, date_format, to_date, datediff, months_between, year, month,  hour, minute, second, expr, asc, desc\n",
					"from pyspark.sql.types import DateType, TimestampType, StringType, IntegerType, FloatType, DoubleType, BooleanType, StructType, StructField, ArrayType, MapType\n",
					"from pyspark.sql.window import Window\n",
					"from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead, ntile\n",
					"from pyspark.sql import SQLContext\n",
					"from pyspark.sql import DataFrame\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.avro.functions import from_avro, to_avro\n",
					"from pyspark.sql.streaming import DataStreamReader, DataStreamWriter\n",
					"from pyspark.sql.utils import AnalysisException\n",
					"from pyspark.sql.catalog import Catalog\n",
					"from pyspark.sql.column import Column\n",
					"from pyspark.sql.group import GroupedData\n",
					"from pyspark.sql.pandas.functions import pandas_udf\n",
					"\n",
					"from datetime import datetime, timedelta\n",
					"import pandas as pd\n",
					"import numpy as np"
				],
				"execution_count": 105
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# staging load"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"SET spark.sql.legacy.timeParserPolicy = LEGACY; -- Enables support for flexible date parsing\n",
					"\n",
					"-- Delete records where PersNo is null\n",
					"DELETE FROM odw_harmonised_db.stage_SAP_HR_Leavers \n",
					"WHERE PersNo IS NULL;\n",
					"\n",
					"-- Insert data into the harmonised table\n",
					"INSERT INTO odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"(\n",
					"    PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract,       \n",
					"    OrgStartDate,  \n",
					"    Leaving,       \n",
					"    Act,                \n",
					"    ActionType,         \n",
					"    ActR,               \n",
					"    ReasonforAction,    \n",
					"    S,                  \n",
					"    EmploymentStatus,  \n",
					"    EmployeeNo,         \n",
					"    Position,           \n",
					"    Position1,  \n",
					"    Annualsalary,        \n",
					"    Curr,               \n",
					"    UserID,             \n",
					"    EmailAddress,       \n",
					"    PersNo1,            \n",
					"    NameofManagerOM,    \n",
					"    ManagerPosition,    \n",
					"    ManagerPositionText, \n",
					"    LMEmail,\n",
					"    SourceSystemID,\n",
					"    IngestionDate,\n",
					"    ValidTo,\n",
					"    RowID,\n",
					"    IsActive   \n",
					")              \n",
					"SELECT \n",
					"    PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract,  \n",
					"cast(to_timestamp(OrgStartDate,'dd/MM/yyyy')  as date) as OrgStartDate ,\n",
					"cast(to_timestamp(Leaving,'dd/MM/yyyy')  as date) as Leaving,  -- Convert dates with dashes (standard format)\n",
					"    Act,                \n",
					"    ActionType,         \n",
					"    ActR,               \n",
					"    ReasonforAction,    \n",
					"    S,                  \n",
					"    EmploymentStatus,  \n",
					"    EmployeeNo,         \n",
					"    Position,           \n",
					"    Position1, \n",
					"     Annualsalary,       \n",
					"    Curr,               \n",
					"    UserID,             \n",
					"    EmailAddress,       \n",
					"    PersNo1,            \n",
					"    NameofManagerOM,    \n",
					"    ManagerPosition,    \n",
					"    ManagerPositionText,  -- Corrected column name\n",
					"    LMEmail,\n",
					"    'saphr' AS SourceSystemID,\n",
					"    CURRENT_DATE() AS IngestionDate,\n",
					"    CURRENT_TIMESTAMP() AS ValidTo,\n",
					"    NULL AS RowID,\n",
					"    'Y' AS IsActive\n",
					"FROM \n",
					"    odw_standardised_db.sap_hr_leavers_monthly;"
				],
				"execution_count": 106
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Update Statements"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"set EmployeeNo = '' \n",
					"where EmployeeNo is null\n",
					""
				],
				"execution_count": 107
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"set Leaving = '2024-02-29'\n",
					" where PersNo = '50426514'"
				],
				"execution_count": 108
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"\n",
					"%%sql\n",
					"\n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"set Leaving = current_date()\n",
					""
				],
				"execution_count": 109
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"    \n",
					"update odw_harmonised_db.stage_SAP_HR_Leavers \n",
					" set Annualsalary = null;"
				],
				"execution_count": 110
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# HashKey Build"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"UPDATE odw_harmonised_db.stage_SAP_HR_Leavers\n",
					"SET RowID = md5(\n",
					"    concat_ws('|',\n",
					" PersNo,            \n",
					"    Lastname,     \n",
					"    Firstname,       \n",
					"    CoCd,        \n",
					"    CompanyCode,        \n",
					"    Loc,                \n",
					"    Location,         \n",
					"    PSgroup,             \n",
					"    PayBandDescription,  \n",
					"    Orgunit,            \n",
					"    OrganizationalUnit, \n",
					"    PA,                 \n",
					"    PersonnelArea,      \n",
					"    PSubarea,           \n",
					"    PersonnelSubarea,   \n",
					"    WorkC,              \n",
					"    WorkContract\n",
					"    )\n",
					")"
				],
				"execution_count": 111
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"delete from odw_harmonised_db.load_SAP_HR_Leavers"
				],
				"execution_count": 112
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# odw_harmonised_db.SAP_HR_Leavers"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from delta.tables import DeltaTable\n",
					"from pyspark.sql import Window\n",
					"from pyspark.sql.functions import row_number, col\n",
					"\n",
					"# Step 1: Update Annualsalary to null\n",
					"delta_table = DeltaTable.forName(spark, \"odw_harmonised_db.stage_SAP_HR_Leavers\")\n",
					"delta_table.update(\"Annualsalary IS NOT NULL\", {\"Annualsalary\": \"null\"})\n",
					"\n",
					"# Step 2: Delete duplicates\n",
					"# Create a DataFrame from the Delta table\n",
					"df = delta_table.toDF()\n",
					"\n",
					"# Add a row number column to identify duplicates\n",
					"window_spec = Window.partitionBy(\"PersNo\", \"Leaving\").orderBy(\"PersNo\", \"Leaving\")\n",
					"df_with_row_number = df.withColumn(\"val\", row_number().over(window_spec))\n",
					"\n",
					"# Filter out duplicates (keep only the first occurrence)\n",
					"df_filtered = df_with_row_number.filter(col(\"val\") == 1).drop(\"val\")\n",
					"\n",
					"# Step 3: Align schemas (cast OrgStartDate to match the target table)\n",
					"#df_filtered = df_filtered.withColumn(\"OrgStartDate\", col(\"OrgStartDate\").cast(\"string\"))\n",
					"\n",
					"# Step 4: Delete records from SAP_HR_Leavers within the date range\n",
					"# Calculate min and max dates\n",
					"min_year = df.selectExpr(\"YEAR(MIN(Leaving))\").collect()[0][0]\n",
					"max_year = df.selectExpr(\"YEAR(MAX(Leaving))\").collect()[0][0]\n",
					"\n",
					"# Handle None values for min_year and max_year\n",
					"if min_year is None or max_year is None:\n",
					"    raise ValueError(\"The 'Leaving' column contains no valid dates. Please check the data.\")\n",
					"\n",
					"mindate = f\"{min_year}-04-01\"\n",
					"maxdate = f\"{max_year + 1}-03-31\"\n",
					"\n",
					"# Delete records from the target table\n",
					"target_table = DeltaTable.forName(spark, \"odw_harmonised_db.SAP_HR_Leavers\")\n",
					"target_table.delete(f\"Leaving BETWEEN '{mindate}' AND '{maxdate}'\")\n",
					"\n",
					"# Step 5: Insert records into SAP_HR_Leavers\n",
					"df_filtered.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"odw_harmonised_db.load_SAP_HR_Leavers\")"
				],
				"execution_count": 113
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}