{
	"name": "checkmark_reading_case",
	"properties": {
		"folder": {
			"name": "odw-harmonised/Checkmark"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "93076b50-170e-446a-940f-cf24129b8e04"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW reading_case_grouped\r\n",
					"\r\n",
					"    AS\r\n",
					"\r\n",
					"SELECT case_reference,\r\n",
					"inspector_email,\r\n",
					"inspector_name,\r\n",
					"reader_email,\r\n",
					"reader_name,\r\n",
					"case_level,\r\n",
					"date_submitted_by_inspector,\r\n",
					"event_date,\r\n",
					"type_of_reading,\r\n",
					"procedure,\r\n",
					"case_target_date,\r\n",
					"reading_status,\r\n",
					"able_to_read_decision,\r\n",
					"advertisement,\r\n",
					"appeal_against_conditions,\r\n",
					"bespoke,\r\n",
					"case_team_officer_email,\r\n",
					"case_team_officer_name,\r\n",
					"costs_decision,\r\n",
					"green_belt,\r\n",
					"kiosk,\r\n",
					"linked,\r\n",
					"neighbourhood_plan, \r\n",
					"nsi_email,\r\n",
					"nsi_name,\r\n",
					"prior_approval,\r\n",
					"reason_for_delay,\r\n",
					"redetermination,\r\n",
					"secretary_of_state_report,\r\n",
					"spa_sac_eps,\r\n",
					"special_category_data,\r\n",
					"specialisms,\r\n",
					"telecommunications,\r\n",
					"urgent,\r\n",
					"amendments_received_notification_needed,\r\n",
					"able_to_check_amendments,\r\n",
					"amendments_cycles,\r\n",
					"amendments_target_date,\r\n",
					"amendments_timeliness_review_flag,\r\n",
					"date_amendments_checked,\r\n",
					"date_amendments_received,\r\n",
					"date_cleared,\r\n",
					"date_decision_sent_for_issue,\r\n",
					"date_read,\r\n",
					"date_read_started,\r\n",
					"decision_read,\r\n",
					"delayed_amendments_submission,\r\n",
					"delayed_submission,\r\n",
					"document_version,\r\n",
					"document_version_needed,\r\n",
					"final_decision_notification_needed,\r\n",
					"notification_sent_flag,\r\n",
					"on_hold_notification_needed,\r\n",
					"on_hold_status, \r\n",
					"reading_complete_notification_needed,\r\n",
					"reading_needed_flag,\r\n",
					"ready_for_issue,\r\n",
					"reason_for_amendments_delay,\r\n",
					"recall_notification_needed,\r\n",
					"replacement_decision_flag,\r\n",
					"return_count,\r\n",
					"revised_decision_notification_needed,\r\n",
					"skim_read,\r\n",
					"source,\r\n",
					"timeliness_review_flag,\r\n",
					"date_modified\r\n",
					"\r\n",
					"FROM odw_standardised_db.checkmark_reading_case\r\n",
					"Where case_reference is not null\r\n",
					"GROUP BY case_reference,\r\n",
					"inspector_email,\r\n",
					"inspector_name,\r\n",
					"reader_email,\r\n",
					"reader_name,\r\n",
					"case_level,\r\n",
					"date_submitted_by_inspector,\r\n",
					"event_date,\r\n",
					"type_of_reading,\r\n",
					"procedure,\r\n",
					"case_target_date,\r\n",
					"reading_status,\r\n",
					"able_to_read_decision,\r\n",
					"advertisement,\r\n",
					"appeal_against_conditions,\r\n",
					"bespoke,\r\n",
					"case_team_officer_email,\r\n",
					"case_team_officer_name,\r\n",
					"costs_decision,\r\n",
					"green_belt,\r\n",
					"kiosk,\r\n",
					"linked,\r\n",
					"neighbourhood_plan, \r\n",
					"nsi_email,\r\n",
					"nsi_name,\r\n",
					"prior_approval,\r\n",
					"reason_for_delay,\r\n",
					"redetermination,\r\n",
					"secretary_of_state_report,\r\n",
					"spa_sac_eps,\r\n",
					"special_category_data,\r\n",
					"specialisms,\r\n",
					"telecommunications,\r\n",
					"urgent,\r\n",
					"amendments_received_notification_needed,\r\n",
					"able_to_check_amendments,\r\n",
					"amendments_cycles,\r\n",
					"amendments_target_date,\r\n",
					"amendments_timeliness_review_flag,\r\n",
					"date_amendments_checked,\r\n",
					"date_amendments_received,\r\n",
					"date_cleared,\r\n",
					"date_decision_sent_for_issue,\r\n",
					"date_read,\r\n",
					"date_read_started,\r\n",
					"decision_read,\r\n",
					"delayed_amendments_submission,\r\n",
					"delayed_submission,\r\n",
					"document_version,\r\n",
					"document_version_needed,\r\n",
					"final_decision_notification_needed,\r\n",
					"notification_sent_flag,\r\n",
					"on_hold_notification_needed,\r\n",
					"on_hold_status, \r\n",
					"reading_complete_notification_needed,\r\n",
					"reading_needed_flag,\r\n",
					"ready_for_issue,\r\n",
					"reason_for_amendments_delay,\r\n",
					"recall_notification_needed,\r\n",
					"replacement_decision_flag,\r\n",
					"return_count,\r\n",
					"revised_decision_notification_needed,\r\n",
					"skim_read,\r\n",
					"source,\r\n",
					"timeliness_review_flag,\r\n",
					"date_modified"
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Check for new, updated or deleted data\n",
					"- This script checks for new, updated or deleted data by checking the source data (checkmark) against the target (odw_harmonised_db.comment_fact)\n",
					"- **New Data:** where a TypeId in the source does not exist as an id in the target. NewData flag is set to 'Y'\n",
					"- **Updated data:** Comparison occurs on TypeId in source and id in target where the row hash is different i.e. there is a change in one of the columns. NewData flag is set to 'Y'\n",
					"- **Deleted data:** where an id in the target exists but the same TypeId doesn't exist in the source. DeletedData flag is set to 'Y'\n",
					"\n",
					"## View comment_type_reference_dim_new is created"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"-- Build reading_case_dim table\r\n",
					"-- Gets modified or deleted from source rows\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY VIEW reading_case_dim_new\r\n",
					"\r\n",
					"    AS\r\n",
					"\r\n",
					"-- gets data that matches of SourceID and flags that it is modified based on a row (md5) hash. Flags as \"NewData\"\r\n",
					"-- gets data that is in the target but not in source. Flags as \"DeletedData\"\r\n",
					"\r\n",
					"SELECT\r\n",
					"    CASE\r\n",
					"        WHEN T1.id IS NULL\r\n",
					"        THEN T3.ReadingCaseID\r\n",
					"        ELSE NULL\r\n",
					"    END AS ReadingCaseID, -- surrogate key\r\n",
					"    \r\n",
					"\r\n",
					"    T1.case_reference AS CaseReference,\r\n",
					"    T1.inspector_email AS InspectorEmail,\r\n",
					"    T1.inspector_name AS InspectorName,\r\n",
					"    T1.reader_email AS ReaderEmail,\r\n",
					"    T1.reader_name AS ReaderName,\r\n",
					"    T1.case_level AS CaseLevel,\r\n",
					"    T1.date_submitted_by_inspector AS DateSubmittedByInspector,\r\n",
					"    T1.event_date AS EventDate,\r\n",
					"    T1.type_of_reading AS TypeOfReading,\r\n",
					"    T1.procedure AS Procedure,\r\n",
					"    T1.case_target_date AS CaseTargetDate,\r\n",
					"    T1.reading_status AS ReadingStatus,\r\n",
					"    T1.able_to_read_decision AS AbleToReadDecision,\r\n",
					"    T1.advertisement AS Advertisement,\r\n",
					"    T1.appeal_against_conditions AS AppealAgainstConditions,\r\n",
					"    T1.bespoke AS Bespoke,\r\n",
					"    T1.case_team_officer_email AS CaseTeamOfficerEmail,\r\n",
					"    T1.case_team_officer_name AS CaseTeamOfficerName,\r\n",
					"    T1.costs_decision AS CostsDecision,\r\n",
					"    T1.green_belt AS GreenBelt,\r\n",
					"    T1.kiosk AS Kiosk,\r\n",
					"    T1.linked AS Linked,\r\n",
					"    T1.neighbourhood_plan, AS NeibourhoodPlan,\r\n",
					"    T1.nsi_email AS NSIEmail,\r\n",
					"    T1.nsi_name AS NSIName,\r\n",
					"    T1.prior_approval AS PriorApproval,\r\n",
					"    T1.reason_for_delay AS ReasonForDelay,\r\n",
					"    T1.redetermination AS Redetermination,\r\n",
					"    T1.secretary_of_state_report AS SecretaryOfStateReport,\r\n",
					"    T1.spa_sac_eps AS SPASACEPS,\r\n",
					"    T1.special_category_data AS SpecialCategoryData,\r\n",
					"    T1.specialisms AS Specialisms,\r\n",
					"    T1.telecommunications AS Telecommunications,\r\n",
					"    T1.urgent AS Urgent,\r\n",
					"    T1.amendments_received_notification_needed AS AmendmentsReceivedNotificationsNeeded,\r\n",
					"    T1.able_to_check_amendments AS AbleToCheckAmendments,\r\n",
					"    T1.amendments_cycles AS AmendmentsCycles,\r\n",
					"    T1.amendments_target_date AS AmendmentsTargetDate,\r\n",
					"    T1.amendments_timeliness_review_flag AS AmendmentsTimelineReviewFlag,\r\n",
					"    T1.date_amendments_checked AS DateAmendmentsChecked,\r\n",
					"    T1.date_amendments_received AS DateAmendmentsReceived,\r\n",
					"    T1.date_cleared AS DateCleared,\r\n",
					"    T1.date_decision_sent_for_issue AS DateDecisionSentForIssue,\r\n",
					"    T1.date_read AS DateRead,\r\n",
					"    T1.date_read_started AS DateReadStarted,\r\n",
					"    T1.decision_read AS DecisionRead,\r\n",
					"    T1.delayed_amendments_submission AS DelayedAmendmentsSubmission,\r\n",
					"    T1.delayed_submission AS DelayedSubmission,\r\n",
					"    T1.document_version AS DocumentVersion,\r\n",
					"    T1.document_version_needed AS DocumentVersionNeeded,\r\n",
					"    T1.final_decision_notification_needed AS FinalDecisionNotificationNeeded,\r\n",
					"    T1.notification_sent_flag AS NotificationSentFlag,\r\n",
					"    T1.on_hold_notification_needed AS OnHoldNotificationNeeded,\r\n",
					"    T1.on_hold_status AS OnHoldStatus,\r\n",
					"    T1.reading_complete_notification_needed AS ReadingCompleteNotificationNeeded,\r\n",
					"    T1.reading_needed_flag AS ReadingNeededFlag,\r\n",
					"    T1.ready_for_issue AS ReadyForIssue,\r\n",
					"    T1.reason_for_amendments_delay AS ReasonForAmendmentsDelay,\r\n",
					"    T1.recall_notification_needed AS RecallNotificationNeeded,\r\n",
					"    T1.replacement_decision_flag AS ReplacementDecisionFlag,\r\n",
					"    T1.return_count AS ReturnCount,\r\n",
					"    T1.revised_decision_notification_needed AS RevisedDecisionNotificationNeeded,\r\n",
					"    T1.skim_read AS SkimRead,\r\n",
					"    T1.source AS Source,\r\n",
					"    T1.timeliness_review_flag AS TimelinessReviewFlag,\r\n",
					"    T1.date_modified AS DateModified,\r\n",
					"\r\n",
					"\r\n",
					"    T2.SourceSystemID as SourceSystemID, -- NOT CORRECT\r\n",
					"    CURRENT_TIMESTAMP AS IngestionDate,\r\n",
					"    NULL AS ValidTo,\r\n",
					"    md5(concat( IFNULL(T1.id,'.'), IFNULL(T1.value,'.'))) AS RowID,\r\n",
					"    'Y' as IsActive,\r\n",
					"    CASE\r\n",
					"        WHEN T1.id = T3.StateID AND md5(concat(IFNULL(T1.id,'.'), IFNULL(T1.value,'.'))) <> T3.RowID\r\n",
					"        THEN 'Y'\r\n",
					"        WHEN T3.StateID IS NULL\r\n",
					"        THEN 'Y'\r\n",
					"        ELSE 'N'\r\n",
					"    END as NewData,\r\n",
					"    CASE\r\n",
					"        WHEN T1.id IS NULL\r\n",
					"        THEN 'Y'\r\n",
					"        ELSE 'N'\r\n",
					"    END AS  DeletedData,\r\n",
					"    T3.IsActive as HistoricIsActive\r\n",
					"\r\n",
					"FROM reading_case_grouped T1\r\n",
					"LEFT JOIN odw_harmonised_db.main_sourcesystem_fact T2 ON \"Checkmark\" = T2.Description\r\n",
					"FULL JOIN odw_harmonised_db.checkmark_reading_case_dim T3 ON T1.id = T3.StateID and T3.IsActive = 'Y'\r\n",
					"WHERE\r\n",
					"    (-- flags new data        \r\n",
					"        (CASE\r\n",
					"            WHEN T1.ID = T3.StateID AND md5(concat( IFNULL(T1.id,'.'), IFNULL(T1.value,'.'))) <> T3.RowID\r\n",
					"            THEN 'Y'\r\n",
					"            WHEN T3.StateID IS NULL\r\n",
					"            THEN 'Y'\r\n",
					"            ELSE 'N'\r\n",
					"        END  = 'Y' ) OR\r\n",
					"        -- flags deleted data\r\n",
					"        (CASE\r\n",
					"            WHEN T1.id IS NULL\r\n",
					"            THEN 'Y'\r\n",
					"            ELSE 'N'\r\n",
					"        END = 'Y' )\r\n",
					"    )\r\n",
					";"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Run tests to check integrity of data by numbers\n",
					"- This script checks for the total number of current codes in the harmonised table, and compare against the numbers for new data to be added and data to be set as inactive.\n",
					"- **Changes tracking:** where it checks the data against active records in harmonised and compares with records to add and records to be set as inactive.\n",
					"- **Changes tolerance levels:** if the total amount to be added and deleted surpasses the tolerance limit, it will interrupt the proces of loading the data"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# from pyspark.sql import SparkSession\r\n",
					"# spark = SparkSession.builder.getOrCreate()\r\n",
					"\r\n",
					"# Source_Number = spark.sql(\"SELECT COUNT(*) AS Source_Number FROM sxo_grouped\")\r\n",
					"# Current_Number = spark.sql(\"SELECT COUNT (DISTINCT RowID) AS Current_Number FROM odw_harmonised_db.sxo_dim where IsActive = 'Y' \")\r\n",
					"# New_Data_Number = spark.sql(\"SELECT COUNT (DISTINCT RowID) AS New_Data_Number FROM sxo_dim_new WHERE NewData = 'Y'\")\r\n",
					"# Deleted_Data_Number = spark.sql(\"SELECT COUNT (DISTINCT RowID) AS Deleted_Data_Number FROM sxo_dim_new WHERE DeletedData = 'Y'\")\r\n",
					"\r\n",
					"# Source_Number_Pandas = Source_Number.toPandas()\r\n",
					"# Current_Number_Pandas =  Current_Number.toPandas()\r\n",
					"# New_Data_Number_Pandas = New_Data_Number.toPandas()\r\n",
					"# Deleted_Data_Number_Pandas = Deleted_Data_Number.toPandas()\r\n",
					"\r\n",
					"# # checking if new total number of registers matches the previously loaded, plus New ones, minus Deleted ones\r\n",
					"# print(\"SET 1:\")\r\n",
					"# Total_Number = Source_Number_Pandas['Source_Number'].tolist() \r\n",
					"# Current_Loaded_Number = Current_Number_Pandas['Current_Number'].tolist() \r\n",
					"# New_Data_Number = New_Data_Number_Pandas['New_Data_Number'].tolist() \r\n",
					"# Deleted_Data_Number = Deleted_Data_Number_Pandas['Deleted_Data_Number'].tolist() \r\n",
					"\r\n",
					"# print(Total_Number) \r\n",
					"# print(Current_Loaded_Number) \r\n",
					"# print(New_Data_Number) \r\n",
					"# print(Deleted_Data_Number)\r\n",
					"\r\n",
					"#if Total_Number[0] != (Current_Loaded_Number[0] + New_Data_Number[0] - Deleted_Data_Number[0]):\r\n",
					"    #raise RuntimeError(\"Loading Number do not match\")\r\n",
					"#else:\r\n",
					"#    print(\"Loading number matches with existing codes plus new, minus deleted!\")\r\n",
					"\r\n",
					"#if New_Data_Number[0] > 1000:\r\n",
					"    #raise RuntimeError(\"ALERT: Too many new codes\")\r\n",
					"#else:\r\n",
					"#    print(\"New data under tolerance levels\")\r\n",
					"\r\n",
					"#if Deleted_Data_Number[0] > 500:\r\n",
					"    #raise RuntimeError(\"ALERT: Too many deleted codes\")\r\n",
					"#else:\r\n",
					"#    print(\"Unused codes under tolerance levels\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Run tests to check integrity of data by comparison of codes\n",
					"- This script checks for the total list of current codes in the harmonised table, and compare against the list for new data to be added and data to be set as inactive.\n",
					"- **Changes tracking:** where it checks the data against active records in harmonised and compares with records to add and records to be set as inactive."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# from pyspark.sql import SparkSession\r\n",
					"# spark = SparkSession.builder.getOrCreate()\r\n",
					"\r\n",
					"# Current_Records = spark.sql(\"SELECT DISTINCT RowID AS Current_Records FROM odw_harmonised_db.sxo_dim where IsActive = 'Y' \")\r\n",
					"# New_Data_Records = spark.sql(\"SELECT DISTINCT RowID AS New_Data_Records FROM sxo_dim_new WHERE NewData = 'Y'\")\r\n",
					"# Deleted_Data_Records = spark.sql(\"SELECT DISTINCT RowID AS Deleted_Data_Records FROM sxo_dim_new WHERE DeletedData = 'Y'\")\r\n",
					"\r\n",
					"# Current_Records_Pandas =  Current_Records.toPandas()\r\n",
					"# New_Data_Records_Pandas = New_Data_Records.toPandas()\r\n",
					"# Deleted_Data_Records_Pandas = Deleted_Data_Records.toPandas()\r\n",
					"\r\n",
					"# # checking if a deleted records are correcly flagged, not existing in the new data, but existing inpreviously loaded\r\n",
					"# print(\"TEST 2:\")\r\n",
					"\r\n",
					"# Current_Records = Current_Records_Pandas['Current_Records'].tolist() \r\n",
					"# Deleted_Records = Deleted_Data_Records_Pandas['Deleted_Data_Records'].tolist()\r\n",
					"# New_Records = New_Data_Records_Pandas['New_Data_Records'].tolist()\r\n",
					"\r\n",
					"# print(Current_Records)\r\n",
					"# print(Deleted_Records)\r\n",
					"# print(New_Records)\r\n",
					"\r\n",
					"#for i in Deleted_Records:\r\n",
					"#    if i in Current_Records: \r\n",
					"#        print(i + \" to be deleted is in the current records\")\r\n",
					"#    else:\r\n",
					"#    else:\r\n",
					"        #raise RuntimeError(\"Records to Delete do not match\")\r\n",
					"\r\n",
					"# for j in New_Records:\r\n",
					"#     if j not in Current_Records: \r\n",
					"#         print(j + \" to be added is not in the current records\")\r\n",
					"#     else:\r\n",
					"#         #raise RuntimeError(\"Records to Add do not match\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Dataset is created that contains changed data and corresponding target data\n",
					"- This script combines data that has been updated, Deleted or is new, with corresponding target data\n",
					"- View **SXO_dim_new** is unioned to the target data filter to only those rows where changes have been detected\n",
					"## View SXO_dim_changed_rows is created"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"-- Create new and updated dataset\r\n",
					"\r\n",
					"CREATE OR REPLACE TEMPORARY  VIEW reading_case_changed_rows\r\n",
					"\r\n",
					"    AS\r\n",
					"\r\n",
					"-- gets updated, deleted and new rows \r\n",
					"\r\n",
					"Select \r\n",
					"    ReadingCaseID,\r\n",
					"    StateID,\r\n",
					"    Value, \r\n",
					"    SourceSystemID,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"From reading_case_dim_new WHERE HistoricIsActive = 'Y' or HistoricIsActive IS NULL\r\n",
					"\r\n",
					"    UNION ALL\r\n",
					"\r\n",
					"-- gets original versions of updated rows so we can update EndDate and set IsActive flag to 'N'\r\n",
					"\r\n",
					"SELECT\r\n",
					"    ReadingCaseID,\r\n",
					"    StateID,\r\n",
					"    Value,\r\n",
					"    SourceSystemID,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"FROM odw_harmonised_db.checkmark_reading_case_dim\r\n",
					"WHERE Value IN (SELECT Value FROM reading_case_dim_new WHERE StateID IS NULL)\r\n",
					"AND IsActive = 'Y'; \r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# View SXO_dim_changed_rows is used in a merge (Upsert) statement into the target table\n",
					"- **WHEN MATCHED** ON the Business Key (i.e. SxO from Personal Characteristics), EndDate is set to today -1 day and the IsActive flag is set to 'N'\n",
					"- **WHEN NOT MATCHED** ON the business key, insert rows\n",
					"## Table odw_harmonised.SXO_dim is updated"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"\r\n",
					"-- merge into fact table\r\n",
					"\r\n",
					"MERGE INTO odw_harmonised_db.checkmark_reading_case_dim AS Target\r\n",
					"USING reading_case_changed_rows AS Source\r\n",
					"\r\n",
					"ON Source.StateID = Target.StateID\r\n",
					"\r\n",
					"-- For Updates existing rows\r\n",
					"\r\n",
					"WHEN MATCHED\r\n",
					"    THEN \r\n",
					"    UPDATE SET\r\n",
					"    Target.ValidTo = date_sub(current_timestamp,1),\r\n",
					"    Target.IsActive = 'N'\r\n",
					"\r\n",
					"-- Insert completely new rows\r\n",
					"WHEN NOT MATCHED \r\n",
					"    THEN INSERT * ;   \r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Fix the IDs\n",
					"- No auto-increment feature is available in delta tables, therefore we need to create new IDs for the inserted rows\n",
					"- This is done by select the target data and using INSERT OVERWRITE to re-insert the data is a new Row Number\n",
					"## Table odw_harmonised.SXO_dim is updated"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\r\n",
					"-- Insert new SXOID\r\n",
					"\r\n",
					"INSERT OVERWRITE odw_harmonised_db.checkmark_reading_case_dim\r\n",
					"\r\n",
					"SELECT \r\n",
					"    ROW_NUMBER() OVER (ORDER BY ReadingCaseID NULLS LAST) AS ReadingCaseID, \r\n",
					"    StateID,\r\n",
					"    Value, \r\n",
					"    SourceSystemID,\r\n",
					"    IngestionDate,\r\n",
					"    ValidTo,\r\n",
					"    RowID,\r\n",
					"    IsActive\r\n",
					"FROM odw_harmonised_db.checkmark_reading_case_dim;\r\n",
					""
				],
				"execution_count": null
			}
		]
	}
}