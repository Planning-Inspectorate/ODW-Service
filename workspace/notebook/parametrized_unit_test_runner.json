{
  "name": "parametrized_unit_test_runner",
  "properties": {
    "folder": {
      "name": "utils/unit-tests"
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "bigDataPool": {
      "referenceName": "pinssynspodw34",
      "type": "BigDataPoolReference"
    },
    "sessionProperties": {
      "driverMemory": "28g",
      "driverCores": 4,
      "executorMemory": "28g",
      "executorCores": 4,
      "numExecutors": 2,
      "conf": {
        "spark.dynamicAllocation.enabled": "false",
        "spark.dynamicAllocation.minExecutors": "2",
        "spark.dynamicAllocation.maxExecutors": "2"
      }
    },
    "metadata": {
      "saveOutput": true,
      "enableDebugMode": true,
      "kernelspec": {
        "name": "synapse_pyspark",
        "display_name": "Synapse PySpark"
      },
      "language_info": {
        "name": "python"
      },
      "sessionKeepAliveTimeout": 30
    },
    "cells": [
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "import json\n",
          "from pyspark.sql.types import *\n",
          "from pyspark.sql import DataFrame\n",
          "from pyspark.sql.functions import *\n",
          "from collections import Counter\n",
          "import pprint\n",
          "\n",
          "# Parameters\n",
          "entity_name = mssparkutils.notebook.run.getArgument('entity_name', 'appeal-document')\n",
          "\n",
          "# Configuration mapping for different entities\n",
          "test_configs = {\n",
          "    'appeal-document': {\n",
          "        'entity_name': 'appeal-document',\n",
          "        'databases': {\n",
          "            'standardised': 'odw_standardised_db',\n",
          "            'harmonised': 'odw_harmonised_db',\n",
          "            'curated': 'odw_curated_db'\n",
          "        },\n",
          "        'tables': {\n",
          "            'std_table': 'sb_appeal_document',\n",
          "            'hrm_table': 'sb_appeal_document',\n",
          "            'hrm_final': 'appeal_document',\n",
          "            'curated_table': 'appeal_document'\n",
          "        },\n",
          "        'test_categories': [\n",
          "            'schema_validation',\n",
          "            'row_count_validation',\n",
          "            'data_integrity',\n",
          "            'no_record_dropping'\n",
          "        ],\n",
          "        'primary_key': 'documentId'\n",
          "    },\n",
          "    'nsip-project': {\n",
          "        'entity_name': 'nsip-project',\n",
          "        'databases': {\n",
          "            'standardised': 'odw_standardised_db',\n",
          "            'harmonised': 'odw_harmonised_db',\n",
          "            'curated': 'odw_curated_db'\n",
          "        },\n",
          "        'tables': {\n",
          "            'std_table': 'sb_nsip_project',\n",
          "            'hrm_table': 'sb_nsip_project',\n",
          "            'hrm_final': 'nsip_project',\n",
          "            'curated_table': 'nsip_project'\n",
          "        },\n",
          "        'test_categories': [\n",
          "            'schema_validation',\n",
          "            'row_count_validation',\n",
          "            'data_integrity',\n",
          "            'no_record_dropping'\n",
          "        ],\n",
          "        'primary_key': 'caseId'\n",
          "    }\n",
          "}\n",
          "\n",
          "# Get configuration for the entity\n",
          "test_config = test_configs.get(entity_name, test_configs['appeal-document'])\n",
          "\n",
          "# Exit code tracking\n",
          "exitCode = 0"
        ],
        "execution_count": null
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "class UnitTestFramework:\n",
          "    def __init__(self, config):\n",
          "        self.config = config\n",
          "        self.entity_name = config['entity_name']\n",
          "        self.databases = config['databases']\n",
          "        self.tables = config['tables']\n",
          "        self.primary_key = config.get('primary_key', 'id')\n",
          "        self.exit_code = 0\n",
          "        \n",
          "        # Load common functions\n",
          "        self.storage_account = mssparkutils.notebook.run('/utils/py_utils_get_storage_account')\n",
          "        self.path_to_orchestration_file = f\"abfss://odw-config@{self.storage_account}orchestration/orchestration.json\"\n",
          "    \n",
          "    def get_incremental_key(self, entity_name, storage_account, path_to_orchestration_file):\n",
          "        df = spark.read.option(\"multiline\", \"true\").json(path_to_orchestration_file)\n",
          "        definitions = json.loads(df.toJSON().first())['definitions']\n",
          "        definition = next((d for d in definitions if entity_name == d['Source_Filename_Start']), None)\n",
          "        return definition['Harmonised_Incremental_Key'] if definition and 'Harmonised_Incremental_Key' in definition else None\n",
          "    \n",
          "    def create_spark_schema(self, db_name, entity_name, folder_name=None, is_servicebus_schema=True):\n",
          "        incremental_key = self.get_incremental_key(\n",
          "            folder_name if folder_name else entity_name, \n",
          "            self.storage_account, \n",
          "            self.path_to_orchestration_file\n",
          "        ) if db_name == 'odw_harmonised_db' else None\n",
          "        \n",
          "        schema = mssparkutils.notebook.run(\n",
          "            '/py_create_spark_schema', 30, \n",
          "            {\n",
          "                'db_name': db_name, \n",
          "                'entity_name': entity_name, \n",
          "                'incremental_key': incremental_key, \n",
          "                'is_servicebus_schema': is_servicebus_schema\n",
          "            }\n",
          "        )\n",
          "        spark_schema = StructType.fromJson(json.loads(schema))\n",
          "        return spark_schema\n",
          "    \n",
          "    def compare_schemas(self, schema1, schema2):\n",
          "        \"\"\"Compare two schemas and return differences\"\"\"\n",
          "        structure1 = self.extract_schema_structure(schema1)\n",
          "        structure2 = self.extract_schema_structure(schema2)\n",
          "        \n",
          "        differences = []\n",
          "        all_fields = set(structure1.keys()).union(set(structure2.keys()))\n",
          "        \n",
          "        for field in all_fields:\n",
          "            if field not in structure1:\n",
          "                differences.append((field, \"Field not in schema1\", structure2[field]))\n",
          "            elif field not in structure2:\n",
          "                differences.append((field, structure1[field], \"Field not in schema2\"))\n",
          "            elif structure1[field] != structure2[field]:\n",
          "                differences.append((field, structure1[field], structure2[field]))\n",
          "        \n",
          "        if differences:\n",
          "            differences_df = spark.createDataFrame(differences, [\"Field\", \"Schema 1\", \"Schema 2\"])\n",
          "            display(differences_df)\n",
          "            return False\n",
          "        return True\n",
          "    \n",
          "    def extract_schema_structure(self, schema):\n",
          "        \"\"\"Extract schema structure for comparison\"\"\"\n",
          "        def extract_field(field):\n",
          "            if isinstance(field.dataType, StructType):\n",
          "                return {field.name: {subfield.name: str(subfield.dataType) for subfield in field.dataType.fields}}\n",
          "            elif isinstance(field.dataType, ArrayType):\n",
          "                element_type = field.dataType.elementType\n",
          "                if isinstance(element_type, StructType):\n",
          "                    subfield_extract = {}\n",
          "                    for subfield in element_type.fields:\n",
          "                        if isinstance(subfield.dataType, ArrayType):\n",
          "                            subfield_extract.update(extract_field(subfield))\n",
          "                        else:\n",
          "                            subfield_extract.update({subfield.name: str(subfield.dataType)})\n",
          "                    return {field.name: subfield_extract}\n",
          "                else:\n",
          "                    return {field.name: f'array<{str(element_type)}>'}\n",
          "            else:\n",
          "                return {field.name: str(field.dataType)}\n",
          "        \n",
          "        result = {}\n",
          "        for field in schema.fields:\n",
          "            result.update(extract_field(field))\n",
          "        return result"
        ],
        "execution_count": null
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "    def test_schema_validation(self):\n",
          "        \"\"\"Test schema validation for all layers\"\"\"\n",
          "        print(\"=== Schema Validation Tests ===\")\n",
          "        \n",
          "        # Test standardised schema\n",
          "        std_expected_schema = self.create_spark_schema(self.databases['standardised'], self.entity_name)\n",
          "        std_actual_schema = spark.table(f\"{self.databases['standardised']}.{self.tables['std_table']}\").schema\n",
          "        std_schema_correct = self.compare_schemas(std_expected_schema, std_actual_schema)\n",
          "        \n",
          "        print(f\"Standardised schema correct: {std_schema_correct}\")\n",
          "        print(f\"Table: {self.databases['standardised']}.{self.tables['std_table']}\")\n",
          "        \n",
          "        # Test harmonised schema\n",
          "        hrm_expected_schema = self.create_spark_schema(self.databases['harmonised'], self.entity_name)\n",
          "        hrm_actual_schema = spark.table(f\"{self.databases['harmonised']}.{self.tables['hrm_table']}\").schema\n",
          "        hrm_schema_correct = self.compare_schemas(hrm_expected_schema, hrm_actual_schema)\n",
          "        \n",
          "        print(f\"Harmonised schema correct: {hrm_schema_correct}\")\n",
          "        print(f\"Table: {self.databases['harmonised']}.{self.tables['hrm_table']}\")\n",
          "        \n",
          "        # Test curated schema\n",
          "        cur_expected_schema = self.create_spark_schema(self.databases['curated'], self.entity_name)\n",
          "        cur_actual_schema = spark.table(f\"{self.databases['curated']}.{self.tables['curated_table']}\").schema\n",
          "        cur_schema_correct = self.compare_schemas(cur_expected_schema, cur_actual_schema)\n",
          "        \n",
          "        print(f\"Curated schema correct: {cur_schema_correct}\")\n",
          "        print(f\"Table: {self.databases['curated']}.{self.tables['curated_table']}\")\n",
          "        \n",
          "        # Update exit code\n",
          "        self.exit_code += int(not std_schema_correct)\n",
          "        self.exit_code += int(not hrm_schema_correct)\n",
          "        self.exit_code += int(not cur_schema_correct)\n",
          "        \n",
          "        return std_schema_correct and hrm_schema_correct and cur_schema_correct\n",
          "    \n",
          "    def test_row_count_validation(self):\n",
          "        \"\"\"Test row count validation between layers\"\"\"\n",
          "        print(\"\\n=== Row Count Validation Tests ===\")\n",
          "        \n",
          "        # Test standardised to harmonised\n",
          "        std_df = spark.table(f\"{self.databases['standardised']}.{self.tables['std_table']}\")\n",
          "        if \"message_type\" in std_df.columns:\n",
          "            std_df = std_df.filter(std_df.message_type.isNotNull() & std_df.message_id.isNotNull())\n",
          "        \n",
          "        std_count = std_df.count()\n",
          "        hrm_count = spark.table(f\"{self.databases['harmonised']}.{self.tables['hrm_table']}\").count()\n",
          "        \n",
          "        print(f\"Standardised Count: {std_count:,}\")\n",
          "        print(f\"Harmonised Count: {hrm_count:,}\")\n",
          "        print(f\"Counts match: {std_count == hrm_count}\")\n",
          "        \n",
          "        if std_count != hrm_count:\n",
          "            self.exit_code += 1\n",
          "            print(f\"{abs(std_count - hrm_count)} rows difference between Standardised and Harmonised.\")\n",
          "        \n",
          "        # Test harmonised final to curated\n",
          "        hrm_final_df = spark.sql(f\"SELECT * FROM {self.databases['harmonised']}.{self.tables['hrm_final']} WHERE IsActive = 'Y'\")\n",
          "        hrm_final_count = hrm_final_df.drop_duplicates().count()\n",
          "        curated_count = spark.table(f\"{self.databases['curated']}.{self.tables['curated_table']}\").count()\n",
          "        \n",
          "        print(f\"\\nHarmonised Final Count: {hrm_final_count:,}\")\n",
          "        print(f\"Curated Count: {curated_count:,}\")\n",
          "        print(f\"Counts match: {hrm_final_count == curated_count}\")\n",
          "        \n",
          "        if hrm_final_count != curated_count:\n",
          "            self.exit_code += 1\n",
          "        \n",
          "        return std_count == hrm_count and hrm_final_count == curated_count"
        ],
        "execution_count": null
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "    def test_no_record_dropping(self):\n",
          "        \"\"\"Test that no records are being dropped inappropriately\"\"\"\n",
          "        print(\"\\n=== No Record Dropping Tests ===\")\n",
          "        \n",
          "        # Test standardised to harmonised - no primary key dropping\n",
          "        std_to_hrm_query = f\"\"\"\n",
          "        SELECT {self.primary_key}\n",
          "        FROM {self.databases['standardised']}.{self.tables['std_table']}\n",
          "        WHERE {self.primary_key} NOT IN (\n",
          "            SELECT {self.primary_key}\n",
          "            FROM {self.databases['harmonised']}.{self.tables['hrm_table']}\n",
          "        )\n",
          "        AND message_id IS NOT NULL\n",
          "        \"\"\"\n",
          "        \n",
          "        missing_records = spark.sql(std_to_hrm_query)\n",
          "        std_to_hrm_test_passed = missing_records.count() == 0\n",
          "        \n",
          "        print(f\"No records dropped from Standardised to Harmonised: {std_to_hrm_test_passed}\")\n",
          "        \n",
          "        if not std_to_hrm_test_passed:\n",
          "            print(f\"Found {missing_records.count()} missing records\")\n",
          "            self.exit_code += 1\n",
          "        \n",
          "        # Test harmonised to curated - no primary key dropping\n",
          "        hrm_to_cur_query = f\"\"\"\n",
          "        SELECT {self.primary_key}\n",
          "        FROM {self.databases['harmonised']}.{self.tables['hrm_final']}\n",
          "        WHERE IsActive = 'Y'\n",
          "        AND {self.primary_key} NOT IN (\n",
          "            SELECT {self.primary_key}\n",
          "            FROM {self.databases['curated']}.{self.tables['curated_table']}\n",
          "        )\n",
          "        \"\"\"\n",
          "        \n",
          "        missing_records_cur = spark.sql(hrm_to_cur_query)\n",
          "        hrm_to_cur_test_passed = missing_records_cur.count() == 0\n",
          "        \n",
          "        print(f\"No records dropped from Harmonised to Curated: {hrm_to_cur_test_passed}\")\n",
          "        \n",
          "        if not hrm_to_cur_test_passed:\n",
          "            print(f\"Found {missing_records_cur.count()} missing records\")\n",
          "            self.exit_code += 1\n",
          "        \n",
          "        return std_to_hrm_test_passed and hrm_to_cur_test_passed\n",
          "    \n",
          "    def test_data_integrity(self):\n",
          "        \"\"\"Test data integrity constraints\"\"\"\n",
          "        print(\"\\n=== Data Integrity Tests ===\")\n",
          "        \n",
          "        # Test for deleted records handling\n",
          "        if 'message_type' in spark.table(f\"{self.databases['standardised']}.{self.tables['std_table']}\").columns:\n",
          "            deleted_records_query = f\"\"\"\n",
          "            SELECT * FROM {self.databases['harmonised']}.{self.tables['hrm_table']}\n",
          "            WHERE message_id IN (\n",
          "                SELECT message_id\n",
          "                FROM {self.databases['standardised']}.{self.tables['std_table']}\n",
          "                WHERE message_type = 'Delete'\n",
          "            )\n",
          "            AND IsActive != 'N'\n",
          "            \"\"\"\n",
          "            \n",
          "            deleted_records_test = spark.sql(deleted_records_query)\n",
          "            deleted_test_passed = deleted_records_test.count() == 0\n",
          "            \n",
          "            print(f\"Deleted records properly handled: {deleted_test_passed}\")\n",
          "            \n",
          "            if not deleted_test_passed:\n",
          "                self.exit_code += 1\n",
          "        \n",
          "        # Test for ValidTo field consistency\n",
          "        if 'ValidTo' in spark.table(f\"{self.databases['harmonised']}.{self.tables['hrm_final']}\").columns:\n",
          "            valid_to_active_query = f\"\"\"\n",
          "            SELECT COUNT(*) as count FROM {self.databases['harmonised']}.{self.tables['hrm_final']}\n",
          "            WHERE IsActive = 'Y' AND ValidTo IS NOT NULL\n",
          "            \"\"\"\n",
          "            \n",
          "            valid_to_inactive_query = f\"\"\"\n",
          "            SELECT COUNT(*) as count FROM {self.databases['harmonised']}.{self.tables['hrm_final']}\n",
          "            WHERE IsActive = 'N' AND ValidTo IS NULL\n",
          "            \"\"\"\n",
          "            \n",
          "            active_with_valid_to = spark.sql(valid_to_active_query).collect()[0]['count']\n",
          "            inactive_without_valid_to = spark.sql(valid_to_inactive_query).collect()[0]['count']\n",
          "            \n",
          "            valid_to_test_passed = active_with_valid_to == 0 and inactive_without_valid_to == 0\n",
          "            print(f\"ValidTo field consistency: {valid_to_test_passed}\")\n",
          "            \n",
          "            if not valid_to_test_passed:\n",
          "                self.exit_code += 1\n",
          "        \n",
          "        return True"
        ],
        "execution_count": null
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "    def run_all_tests(self):\n",
          "        \"\"\"Run all test categories\"\"\"\n",
          "        print(f\"Running unit tests for entity: {self.entity_name}\")\n",
          "        print(\"=\" * 50)\n",
          "        \n",
          "        test_results = {}\n",
          "        \n",
          "        # Run test categories\n",
          "        test_categories = self.config.get('test_categories', [])\n",
          "        \n",
          "        if 'schema_validation' in test_categories:\n",
          "            test_results['schema_validation'] = self.test_schema_validation()\n",
          "        \n",
          "        if 'row_count_validation' in test_categories:\n",
          "            test_results['row_count_validation'] = self.test_row_count_validation()\n",
          "        \n",
          "        if 'no_record_dropping' in test_categories:\n",
          "            test_results['no_record_dropping'] = self.test_no_record_dropping()\n",
          "        \n",
          "        if 'data_integrity' in test_categories:\n",
          "            test_results['data_integrity'] = self.test_data_integrity()\n",
          "        \n",
          "        # Summary\n",
          "        print(\"\\n=== Test Summary ===\")\n",
          "        for test_name, result in test_results.items():\n",
          "            print(f\"{test_name}: {'PASSED' if result else 'FAILED'}\")\n",
          "        \n",
          "        print(f\"\\nOverall exit code: {self.exit_code}\")\n",
          "        \n",
          "        return self.exit_code"
        ],
        "execution_count": null
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# Initialize and run tests\n",
          "test_framework = UnitTestFramework(test_config)\n",
          "final_exit_code = test_framework.run_all_tests()\n",
          "\n",
          "# Exit with the result code\n",
          "mssparkutils.notebook.exit(final_exit_code)"
        ],
        "execution_count": null
      }
    ]
  }
}
