{
	"name": "SAP_HR_PROTECTED",
	"properties": {
		"folder": {
			"name": "odw-harmonised"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "c9aec634-6340-47ac-a6b2-37f111c19702"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Entity Name : Protected Data</u>\n",
					"###### Author: Prathap A\n",
					"###### Date: 25/02/2025\n",
					"\n",
					"###### version : 0001\n",
					"###### <u>Description</u>:\n",
					"This template is designed to facilitate the monthly processing and harmonization of Protected data. It includes steps for initializing the environment, creating and managing Delta tables, and inserting data into harmonized tables. The template ensures that Protected data is accurately transformed, stored, and made available for reporting and analysis."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Intialisations"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import udf, col, lit, when, coalesce, concat, sum, avg, max, min, count, countDistinct, date_format, to_date, datediff, months_between, year, month,  hour, minute, second, expr, asc, desc\n",
					"from pyspark.sql.types import DateType, TimestampType, StringType, IntegerType, FloatType, DoubleType, BooleanType, StructType, StructField, ArrayType, MapType\n",
					"from pyspark.sql.window import Window\n",
					"from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead, ntile\n",
					"from pyspark.sql import SQLContext\n",
					"from pyspark.sql import DataFrame\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.avro.functions import from_avro, to_avro\n",
					"from pyspark.sql.streaming import DataStreamReader, DataStreamWriter\n",
					"from pyspark.sql.utils import AnalysisException\n",
					"from pyspark.sql.catalog import Catalog\n",
					"from pyspark.sql.column import Column\n",
					"from pyspark.sql.group import GroupedData\n",
					"from pyspark.sql.pandas.functions import pandas_udf\n",
					"\n",
					"from datetime import datetime, timedelta\n",
					"import pandas as pd\n",
					"import numpy as np\n",
					"\n",
					""
				],
				"execution_count": 44
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Data Load into SAP_HR_PC"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"\n",
					"SET spark.sql.ansi.enabled = false;\n",
					"\n",
					"delete from odw_harmonised_db.SAP_HR_PC;\n",
					"\n",
					"insert into odw_harmonised_db.SAP_HR_PC\n",
					"SELECT \n",
					"    RefNo,\n",
					"    NULLIF(EthnicOrigin, '')  as EthnicOrigin,\n",
					"    NULLIF(ReligiousDenominationKey, '')  as ReligiousDenominationKey,\n",
					"    NULLIF(SxO, '')  as SxO,\n",
					"    Grade,\n",
					"    NULLIF(DisabilityText, '') as DisabilityText,\n",
					"    cast(to_timestamp(Report_MonthEnd_Date, \"dd/MM/yyyy\") as date) as Report_MonthEnd_Date,\n",
					"    'saphr' AS SourceSystemID,\n",
					"    CURRENT_DATE() AS IngestionDate,\n",
					"    CURRENT_TIMESTAMP() AS ValidTo,\n",
					"    md5(concat_ws('|', RefNo, EthnicOrigin, ReligiousDenominationKey, SxO, Grade, DisabilityText)) AS RowID,\n",
					"    'Y' AS IsActive\n",
					"FROM odw_standardised_db.sap_protected_monthly;"
				],
				"execution_count": 19
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# PC_INSERT_DELETE"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"-- First, ensure SAP_HR_PC is properly formatted with dates\n",
					"WITH source_data AS (\n",
					"    SELECT \n",
					"        RefNo,\n",
					"        NULLIF(EthnicOrigin, '') AS EthnicOrigin,\n",
					"        NULLIF(ReligiousDenominationKey, '') AS ReligiousDenominationKey,\n",
					"        NULLIF(SxO, '') AS SxO,\n",
					"        Grade,\n",
					"        NULLIF(DisabilityText, '') AS DisabilityText,\n",
					"        cast(to_timestamp(Report_MonthEnd_Date, \"dd/MM/yyyy\") as date) AS Report_MonthEnd_Date,\n",
					"        'saphr' AS SourceSystemID,\n",
					"        CURRENT_DATE() AS IngestionDate,\n",
					"        CURRENT_TIMESTAMP() AS ValidTo,\n",
					"        NULL AS RowID,\n",
					"        'Y' AS IsActive,\n",
					"        -- Calculate hash in the source directly\n",
					"        md5(concat(\n",
					"            coalesce(RefNo, ''),\n",
					"            coalesce(NULLIF(EthnicOrigin, ''), ''),\n",
					"            coalesce(NULLIF(ReligiousDenominationKey, ''), ''),\n",
					"            coalesce(NULLIF(SxO, ''), ''),\n",
					"            coalesce(Grade, ''),\n",
					"            coalesce(NULLIF(DisabilityText, ''), '')\n",
					"        )) AS record_hash\n",
					"    FROM odw_harmonised_db.SAP_HR_PC\n",
					"),\n",
					"-- Deduplicate source data to ensure only one row per key\n",
					"deduplicated_source AS (\n",
					"    SELECT *,\n",
					"           ROW_NUMBER() OVER (\n",
					"               PARTITION BY RefNo, Report_MonthEnd_Date \n",
					"               ORDER BY IngestionDate DESC\n",
					"           ) AS row_num\n",
					"    FROM source_data\n",
					")\n",
					"\n",
					"-- Use MERGE with deduplicated source\n",
					"MERGE INTO odw_harmonised_db.sap_hr_protected_data target\n",
					"USING (SELECT * FROM deduplicated_source WHERE row_num = 1) source\n",
					"ON source.RefNo = target.RefNo AND source.Report_MonthEnd_Date = target.Report_MonthEnd_Date\n",
					"WHEN MATCHED AND \n",
					"     md5(concat(\n",
					"        coalesce(target.RefNo, ''),\n",
					"        coalesce(target.EthnicOrigin, ''),\n",
					"        coalesce(target.ReligiousDenominationKey, ''),\n",
					"        coalesce(target.SxO, ''),\n",
					"        coalesce(target.Grade, ''),\n",
					"        coalesce(target.DisabilityText, '')\n",
					"     )) != source.record_hash \n",
					"THEN UPDATE SET\n",
					"    EthnicOrigin = source.EthnicOrigin,\n",
					"    ReligiousDenominationKey = source.ReligiousDenominationKey,\n",
					"    SxO = source.SxO,\n",
					"    Grade = source.Grade,\n",
					"    DisabilityText = source.DisabilityText,\n",
					"    SourceSystemID = source.SourceSystemID,\n",
					"    IngestionDate = source.IngestionDate,\n",
					"    ValidTo = source.ValidTo,\n",
					"    IsActive = source.IsActive\n",
					"WHEN NOT MATCHED THEN\n",
					"INSERT (\n",
					"    RefNo, EthnicOrigin, ReligiousDenominationKey, SxO, Grade, \n",
					"    DisabilityText, Report_MonthEnd_Date, SourceSystemID, \n",
					"    IngestionDate, ValidTo, RowID, IsActive\n",
					")\n",
					"VALUES (\n",
					"    source.RefNo, source.EthnicOrigin, source.ReligiousDenominationKey, \n",
					"    source.SxO, source.Grade, source.DisabilityText, source.Report_MonthEnd_Date, \n",
					"    source.SourceSystemID, source.IngestionDate, source.ValidTo, \n",
					"    source.RowID, source.IsActive\n",
					");"
				],
				"execution_count": 51
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# One off Historic load"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"editable": true,
					"run_control": {
						"frozen": false
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"delete from odw_harmonised_db.sap_hr_protected_data;\n",
					"\n",
					"INSERT into odw_harmonised_db.sap_hr_protected_data\n",
					"select\n",
					"\t   RefNumber   as RefNo\n",
					"      ,Ethnicorigin as EthnicOrigin\n",
					"      ,ReligiousDenominationKey\n",
					"      ,SxO\n",
					"      ,Grade\n",
					"      ,DisabilityText\n",
					"      ,  CASE \n",
					"    WHEN regexp_extract(file_name, '(20[0-9]{2})[-_]([0-9]{2})', 1) != '' THEN\n",
					"      TO_DATE(\n",
					"        CONCAT(\n",
					"          regexp_extract(file_name, '(20[0-9]{2})[-_]([0-9]{2})', 1),  -- Extract year\n",
					"          '-',\n",
					"          regexp_extract(file_name, '(20[0-9]{2})[-_]([0-9]{2})', 2),  -- Extract month\n",
					"          '-01'\n",
					"        ),\n",
					"        'yyyy-MM-dd'\n",
					"      )\n",
					"    ELSE NULL\n",
					"  END as Report_MonthEnd_Date\n",
					"      ,'saphr'  as SourceSystemID\n",
					"      ,current_date() as IngestionDate\n",
					"      ,current_timestamp() as ValidTo\n",
					"      ,null as RowID\n",
					"      ,'Y' as IsActive\n",
					" from \n",
					"odw_standardised_db.sap_hr_protected_data_hist ;"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"editable": false,
					"run_control": {
						"frozen": true
					},
					"collapsed": false
				},
				"source": [
					" %%sql\n",
					" select  DISTINCT\n",
					" file_name,\n",
					"  CASE \n",
					"    WHEN regexp_extract(file_name, '(20[0-9]{2})[-_]([0-9]{2})', 1) != '' THEN\n",
					"      TO_DATE(\n",
					"        CONCAT(\n",
					"          regexp_extract(file_name, '(20[0-9]{2})[-_]([0-9]{2})', 1),  -- Extract year\n",
					"          '-',\n",
					"          regexp_extract(file_name, '(20[0-9]{2})[-_]([0-9]{2})', 2),  -- Extract month\n",
					"          '-01'\n",
					"        ),\n",
					"        'yyyy-MM-dd'\n",
					"      )\n",
					"    ELSE NULL\n",
					"  END as Report_MonthEnd_Date\n",
					" \n",
					" from \n",
					"odw_standardised_db.sap_hr_protected_data_hist ;"
				],
				"execution_count": 15
			}
		]
	}
}