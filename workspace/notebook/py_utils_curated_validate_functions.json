{
	"name": "py_utils_curated_validate_functions",
	"properties": {
		"description": "Generic validation functions that can be imported and used in other notebooks.",
		"folder": {
			"name": "utils/data-validation"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "8b04bd91-d5de-401d-a82f-09ace5c230c2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Function to be used for validating data in a table against a defined json schema. To be called from other validation notebooks."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pandas as pd"
				],
				"execution_count": 9
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Validation functions"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def is_iso8601_date_time(instance):\r\n",
					"\r\n",
					"    \"\"\"\r\n",
					"    Function to check if a date matches ISO-8601 format\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    try:\r\n",
					"        parse_date(instance)\r\n",
					"        return True\r\n",
					"    except ParseError:\r\n",
					"        return False\r\n",
					"\r\n",
					"def validate_data(data: list, schema: dict) -> list:\r\n",
					"\r\n",
					"    \"\"\"\r\n",
					"    Function to validate a list of rows of data.\r\n",
					"    Validation includes a format check against ISO-8601.\r\n",
					"    \"\"\"\r\n",
					"    \r\n",
					"    format_checker = FormatChecker()\r\n",
					"    format_checker.checks(\"date-time\")(is_iso8601_date_time)\r\n",
					"    validator = Draft202012Validator(schema, format_checker=format_checker)\r\n",
					"\r\n",
					"    success = True\r\n",
					"\r\n",
					"    for index, row in enumerate(data, start=1):\r\n",
					"        errors = list(validator.iter_errors(row))\r\n",
					"        if errors:\r\n",
					"            success = False\r\n",
					"            print(f\"Validation failed for object at index {index}:\")\r\n",
					"            for error in errors:\r\n",
					"                print(error)\r\n",
					"                print(\"-\"*100)\r\n",
					"        print(\"#\"*100)\r\n",
					"        print(\"#\"*100)\r\n",
					"\r\n",
					"    return success"
				],
				"execution_count": 10
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to convert the rows in the table into a list of dictionaries - FLAT SCHEMA ONLY\r\n",
					"\r\n",
					"This maps the columns in the table to the json schema and creates the array(s) if needed to allow accurate validation of the data against the schema"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def create_json_from_table_flat(data: pd.DataFrame) -> list:\r\n",
					"\r\n",
					"    \"\"\"\r\n",
					"    Args:\r\n",
					"        data: pandas dataframe\r\n",
					"\r\n",
					"    Returns:\r\n",
					"        list of dictionaries\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    data_dict = defaultdict(dict)\r\n",
					"\r\n",
					"    final_dict = []\r\n",
					"\r\n",
					"    date_format = \"%Y-%m-%d %H:%M:%S\"\r\n",
					"\r\n",
					"    for index, row in data.iterrows():\r\n",
					"\r\n",
					"        for column, value in row.items():\r\n",
					"            data_dict[column] = value.strftime(date_format) if isinstance(value, pd.Timestamp) else value\r\n",
					"        \r\n",
					"        row_dict = {key: value for key, value in data_dict.items()}\r\n",
					"        final_dict.append(row_dict)\r\n",
					"\r\n",
					"    return final_dict"
				],
				"execution_count": 11
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to convert the rows in the table into a list of dictionaries - SCHEMAS WITH ARRAYS\r\n",
					"\r\n",
					"This maps the columns in the table to the json schema and creates the array(s) if needed to allow accurate validation of the data against the schema"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def create_json_from_table_with_arrays(data: pd.DataFrame, primary_key: str, array: str, array_field: str) -> list:\r\n",
					"\r\n",
					"    \"\"\"\r\n",
					"    Args:\r\n",
					"        data: pandas dataframe\r\n",
					"        primary_key: string\r\n",
					"        array: string\r\n",
					"        array_field: string\r\n",
					"\r\n",
					"    Returns:\r\n",
					"        list of dictionaries\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    data_dict = defaultdict(dict)\r\n",
					"\r\n",
					"    array_field_to_exclude = array_field\r\n",
					"\r\n",
					"    date_format = \"%Y-%m-%d %H:%M:%S\"\r\n",
					"\r\n",
					"    for index, row in data.iterrows():\r\n",
					"\r\n",
					"        primary_key_field = row[primary_key]\r\n",
					"\r\n",
					"        if primary_key_field not in data_dict:\r\n",
					"\r\n",
					"            data_dict[primary_key_field][array] = []\r\n",
					"\r\n",
					"            for column, value in row.items():\r\n",
					"                if column in array_field_to_exclude:\r\n",
					"                    continue\r\n",
					"                data_dict[primary_key_field][column] = value.strftime(date_format) if isinstance(value, pd.Timestamp) else value\r\n",
					"\r\n",
					"        array_to_populate = data_dict[primary_key_field][array]\r\n",
					"        new_item = row[array_field]\r\n",
					"        if new_item not in array_to_populate:\r\n",
					"            array_to_populate.append(new_item)\r\n",
					"\r\n",
					"    final_dict = {key: dict(value) for key, value in data_dict.items()}\r\n",
					"\r\n",
					"    data_to_compare = list(final_dict.values())\r\n",
					"\r\n",
					"    return data_to_compare"
				],
				"execution_count": 12
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Function to convert the rows in the table into a list of dictionaries - examination_timetable only\r\n",
					"\r\n",
					"Bespoke function for examination_timetable as it's the only schema with nested arrays within arrays so need a bit of extra processing."
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def create_json_from_table_examination_timetable(data: pd.DataFrame) -> list:\r\n",
					"\r\n",
					"    \"\"\"\r\n",
					"    Args:\r\n",
					"        data: pandas dataframe\r\n",
					"\r\n",
					"    Returns:\r\n",
					"        list of dictionaries\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    data_dict = defaultdict(dict)\r\n",
					"\r\n",
					"    event_fields = [\"eventID\", \"eventType\", \"eventTitle\", \"eventDeadlineStartDate\", \"eventDate\"]\r\n",
					"    eventLineItemFields = [\"eventLineItemDescription\"]\r\n",
					"\r\n",
					"    date_format = \"%Y-%m-%d %H:%M:%S\"\r\n",
					"\r\n",
					"    for index, row in data.iterrows():\r\n",
					"        caseReference = row[\"caseReference\"]\r\n",
					"\r\n",
					"        for column, value in row.items():\r\n",
					"            if caseReference not in data_dict:\r\n",
					"                data_dict[caseReference][column] = value\r\n",
					"\r\n",
					"                data_dict[caseReference][\"events\"] = []\r\n",
					"\r\n",
					"            events = data_dict[caseReference][\"events\"]\r\n",
					"            new_event = {column: value for column, value in row.items() if column in event_fields}\r\n",
					"            new_eventLineItem = {column: value for column, value in row.items() if column in eventLineItemFields}\r\n",
					"            \r\n",
					"            if new_event not in events:\r\n",
					"                events.append(new_event)\r\n",
					"\r\n",
					"        for event in events:\r\n",
					"            if \"eventLineItems\" not in event:\r\n",
					"                event[\"eventLineItems\"] = []\r\n",
					"                eventLineItems = event[\"eventLineItems\"]\r\n",
					"                if new_eventLineItem not in eventLineItems:\r\n",
					"                    eventLineItems.append(new_eventLineItem)\r\n",
					"\r\n",
					"    final_dict = {key: dict(value) for key, value in data_dict.items()}\r\n",
					"\r\n",
					"    data_to_compare = list(final_dict.values())\r\n",
					"\r\n",
					"    return data_to_compare"
				],
				"execution_count": null
			}
		]
	}
}