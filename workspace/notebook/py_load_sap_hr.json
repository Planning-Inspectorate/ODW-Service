{
	"name": "py_load_sap_hr",
	"properties": {
		"folder": {
			"name": "odw-harmonised/saphr"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "e6aeabe8-b7e5-4001-a11e-39615d2740db"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### The purpose of this notebook is to read data from Standardised layer and build a table for Curated Layer.\n",
					"\n",
					"**Author** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   **Created Date** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Description**  \n",
					"Prathap Adicherla &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;01-April-2025 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This Notebook is designed to facilitate the monthly processing and harmonization of SAP HR data. It includes steps for initializing the environment, creating and managing Delta tables, and inserting data into harmonized tables. The Notebook ensures that HR data is accurately transformed, stored, and made available for reporting and analysis."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## LOAD_SAP_HR_MONTHLY"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import udf, col, lit, when, coalesce, concat, sum, avg, max, min, count, countDistinct, date_format, to_date, datediff, months_between, year, month,  hour, minute, second, expr, asc, desc\n",
					"from pyspark.sql.types import DateType, TimestampType, StringType, IntegerType, FloatType, DoubleType, BooleanType, StructType, StructField, ArrayType, MapType\n",
					"from pyspark.sql.window import Window\n",
					"from pyspark.sql.functions import row_number, rank, dense_rank, lag, lead, ntile\n",
					"from pyspark.sql import SQLContext\n",
					"from pyspark.sql import DataFrame\n",
					"from pyspark.sql import functions as F\n",
					"from pyspark.sql.avro.functions import from_avro, to_avro\n",
					"from pyspark.sql.streaming import DataStreamReader, DataStreamWriter\n",
					"from pyspark.sql.utils import AnalysisException\n",
					"from pyspark.sql.catalog import Catalog\n",
					"from pyspark.sql.column import Column\n",
					"from pyspark.sql.group import GroupedData\n",
					"from pyspark.sql.pandas.functions import pandas_udf\n",
					"\n",
					"from datetime import datetime, timedelta\n",
					"import pandas as pd\n",
					"import numpy as np"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"microsoft": {
						"language": "sparksql"
					},
					"collapsed": false
				},
				"source": [
					"%%sql\n",
					"\n",
					"SET spark.sql.legacy.timeParserPolicy = LEGACY;\n",
					"\n",
					"-- Delete existing data\n",
					"DELETE FROM odw_harmonised_db.load_sap_hr_monthly;\n",
					"\n",
					"-- Insert data and generate RowID in one operation\n",
					"INSERT INTO odw_harmonised_db.load_sap_hr_monthly\n",
					"SELECT\n",
					"    PersNo,\n",
					"    Firstname,\n",
					"    Lastname,\n",
					"    EmployeeNo,\n",
					"    CoCd,\n",
					"    CompanyCode,\n",
					"    PA,\n",
					"    PersonnelArea,\n",
					"    PSubarea,\n",
					"    PersonnelSubarea,\n",
					"    Orgunit,\n",
					"    OrganizationalUnit,\n",
					"    Organizationalkey,\n",
					"    OrganizationalKey1,\n",
					"    WorkC,\n",
					"    WorkContract,\n",
					"    CT,\n",
					"    ContractType,\n",
					"    PSgroup,\n",
					"    PayBandDescription,\n",
					"    CASE WHEN FTE = '' THEN NULL ELSE TRY_CAST(FTE AS FLOAT) END AS FTE,\n",
					"    CASE WHEN Wkhrs = '' THEN NULL ELSE TRY_CAST(Wkhrs AS FLOAT) END AS Wkhrs,\n",
					"    CASE WHEN IndicatorPartTimeEmployee = '' THEN NULL ELSE TRY_CAST(IndicatorPartTimeEmployee AS BOOLEAN) END AS IndicatorPartTimeEmployee,\n",
					"    S,\n",
					"    EmploymentStatus,\n",
					"    GenderKey,\n",
					"    TRAStartDate AS TRAStartDate,\n",
					"    TRAEndDate AS TRAEndDate,\n",
					"    TRAStatus,\n",
					"    TRAGrade,\n",
					"    PrevPersNo,\n",
					"    ActR,\n",
					"    ReasonforAction,\n",
					"    Position,\n",
					"    Position1,\n",
					"    CostCtr,\n",
					"    CostCentre,\n",
					"    cast(to_timestamp(CivilServiceStart, \"dd/MM/yyyy\") as date) as CivilServiceStart,\n",
					"    cast(to_timestamp(DatetoCurrentJob  ,'dd/MM/yyyy') as date) AS DatetoCurrentJob,\n",
					"    cast(to_timestamp(SeniorityDate  ,'dd/MM/yyyy') as date) AS SeniorityDate,\n",
					"    cast(to_timestamp(DatetoSubstGrade  ,'dd/MM/yyyy')  as date) as DatetoSubstGrade,\n",
					"    PersNo1,\n",
					"    NameofManagerOM,\n",
					"    ManagerPosition,\n",
					"    ManagerPositionText,\n",
					"    CounterSignManager,\n",
					"    Loc,\n",
					"    Location,\n",
					"    cast(to_timestamp(OrgStartDate,'dd/MM/yyyy')  as date) as OrgStartDate,\n",
					"    FixTermEndDate AS FixTermEndDate,\n",
					"    LoanStartDate AS LoanStartDate,\n",
					"    LoanEndDate AS LoanEndDate,\n",
					"    EEGrp,\n",
					"    EmployeeGroup,\n",
					"    CASE WHEN Annualsalary = '' THEN NULL ELSE TRY_CAST(Annualsalary AS DOUBLE) END AS Annualsalary,\n",
					"    Curr,\n",
					"    null as NInumber,\n",
					"    to_date(Birthdate,'dd/MM/yyyy') as Birthdate,\n",
					"    Ageofemployee,\n",
					"    EO,\n",
					"    Ethnicorigin,\n",
					"    NID,\n",
					"    Rel,\n",
					"    ReligiousDenominationKey,\n",
					"    SxO,\n",
					"    WageType,\n",
					"    EmployeeSubgroup,\n",
					"    LOAAbsType,\n",
					"    LOAAbsenceTypeText,\n",
					"    Schemereference,\n",
					"    PensionSchemeName,\n",
					"    DisabilityCode,\n",
					"    DisabilityText,\n",
					"    DisabilityCodeDescription,\n",
					"    PArea,\n",
					"    PayrollArea,\n",
					"    AssignmentNumber,\n",
					"    CASE WHEN FTE2 = '' THEN NULL ELSE TRY_CAST(FTE2 AS FLOAT) END AS FTE2,\n",
					"    cast(Report_MonthEnd_Date as date) as Report_MonthEnd_Date,\n",
					"    CURRENT_TIMESTAMP() AS PDAC_ETL_Date,\n",
					"    'saphr' AS SourceSystemID,\n",
					"    CURRENT_DATE() AS IngestionDate,\n",
					"    CURRENT_TIMESTAMP() AS ValidTo,\n",
					"    md5(concat_ws('|', \n",
					"        PersNo, Firstname, Lastname, EmployeeNo, CoCd, CompanyCode, PA, PersonnelArea, PSubarea, PersonnelSubarea, \n",
					"        Orgunit, OrganizationalUnit, Organizationalkey, OrganizationalKey1, WorkC, WorkContract, CT, ContractType, \n",
					"        PSgroup, PayBandDescription, FTE, Wkhrs, IndicatorPartTimeEmployee, S, EmploymentStatus, GenderKey, \n",
					"        TRAStartDate, TRAEndDate, TRAStatus, TRAGrade, PrevPersNo, ActR, ReasonforAction, Position, Position1, \n",
					"        CostCtr, CostCentre, CivilServiceStart, DatetoCurrentJob, SeniorityDate, DatetoSubstGrade, PersNo1, \n",
					"        NameofManagerOM, ManagerPosition, ManagerPositionText, CounterSignManager, Loc, Location, OrgStartDate, \n",
					"        FixTermEndDate, LoanStartDate, LoanEndDate, EEGrp, EmployeeGroup, Annualsalary, Curr, NInumber, Birthdate, \n",
					"        Ageofemployee, EO, Ethnicorigin, NID, Rel, ReligiousDenominationKey, SxO, WageType, EmployeeSubgroup, \n",
					"        LOAAbsType, LOAAbsenceTypeText, Schemereference, PensionSchemeName, DisabilityCode, DisabilityText, \n",
					"        DisabilityCodeDescription, PArea, PayrollArea, AssignmentNumber, FTE2\n",
					"    )) AS RowID,\n",
					"    'Y' AS IsActive\n",
					"FROM odw_standardised_db.sap_hr_history_monthly;"
				],
				"execution_count": 1
			}
		]
	}
}