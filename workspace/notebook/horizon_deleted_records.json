{
	"name": "horizon_deleted_records",
	"properties": {
		"folder": {
			"name": "utils"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "pinssynspodw",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "bf0acafc-e1db-4dea-b905-e2b4e1ad5586"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/ff442a29-fc06-4a13-8e3e-65fd5da513b3/resourceGroups/pins-rg-data-odw-dev-uks/providers/Microsoft.Synapse/workspaces/pins-synw-odw-dev-uks/bigDataPools/pinssynspodw",
				"name": "pinssynspodw",
				"type": "Spark",
				"endpoint": "https://pins-synw-odw-dev-uks.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/pinssynspodw",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import DataFrame\n",
					"from pyspark.sql.functions import when, col, date_add"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"service_bus_table = \"odw_harmonised_db.sb_s51_advice\"\n",
					"horizon_table = \"odw_standardised_db.horizon_nsip_advice\"\n",
					"spark_table_final = \"odw_harmonised_db.nsip_s51_advice\"\n",
					"curated_migration_table = \"odw_curated_migration_db.s51_advice\""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"servicebus_df = spark.table(service_bus_table)\n",
					"horizon_df = spark.table(horizon_table)\n",
					"horizon_latest_df = spark.sql(f\"select * from {horizon_table} where ingested_datetime = (select max(ingested_datetime) from {horizon_table})\")\n",
					"horizon_deleted = horizon_df.join(horizon_latest_df, on=\"advicenodeid\", how=\"left_anti\").select(\"advicenodeid\").distinct()\n",
					"harmonised_df = spark.table(spark_table_final)\n",
					"curated_migration_df = spark.table(curated_migration_table)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def test_no_deleted_horizon_records_in_harmonised(horizon_latest_df: DataFrame, harmonised_df: DataFrame) -> bool:\n",
					"    \"\"\"\n",
					"    Tests if there are any records in harmonised that have been deleted from Horizon\n",
					"    \"\"\"\n",
					"    harmonised_df: DataFrame = harmonised_df.filter(\"ODTSourceSystem = 'Horizon' and IsActive = 'Y'\")\n",
					"    result_df: DataFrame = harmonised_df.join(\n",
					"        horizon_latest_df, \n",
					"        on=harmonised_df.adviceId==horizon_latest_df.advicenodeid,\n",
					"        how=\"left_anti\"\n",
					"    )\n",
					"    return result_df.count() == 0\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def test_valid_to_set_for_inactive_records(harmonised_df: DataFrame) -> bool:\n",
					"    \"\"\"\n",
					"    Tests if the ValidTo date is populated for all inactive records\n",
					"    \"\"\"\n",
					"    harmonised_df.filter(\"IsActive = 'N' and ValidTo is null\")\n",
					"    return harmonised_df.count() == 0"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"def test_valid_to_not_set_for_active_records(harmonised_df: DataFrame) -> bool:\n",
					"    \"\"\"\n",
					"    Tests if the ValidTo date is not populated for active records\n",
					"    \"\"\"\n",
					"    harmonised_df.filter(\"IsActive = 'Y' and ValidTo is not null\")\n",
					"    return harmonised_df.count() == 0"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"test_no_deleted_horizon_records_in_harmonised(horizon_latest_df, harmonised_df)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"test_valid_to_set_for_inactive_records(harmonised_df)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"test_valid_to_not_set_for_active_records(harmonised_df)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"deleted_advice_ids = [row[0] for row in horizon_deleted.collect()]\n",
					"\n",
					"hrm_updated = harmonised_df.withColumn(\n",
					"    \"IsActive\", when(col(\"adviceId\").isin(deleted_advice_ids), \"N\").otherwise(col(\"IsActive\"))\n",
					")\n",
					"\n",
					"hrm_final = hrm_updated.withColumn(\n",
					"    \"ValidTo\", when((col(\"ValidTo\").isNull()) & (col(\"IsActive\") == \"N\"), date_add(col(\"IngestionDate\"), 1).cast(\"timestamp\")).otherwise(col(\"ValidTo\"))\n",
					")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"test_no_deleted_horizon_records_in_harmonised(horizon_latest_df, hrm_final)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"test_valid_to_set_for_inactive_records(hrm_final)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"test_valid_to_not_set_for_active_records(hrm_final)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"display(hrm_final.filter(\"ValidTo is not null and IsActive = 'Y'\"))"
				],
				"execution_count": null
			}
		]
	}
}