{
	"name": "pln_casework_main",
	"properties": {
		"activities": [
			{
				"name": "Ingest Standardised",
				"description": "Ingests raw data into standardised. Can create tables if they don't already exist.",
				"type": "SynapseNotebook",
				"dependsOn": [
					{
						"activity": "Ingest Raw",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"notebook": {
						"referenceName": "py_casework_raw_to_std",
						"type": "NotebookReference"
					},
					"parameters": {
						"date_folder": {
							"value": {
								"value": "@formatDateTime(utcNow(), 'yyyy-MM-dd')",
								"type": "Expression"
							},
							"type": "string"
						}
					},
					"snapshot": true,
					"conf": {
						"spark.dynamicAllocation.enabled": null,
						"spark.dynamicAllocation.minExecutors": null,
						"spark.dynamicAllocation.maxExecutors": null
					},
					"numExecutors": null
				}
			},
			{
				"name": "Prepare Views",
				"description": "Creates views from each standardised table with the data from the latest ingestion.",
				"type": "SynapseNotebook",
				"dependsOn": [
					{
						"activity": "Ingest Standardised",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"notebook": {
						"referenceName": "casework-views",
						"type": "NotebookReference"
					},
					"snapshot": true,
					"conf": {
						"spark.dynamicAllocation.enabled": null,
						"spark.dynamicAllocation.minExecutors": null,
						"spark.dynamicAllocation.maxExecutors": null
					},
					"numExecutors": null
				}
			},
			{
				"name": "Ingest Harmonised",
				"description": "Sequentially runs the notebooks that are responsible for ingesting data in each of the tables in the harmonised layer. Each notebook may utilise the views created in the previous step.",
				"type": "SynapseNotebook",
				"dependsOn": [
					{
						"activity": "Prepare Views",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"notebook": {
						"referenceName": "casework_master",
						"type": "NotebookReference"
					},
					"snapshot": true,
					"conf": {
						"spark.dynamicAllocation.enabled": null,
						"spark.dynamicAllocation.minExecutors": null,
						"spark.dynamicAllocation.maxExecutors": null
					},
					"numExecutors": null
				}
			},
			{
				"name": "Ingest Raw",
				"description": "Copies case, appeal, NSIP, Green Appeal data sourced from Horizon, PICASO and Back Office into ODW's raw layer.",
				"type": "ExecutePipeline",
				"dependsOn": [],
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "pln_casework_source_to_raw",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true
				}
			}
		],
		"folder": {
			"name": "archive/casework"
		},
		"annotations": []
	}
}